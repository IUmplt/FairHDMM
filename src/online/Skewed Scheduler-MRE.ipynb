{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478247e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from typing import Tuple\n",
    "import src.hdmm.workload as workload\n",
    "import src.census_workloads as census\n",
    "from src.workload_selection import workload_selection\n",
    "import online_workloads as online_workloads\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15becd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7387706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=64\n",
    "W_name = ['identity', 'H2', 'race1', 'race2', 'race3', 'custom', 'prefix_sum']#, 'total',]\n",
    "W_lst = [online_workloads.identity(n), online_workloads.H2(n), online_workloads.race1(), online_workloads.race2(), online_workloads.race3(), online_workloads.custom(n), online_workloads.prefix_sum(n),] # online_workloads.total(n),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12416414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw_naive(workload, x, analyst_labels, T, eps=0.01, total_k=None, \n",
    "         show_messages=False, to_return='error', show_plot=False, show_failure_step=False, eta = None,\n",
    "             count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries where analysts can run out of privacy budget if they use too much of others'. \n",
    "    \n",
    "    In other words, all analysts share from the same privacy budget. \n",
    "    \n",
    "    Last Updated: 4-23-2022\n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - total_k = total number of update steps alloted for the entire group\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'error', pmw() returns a dictionary for the average absolute error for each analyst\n",
    "        - if 'pct_ans', pmw() returns a dictionary for the percent of queries answered that meets\n",
    "        the accuracy threshold set by count_threshold\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    - count_threshold - this is for the to_return = 'pct_ans' setting. It is the min error threshold \n",
    "    that a query answer for us to count the answer as \"reasonable\" as opposed to \"bot\". The default\n",
    "    is 0.1. This functions as another way to  measure the accuracy of the queries that is more similar \n",
    "    to how our other functions; i.e., cache and reconstruct either returns an accurate answer or \"bot\".\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    if(eta == None):\n",
    "        eta = (math.log(m, np.e) / ((math.sqrt(n))) )\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    # initialize total_k, the total number of update steps if not default\n",
    "    if total_k == None:\n",
    "        total_k = round(n * math.log(math.sqrt(m)) / 770) #770\n",
    "        #print(f'{total_k=}')\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        answer = np.dot(query, x_list[time])\n",
    "        if answer < 0:\n",
    "            pmw_answers.append(0)\n",
    "        else: \n",
    "            pmw_answers.append(answer)\n",
    "        x_list.append(x_list[time])\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    #print(rho + T)\n",
    "    \n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique; compute noisy answer by adding Laplacian noise\n",
    "        A_t = np.random.laplace(loc=0, scale=(total_k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # LAZY ROUND: QUERY USING THE SYNTHETIC DATABASE\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "\n",
    "        # UPDATE ROUND: UPDATE SYNTHETIC DATABASE AND RETURN NOISY ANSWER, A_T-HAT\n",
    "        else:\n",
    "            # noise\n",
    "            A_t = np.random.laplace(loc=0, scale=(2*total_k/eps), size=1)[0]\n",
    "            \n",
    "            # noisy answer\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i in range(len(y_t)):\n",
    "                y_t[i] = x_list[time][i] * math.exp(-( eta * r_t[i]))# eta is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if total_k == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t)\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                answer = a_t_hat / np.sum(x)\n",
    "                \n",
    "                if answer < 0:\n",
    "                    pmw_answers.append(0)\n",
    "                else: \n",
    "                    pmw_answers.append(answer)\n",
    "                \n",
    "                total_k -= 1 # use one of the total update steps\n",
    "        \n",
    "        #print(f'{x_list[time] - x_list[time - 1]=}')\n",
    "        \n",
    "        \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Synthetic Database (after) = {x_list[len(x_list) - 1] * sum(x)}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Synthetic Database (before) = {x_list[0]}\\n')\n",
    "        print(f'Synthetic Database (after, norm) = {x_list[len(x_list) - 1]}\\n')\n",
    "        print(f'Difference btw. Final Synthetic and true database = {x_list[len(x_list) - 1] - x_norm}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*total_k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*total_k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        #test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"tse\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data['squared_err'] = data['abs_error'] ** 2\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) & \n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20d3be22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([412, 333, 285, 231, 202, 174, 160, 142, 146, 149, 145, 181, 174,\n",
       "       190, 213, 287, 372, 499, 619, 715, 785, 821, 822, 816, 799, 742,\n",
       "       717, 697, 658, 593, 564, 519, 447, 403, 388, 365, 336, 306, 311,\n",
       "       289, 261, 231, 213, 196, 194, 170, 175, 168, 149, 142, 131, 119,\n",
       "       112, 118, 114, 116, 112, 114, 106, 111, 109, 112, 113, 109, 104,\n",
       "       108, 108,  94,  91,  81,  81,  72,  68,  63,  56,  46,  41,  38,\n",
       "        34,  28,  23,  22,  18,  18,  16,  41])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"migration_tworace.csv\"\n",
    "x_race = pd.read_csv(data_path, header=None).to_numpy().T[1] # truncate to first 64\n",
    "x_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41149e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [11, 22, 33],\n",
       "        [ 7,  8,  9],\n",
       "        [44, 55, 66],\n",
       "        [77, 88, 99]]),\n",
       " ['A', 'A', 'B', 'A', 'B', 'B'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def skewed_scheduler(a: np.ndarray, b: np.ndarray, p: int) -> Tuple: \n",
    "    \"\"\"\n",
    "    Schedules Alice's queries with a probability of p and Bob's queries with a probability of (p - 1).\n",
    "    \n",
    "    Returns new workload of queries (2x2 np.array) and analyst labels (python list). \n",
    "    \n",
    "    p: prob of scheduling Alice's queries\n",
    "    a: alice's workload\n",
    "    b: bob's workload\n",
    "    \"\"\"\n",
    "    \n",
    "    W = []\n",
    "    analyst_labels = []\n",
    "    \n",
    "    if a.shape[1] != b.shape[1]:\n",
    "         raise TypeError(\"a and b dimensions don't match\")\n",
    "    \n",
    "    a_pointer = 0\n",
    "    b_pointer = 0\n",
    "    \n",
    "    while(a_pointer < len(a) and b_pointer < len(b)):\n",
    "        if np.random.random() < p:\n",
    "            W.append(a[a_pointer])\n",
    "            a_pointer += 1\n",
    "            analyst_labels.append('A')\n",
    "        else: \n",
    "            W.append(b[b_pointer])\n",
    "            b_pointer += 1\n",
    "            analyst_labels.append('B')\n",
    "    \n",
    "    if a_pointer == len(a):\n",
    "        W = np.vstack((W, b[b_pointer:]))\n",
    "        analyst_labels += ['B' for i in range(b_pointer, len(b))]\n",
    "    if b_pointer == len(b): \n",
    "        W = np.vstack((W, a[a_pointer:]))\n",
    "        analyst_labels += ['A' for i in range(a_pointer, len(a))]\n",
    "    \n",
    "    W = np.array(W)\n",
    "    return W, analyst_labels\n",
    "\n",
    "a_ex = np.array([[1, 2, 3],\n",
    "             [4, 5, 6],\n",
    "             [7, 8, 9]])\n",
    "\n",
    "b_ex = np.array([[11, 22, 33],\n",
    "             [44, 55, 66],\n",
    "             [77, 88, 99]])\n",
    "    \n",
    "skewed_scheduler(a_ex, b_ex, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3798f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_ratio_df(version='practical', iterations=3000, input_thresh = 0.05, mode='utility'):\n",
    "    \"\"\"\n",
    "    Run experiments using calc_max_ratio. \n",
    "    \n",
    "    version = type of workloads\n",
    "        practical: practical workloads from hdmm paper\n",
    "        disjoint: random disjoint workloads\n",
    "    \n",
    "    mode = \n",
    "        utility: refers to pct of queries answerable\n",
    "        error: refers to the pct of queries unanswerable \n",
    "        error_val: refers to the exact error values of the queries from pmw\n",
    "    \n",
    "    date: may-1, last edited may-4\n",
    "    \"\"\"\n",
    "    BwA_lst = []\n",
    "    BwoA_lst = []\n",
    "    AwB_lst = []\n",
    "    AwoB_lst = []\n",
    "    max_ratio_p_lst = []\n",
    "    \n",
    "    def calc_max_ratio(p, thresh = 0.03, workload='practical'):\n",
    "        \"\"\"\n",
    "        Calculate max ratio using appending to lists. \n",
    "\n",
    "        May 1\n",
    "        \"\"\"\n",
    "\n",
    "        #database = x_race[:64]\n",
    "        database = np.concatenate([x_race[:32], x_race[:32]])\n",
    "\n",
    "        if workload=='practical':\n",
    "            c = np.random.randint(len(W_lst))\n",
    "\n",
    "            alice = W_lst[c]\n",
    "            bob = W_lst[c]\n",
    "\n",
    "        elif workload=='disjoint':\n",
    "            random_array = np.random.randint(2, size=(100,32))\n",
    "            zero_array = np.zeros((100,32))\n",
    "            alice = np.hstack((random_array, zero_array))\n",
    "            bob = np.hstack((zero_array, random_array))\n",
    "        \n",
    "        # skewed scheduler\n",
    "        W, analyst_labels = skewed_scheduler(alice, bob, p)\n",
    "        \n",
    "        if mode=='error_val':\n",
    "            BwA = pmw_naive(W, database, analyst_labels, eps=1, T=40, to_return='error', count_threshold=thresh)['B']\n",
    "\n",
    "            AwB = pmw_naive(W, database, analyst_labels, eps=1, T=40, to_return='error', count_threshold=thresh)['A']\n",
    "\n",
    "            # bob ind\n",
    "            BwoA = pmw_naive(bob, database, ['B'] * len(bob), eps=0.5, T=20, to_return='error', count_threshold=thresh)['B']\n",
    "\n",
    "            # alice ind\n",
    "            AwoB = pmw_naive(bob, database, ['A'] * len(alice), eps=0.5, T=20, to_return='error', count_threshold=thresh)['A']\n",
    "            \n",
    "            if(AwoB != 0 and BwoA != 0):\n",
    "                if mode=='utility':        \n",
    "                    # prevent divide by 0 error, ignore\n",
    "                    max_ratio_p_lst.append(p)\n",
    "                    BwA_lst.append(BwA)\n",
    "                    BwoA_lst.append(BwoA)\n",
    "                    AwB_lst.append(AwB)\n",
    "                    AwoB_lst.append(AwoB)\n",
    "        else: \n",
    "            BwA = pmw_naive(W, database, analyst_labels, eps=1, T=40, to_return='pct_ans', count_threshold=thresh)['B']\n",
    "\n",
    "            AwB = pmw_naive(W, database, analyst_labels, eps=1, T=40, to_return='pct_ans', count_threshold=thresh)['A']\n",
    "\n",
    "            # bob ind\n",
    "            BwoA = pmw_naive(bob, database, ['B'] * len(bob), eps=0.5, T=20, to_return='pct_ans', count_threshold=thresh)['B']\n",
    "\n",
    "            # alice ind\n",
    "            AwoB = pmw_naive(bob, database, ['A'] * len(alice), eps=0.5, T=20, to_return='pct_ans', count_threshold=thresh)['A']\n",
    "\n",
    "            if(AwoB != 0 and BwoA != 0):\n",
    "                if mode=='utility':        \n",
    "                    # prevent divide by 0 error, ignore\n",
    "                    max_ratio_p_lst.append(p)\n",
    "                    BwA_lst.append(BwA)\n",
    "                    BwoA_lst.append(BwoA)\n",
    "                    AwB_lst.append(AwB)\n",
    "                    AwoB_lst.append(AwoB)\n",
    "                if mode=='error':        \n",
    "                    # prevent divide by 0 error, ignore\n",
    "                    max_ratio_p_lst.append(p)\n",
    "                    BwA_lst.append(100 - BwA)\n",
    "                    BwoA_lst.append(100 - BwoA)\n",
    "                    AwB_lst.append(100 - AwB)\n",
    "                    AwoB_lst.append(100 - AwoB)\n",
    "                \n",
    "\n",
    "    for i in range(iterations):\n",
    "        if i in list(range(0, 3001, 50)): \n",
    "            print(f'{i} iterations have passed')\n",
    "        for p in [i / 100 for i in range(50, 101, 10)]:\n",
    "            calc_max_ratio(p, thresh=input_thresh, workload=version)\n",
    "\n",
    "    df_max_ratio = pd.DataFrame(list(zip(max_ratio_p_lst, BwA_lst, BwoA_lst, AwB_lst, AwoB_lst)), \n",
    "                                             columns =['p', 'BwA', 'BwoA', 'AwB', 'AwoB'])\n",
    "    return df_max_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea28a20",
   "metadata": {},
   "source": [
    "# Disjoint Max Ratio Error\n",
    "Date: May-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652364a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iterations have passed\n"
     ]
    }
   ],
   "source": [
    "df_max_ratio_disjoint = get_max_ratio_df(version='disjoint', \n",
    "                                         iterations=300, \n",
    "                                         input_thresh = 0.001, \n",
    "                                         mode='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3029311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove zeros\n",
    "df_max_ratio_disjoint = df_max_ratio_disjoint[(df_max_ratio_disjoint != 0).all(1)]\n",
    "\n",
    "df_max_ratio_disjoint['A_MRE'] = df_max_ratio_disjoint['AwB'] / df_max_ratio_disjoint['AwoB']\n",
    "df_max_ratio_disjoint['B_MRE'] = df_max_ratio_disjoint['BwA'] / df_max_ratio_disjoint['BwoA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7dbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MRE = pd.melt(df_max_ratio_disjoint, id_vars='p', \n",
    "                 #value_vars=['AwB', 'AwoB', 'BwA', 'BwoA'])\n",
    "                 value_vars=['A_MRE','B_MRE'])\n",
    "\n",
    "df_MRE\n",
    "\n",
    "ax = sns.lineplot(data=df_MRE, \n",
    "             x=\"p\", \n",
    "             y=\"value\",\n",
    "             hue=\"variable\",\n",
    "             lw=5)\n",
    "\n",
    "#plt.legend([],[], frameon=False)\n",
    "ax.axhline(1, lw = 5, ls='--', color='black')\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "sns.despine()\n",
    "\n",
    "ax.set_xticks([0.5, 0.75, 1])\n",
    "#ax.set_ylim([.65, 1])\n",
    "ax.set_xlim([.5, 1.1])\n",
    "#ax.set_yticks([1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "artifacts_path = '/Users/albertsun/Projects/artifacts/'\n",
    "\n",
    "#txt=\"Run on practical workloads with t=500 trials each \\nusing Private Multiplicative Weights (Hardt 2010)\"\n",
    "#plt.figtext(0.53, -0.05, txt, wrap=True, horizontalalignment='left', fontsize=15)\n",
    "\n",
    "plt.savefig(artifacts_path + \"MotivatingMRE_05.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
