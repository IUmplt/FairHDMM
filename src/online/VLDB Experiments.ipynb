{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4090fe",
   "metadata": {},
   "source": [
    "# VLDB Experiments\n",
    "In this Jupyter Notebook, I wish to conduct the following experiments for VLDB.\n",
    "\n",
    "Edited: May 23, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb0649",
   "metadata": {},
   "source": [
    "Let's design the experiments we're going to use for VLDB with the following varying configs: \n",
    "- p = 0.1, 0.5, 1\n",
    "- Algos = PMW, PMW (random scheduler), PMW, PMW (Round Robin) and Seeded C&R\n",
    "- Measures = Total Utility, Max Ratio, Empirical Interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38945387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.hdmm.error import expected_error, strategy_supports_workload\n",
    "from src.hdmm.matrix import EkteloMatrix\n",
    "from typing import Tuple\n",
    "import string\n",
    "import random\n",
    "from itertools import cycle, islice\n",
    "import src.hdmm.workload as workload\n",
    "import src.census_workloads as census\n",
    "from src.workload_selection import workload_selection\n",
    "import online_workloads as online_workloads\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from src.hdmm.workload import AllRange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84825da3",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "The following are the algorithms that we wish to implement. They are Private Multiplicative Weights and Cache and Reconstruct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5b282",
   "metadata": {},
   "source": [
    "### 1. PMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c37ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw_naive(workload, x, analyst_labels, T, eps=0.01, total_k=None, \n",
    "         show_messages=False, to_return='error', show_plot=False, show_failure_step=False, eta = None,\n",
    "             count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries where analysts can run out of privacy budget if they use too much of others'. \n",
    "    \n",
    "    In other words, all analysts share from the same privacy budget. \n",
    "    \n",
    "    Last Updated: 4-23-2022\n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - total_k = total number of update steps alloted for the entire group\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'error', pmw() returns a dictionary for the average absolute error for each analyst\n",
    "        - if 'pct_ans', pmw() returns a dictionary for the percent of queries answered that meets\n",
    "        the accuracy threshold set by count_threshold\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    - count_threshold - this is for the to_return = 'pct_ans' setting. It is the min error threshold \n",
    "    that a query answer for us to count the answer as \"reasonable\" as opposed to \"bot\". The default\n",
    "    is 0.1. This functions as another way to  measure the accuracy of the queries that is more similar \n",
    "    to how our other functions; i.e., cache and reconstruct either returns an accurate answer or \"bot\".\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    if(eta == None):\n",
    "        eta = (math.log(m, np.e) / ((math.sqrt(n))) )\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    # initialize total_k, the total number of update steps if not default\n",
    "    if total_k == None:\n",
    "        total_k = round(n * math.log(math.sqrt(m)) / 770) #770\n",
    "        #print(f'{total_k=}')\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        answer = np.dot(query, x_list[time])\n",
    "        if answer < 0:\n",
    "            pmw_answers.append(0)\n",
    "        else: \n",
    "            pmw_answers.append(answer)\n",
    "        x_list.append(x_list[time])\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    #print(rho + T)\n",
    "    \n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique; compute noisy answer by adding Laplacian noise\n",
    "        A_t = np.random.laplace(loc=0, scale=(total_k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # LAZY ROUND: QUERY USING THE SYNTHETIC DATABASE\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "\n",
    "        # UPDATE ROUND: UPDATE SYNTHETIC DATABASE AND RETURN NOISY ANSWER, A_T-HAT\n",
    "        else:\n",
    "            # noise\n",
    "            A_t = np.random.laplace(loc=0, scale=(2*total_k/eps), size=1)[0]\n",
    "            \n",
    "            # noisy answer\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i in range(len(y_t)):\n",
    "                y_t[i] = x_list[time][i] * math.exp(-( eta * r_t[i]))# eta is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if total_k == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t)\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                answer = a_t_hat / np.sum(x)\n",
    "                \n",
    "                if answer < 0:\n",
    "                    pmw_answers.append(0)\n",
    "                else: \n",
    "                    pmw_answers.append(answer)\n",
    "                \n",
    "                total_k -= 1 # use one of the total update steps\n",
    "        \n",
    "        #print(f'{x_list[time] - x_list[time - 1]=}')\n",
    "        \n",
    "        \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Synthetic Database (after) = {x_list[len(x_list) - 1] * sum(x)}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Synthetic Database (before) = {x_list[0]}\\n')\n",
    "        print(f'Synthetic Database (after, norm) = {x_list[len(x_list) - 1]}\\n')\n",
    "        print(f'Difference btw. Final Synthetic and true database = {x_list[len(x_list) - 1] - x_norm}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*total_k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*total_k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        #test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"tse\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data['squared_err'] = data['abs_error'] ** 2\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"num_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        num_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            num_answered[analyst] = data[(data['abs_error'] < count_threshold) & (data.analyst==analyst)]['abs_error'].count()\n",
    "        return num_answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6694486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 4, 'B': 6}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pmw_independent: write pmw for one person. \n",
    "# create wrapper function called pmw_independent() that takes in the workloads and workload labels. Run PMW for each analyst, separate their workloads based on analysts. \n",
    "\n",
    "def pmw_independent(w, input_x, labs, input_T, input_eps=0.01, input_k=None, input_to_return='num_ans'):\n",
    "    \"\"\"\n",
    "    Wrapper function that calls pmw2() to simulate PMW for each independent person. \n",
    "    \n",
    "    Takes a stream of workloads and analyst labels and separates them into distinct workloads for each analyst. \n",
    "    Runs pmw_naive() on that particular workload for each analyst. Returns a dictionary of percent answered\n",
    "    \"\"\"\n",
    "    indices = {} # k: analyst, v: row indices of queries in the workloads\n",
    "    for i, analyst in enumerate(labs):\n",
    "        if analyst not in indices.keys(): \n",
    "            indices[analyst] = []\n",
    "        indices[analyst].append(i)\n",
    "\n",
    "    workloads = {} # k: analyst, v: the analyst's workload\n",
    "    for analyst in indices.keys():\n",
    "        workloads[analyst] = w[indices[analyst], :]\n",
    "    #print(workloads)\n",
    "\n",
    "    all_analyst_error_dic = {}\n",
    "    \n",
    "    for analyst in workloads.keys():\n",
    "        single_analyst_error = pmw_naive(workload=workloads[analyst], \n",
    "                                    eps=input_eps,\n",
    "                                    x=input_x, \n",
    "                                    T=input_T, \n",
    "                                    total_k = input_k,\n",
    "                                    analyst_labels=[analyst]*len(workloads[analyst]), \n",
    "                                    to_return=input_to_return,\n",
    "                                    count_threshold=0.01,\n",
    "                                    show_messages=False)\n",
    "        all_analyst_error_dic.update(single_analyst_error)\n",
    "    return all_analyst_error_dic\n",
    "\n",
    "pmw_independent(np.vstack((online_workloads.identity(5), \n",
    "                           online_workloads.identity(5))), \n",
    "                input_x=np.array([1, 1, 1, 1, 1]), \n",
    "                input_T=40, \n",
    "                input_eps=1, \n",
    "                labs=['A'] * 2 + ['B'] * 6 + ['A'] * 2, \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbb3df",
   "metadata": {},
   "source": [
    "### 2. Cache and Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5ab26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(query, storage, ans, error):\n",
    "    \"\"\"caches query into a dictionary with values of (ans, error)\"\"\"\n",
    "    storage[np.array2string(query)] = (ans, error)\n",
    "    return storage\n",
    "    \n",
    "def is_reusable(query, storage):\n",
    "    \"\"\"returns whether or not a query is in a strategy matrix \n",
    "    (cache)\"\"\"\n",
    "    return np.array2string(query) in storage\n",
    "\n",
    "def reuse(query, storage):\n",
    "    \"\"\"returns tuple with (query answer, error) stored in \n",
    "    a storage dictionary\"\"\"\n",
    "    return storage[np.array2string(query)]\n",
    "\n",
    "def cache_and_reconstruct(workload, x, eps=0.01, k=0, analyst_labels=[], to_return = \"pd\", count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Seeded Cache and Reconstruct algorithm. \n",
    "    \n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    numAnalysts = len(budgets)\n",
    "    error_list = []\n",
    "    laplace_list = [] # if the algorithm simply added noise to the answer\n",
    "    used_reconstruct_list = []\n",
    "    used_reuse_list = []\n",
    "    \n",
    "    storage = {} # storage dictionary for reuse, k: query,v: error\n",
    "    strategy = workload[0:0] # workload matrix for reconstruction, \n",
    "    # make strategy = empty workload to create matrix of same dtype to be used in reconstruct step (avoid error)\n",
    "    \n",
    "    n = x.sum()\n",
    "    x_norm = x/sum(x) # normalize database\n",
    "    \n",
    "    def add_to_strategy(query, strategy):\n",
    "        \"\"\"Append query to the end fo the strategy matrix\"\"\"\n",
    "        return np.concatenate((strategy, query), axis = 0)\n",
    "    \n",
    "    for i, query in enumerate(workload): \n",
    "        query = np.expand_dims(query, axis = 0)\n",
    "        analyst = analyst_labels[i]\n",
    "        \n",
    "        # If query has answered before, then use old query answer\n",
    "        if is_reusable(query, storage): \n",
    "            abs_error = reuse(query, storage)\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            used_reconstruct_list.append(False) \n",
    "            laplace_list.append(False)\n",
    "            used_reuse_list.append(True)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst still has update steps left\n",
    "        elif budgets[analyst] > 0: \n",
    "            noise = np.random.laplace(0, (k * numAnalysts) / (n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            abs_error = np.abs(noisy_ans - true_ans)[0]\n",
    "            \n",
    "            error_list.append(abs_error) # *n\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            budgets[analyst] -= 1 \n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            laplace_list.append(True)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "        \n",
    "        # If query is reconstructable, then reconstruct\n",
    "        elif strategy_supports_workload(EkteloMatrix(query), EkteloMatrix(strategy)): # how to convert numpy array to ektelo matrix https://github.com/yikai-wu/Multi-Analyst-DP/blob/fadc7ac1d20199e8b31914f44323e51a05ed072d/src/hdmm/matrix.py#L34\n",
    "            \n",
    "            squared_error = expected_error(query, strategy, len(strategy) / (k * numAnalysts) * eps) # do i mult by 100\n",
    "            abs_error = math.sqrt(squared_error) / n #\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            error_list.append(abs_error)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(True) \n",
    "            used_reuse_list.append(False)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst ran out of update steps\n",
    "        else: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "            \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': error_list,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) & \n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered\n",
    "    \n",
    "    if to_return == \"num_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': error_list,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        num_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            num_answered[analyst] = data[(data['abs_error'] < count_threshold) & (data.analyst==analyst)]['abs_error'].count()\n",
    "        return num_answered\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        d = {'queries': workload.tolist(), \n",
    "            'abs_error': error_list,\n",
    "            'used_reconstruct': used_reconstruct_list,\n",
    "            'used_reuse': used_reuse_list,\n",
    "            'laplace': laplace_list,\n",
    "            'analyst': analyst_labels,\n",
    "        }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data = test_data.round(3)\n",
    "        test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ed48d",
   "metadata": {},
   "source": [
    "# Schedulers\n",
    "The following are the schedulers that we will use. There are 2 schedulers: random scheduler and round robin scheduler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478b7ea",
   "metadata": {},
   "source": [
    "### 1. Random Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f4471",
   "metadata": {},
   "source": [
    "Create a scheduler that schedules Alice's queries with a probability of p and all other analysts' queries with a probability of (1 - p) / (number of analysts - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd1b2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scheduler(analysts: list, workloads: list, p : int = 0.1) -> Tuple: \n",
    "    \"\"\"\n",
    "    In a system with n analysts, this system schedules Alice's queries with a probability of p and \n",
    "    other analysts' queries with an equal probability of (1 - p) / (n - 1), i.e. uniform probability.\n",
    "    \n",
    "    Returns new workload of queries (2D np.array) and analyst labels (list) that label each query in the \n",
    "    new workload. \n",
    "    \n",
    "    Takes: \n",
    "    - analysts: list of analyst names\n",
    "    - workloads: list of workloads in order where analyst[i] has workloads[i]\n",
    "    - p: probability that Alice has her query answered at any given step\n",
    "    \n",
    "    Returns: \n",
    "    - W_final: final workload\n",
    "    - analyst_labels: labels the final workload where analyst_labels[i] is the analyst with query at W_final[i]\n",
    "    \n",
    "    Date: 5-27-2022\n",
    "    \"\"\"\n",
    "\n",
    "    workloads_dict = dict(zip(analysts, workloads))\n",
    "\n",
    "    # gives alice p, all other analysts equal weight left\n",
    "    weights = [p if analyst=='a' else (1-p)/(len(analysts) - 1) for analyst in analysts] \n",
    "    # points the query that analyst is at, e.g., {'a': 0, 'b': 0, ...}\n",
    "    pointers = {analyst: 0 for analyst in analysts}\n",
    "\n",
    "    num_queries_left = {analyst: len(workloads_dict[analyst]) for analyst in analysts}\n",
    "\n",
    "    ordering = random.choices(analysts, weights, k=5000)\n",
    "    iterator = cycle(ordering)\n",
    "    \n",
    "    W = []\n",
    "    analyst_labels = []\n",
    "\n",
    "    for analyst in iterator: \n",
    "        if num_queries_left[analyst] > 0: \n",
    "            # add query to the workload\n",
    "            pointer = pointers[analyst]\n",
    "            W.append(workloads_dict[analyst][pointer])\n",
    "            analyst_labels.append(analyst)\n",
    "\n",
    "            num_queries_left[analyst] -= 1\n",
    "            pointers[analyst] += 1\n",
    "        if sum(num_queries_left.values()) == 0: # if no more queries left to ask\n",
    "            break\n",
    "\n",
    "    W_final = np.array(W)\n",
    "    #list(zip(analyst_labels, W_final))\n",
    "    return W_final, analyst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9501c3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]),\n",
       " ['i',\n",
       "  'a',\n",
       "  'b',\n",
       "  'g',\n",
       "  'a',\n",
       "  'c',\n",
       "  'f',\n",
       "  'f',\n",
       "  'h',\n",
       "  'h',\n",
       "  'e',\n",
       "  'e',\n",
       "  'c',\n",
       "  'g',\n",
       "  'b',\n",
       "  'j',\n",
       "  'j',\n",
       "  'd',\n",
       "  'd',\n",
       "  'i'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test random_scheduler(): \n",
    "analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "a = np.array([[1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "c = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "d = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "e = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "f = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "g = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "h = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "i = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "j = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "workloads = [a, b, c, d, e, f, g, h, i, j]\n",
    "\n",
    "random_scheduler(analysts, workloads, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aafc4d",
   "metadata": {},
   "source": [
    "### 2. Round Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49beaa6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    num_active = len(iterables)\n",
    "    nexts = cycle(iter(it).__next__ for it in iterables)\n",
    "    while num_active:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            # Remove the iterator we just exhausted from the cycle.\n",
    "            num_active -= 1\n",
    "            nexts = cycle(islice(nexts, num_active))\n",
    "\n",
    "def rr_scheduler(analysts: list, workloads: list) -> Tuple:\n",
    "    \"\"\"\n",
    "    Adapting itertools' roundrobin() code to np workloads and analyst labels. \n",
    "    \n",
    "    Takes two parallel lists: \n",
    "    - analysts - list of each analyst \n",
    "    - workloads - list of each workload; analysts[i] owns workloads[i]\n",
    "    \n",
    "    Returns Tuple of two parallel lists: \n",
    "    - analyst_labels - list of shuffled analyst labels s.t. analyst_labels[i] owns final_workload[i] query \n",
    "    - final_workload - np.array shuffled workload\n",
    "    \"\"\"\n",
    "    analyst_labels = list(roundrobin(*[[analysts[i]] * len(workloads[i]) for i in range(len(analysts))]))\n",
    "    final_workload = np.vstack(list(roundrobin(*workloads)))\n",
    "    \n",
    "    return final_workload, analyst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743fd580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0]]),\n",
       " ['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'd'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test rr_scheduler():\n",
    "\n",
    "analysts = ['a', 'b', 'c', 'd']\n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "d = np.array([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])\n",
    "workloads = [a, b, c, d]\n",
    "\n",
    "rr_scheduler(analysts, workloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc54ed8",
   "metadata": {},
   "source": [
    "# Tests\n",
    "The following are test case workloads that I built to ensure that the schedulers were working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15752b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cases: \n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "\n",
    "# round robin would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 1 would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 0 would return: \n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "\n",
    "# skewed scheduler with p = 0.333 would return something similar to round robin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43acffd4",
   "metadata": {},
   "source": [
    "# 5-27 (Top Left Corner)\n",
    "\n",
    "First, let's start doing one box (the top left corner). For p = 0.1, let's find the total utility for PMW (random scheduler), PMW (Round Robin) and Seeded C&R. Let's do this 500 times for PMWRS, PMWRR, and SCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "329e4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workload parameters\n",
    "n=64\n",
    "W_name = ['identity', 'H2', 'race1', 'race2', 'race3', 'custom', 'prefix_sum']#, 'total',]\n",
    "W_lst = [online_workloads.identity(n), online_workloads.H2(n), online_workloads.race1(), online_workloads.race2(), online_workloads.race3(), online_workloads.custom(n), online_workloads.prefix_sum(n),] # online_workloads.total(n),]\n",
    "\n",
    "# database\n",
    "data_path = \"migration_tworace.csv\"\n",
    "x_race = pd.read_csv(data_path, header=None).to_numpy().T[1] \n",
    "database = np.concatenate([x_race[:32], x_race[:32]]) # truncate for the first 32 twice for symmetry purposes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e45e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vldb_exp(p_list = [0.1, 0.5, 0.9], t = 10, epsilon = 1):\n",
    "    \"\"\"\n",
    "    Run VLDB experiments. Implement the following algs. Return dictionary of dataframes\n",
    "    of the following experiments in different settings of p (probability that Alice has \n",
    "    her query answered at any time step):\n",
    "    - PMW (BL*: independent, strawman arg, generally a bad idea to prove our alg is better), \n",
    "    - PMW (OPT*: optimal in terms of overall error, we don’t care about desiderata, no changes)\n",
    "    - Seeded C&R\n",
    "    - PMW (Randomized Scheduler, p is always 0.1)\n",
    "    - PMW (RR*, always the same) \n",
    "    \"\"\"\n",
    "    test_data_dics = {}\n",
    "    \n",
    "    for p in p_list:\n",
    "        bl_pctans = []\n",
    "        rr_pctans = []\n",
    "        rs_pctans = []\n",
    "        opt_pctans = []\n",
    "        cr_pctans = []\n",
    "        for i in range(10):\n",
    "            # 1. generate workloads\n",
    "            # generate 10 workloads, one for each analyst\n",
    "            c = np.random.randint(len(W_lst))\n",
    "            analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "            workloads = [W_lst[c] for i in analysts]\n",
    "\n",
    "            # 2. use each algorithm\n",
    "\n",
    "            # bl - independent pmw, strawman arg\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, p) # random ordering\n",
    "            bl_pctans_dict = pmw_independent(W, \n",
    "                                             input_x=database, \n",
    "                                             input_T=40, \n",
    "                                             input_eps=epsilon/len(analysts), \n",
    "                                             labs=analyst_labels)\n",
    "            bl_pctans.append(sum(bl_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # opt - pmw with skewed ordering based on p\n",
    "            opt_pctans_dict = pmw_naive(W, \n",
    "                                        database, \n",
    "                                        analyst_labels, \n",
    "                                        eps=epsilon, \n",
    "                                        T=40, \n",
    "                                        to_return='pct_ans', \n",
    "                                        count_threshold=0.01)\n",
    "            opt_pctans.append(sum(opt_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # cr - c&r with skewed ordering based on p\n",
    "            cr_pctans_dict = cache_and_reconstruct(W, \n",
    "                                                   database, \n",
    "                                                   epsilon, \n",
    "                                                   5, \n",
    "                                                   analyst_labels, \n",
    "                                                   to_return = \"pct_ans\", \n",
    "                                                   count_threshold=0.01)\n",
    "            cr_pctans.append(sum(cr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rs - random scheduler, p is always 0.1\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, 0.1)\n",
    "            rs_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       to_return='pct_ans', \n",
    "                                       count_threshold=0.01)\n",
    "            rs_pctans.append(sum(rs_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rr - pmw with round robin ordering\n",
    "            W, analyst_labels = rr_scheduler(analysts, workloads)\n",
    "            rr_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       to_return='pct_ans',\n",
    "                                       count_threshold=0.01)\n",
    "            rr_pctans.append(sum(rr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "\n",
    "        d = {'bl': bl_pctans,\n",
    "             'opt': opt_pctans,\n",
    "             'cr': cr_pctans,\n",
    "             'rs': rs_pctans,\n",
    "            'rr': rr_pctans,\n",
    "            }\n",
    "\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data_dics[p] = test_data\n",
    "\n",
    "    return test_data_dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecabaae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dics = vldb_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065a996b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1:           bl        opt          cr          rs         rr\n",
       " 0  36.850394  43.700787   63.700787   43.228346  40.866142\n",
       " 1  30.468750  26.406250   49.843750   27.031250  25.781250\n",
       " 2  48.714286  67.000000   48.428571   68.000000  67.000000\n",
       " 3  37.322835  42.519685   65.669291   43.858268  41.574803\n",
       " 4  44.687500  73.125000   56.093750   72.812500  68.125000\n",
       " 5  38.571429  94.285714   98.571429  100.000000  97.142857\n",
       " 6  30.312500  26.093750   51.093750   27.500000  25.937500\n",
       " 7  28.750000  50.625000   78.750000   48.958333  41.666667\n",
       " 8  45.857143  68.428571   51.142857   68.571429  65.428571\n",
       " 9  10.000000  70.000000  100.000000   90.000000  90.000000,\n",
       " 0.5:           bl         opt          cr         rs         rr\n",
       " 0  20.000000   90.000000  100.000000  90.000000  60.000000\n",
       " 1  20.000000   97.142857  100.000000  95.714286  97.142857\n",
       " 2  49.000000   66.857143   45.714286  67.142857  65.142857\n",
       " 3  20.000000  100.000000  100.000000  90.000000  90.000000\n",
       " 4  40.000000   80.000000  100.000000  90.000000  80.000000\n",
       " 5  45.625000   70.937500   52.968750  71.718750  70.000000\n",
       " 6  27.708333   50.833333   65.208333  47.708333  45.416667\n",
       " 7  27.500000   27.812500   57.031250  28.125000  26.093750\n",
       " 8  28.750000   51.666667   77.083333  49.791667  43.125000\n",
       " 9  40.000000   98.571429   98.571429  95.714286  94.285714,\n",
       " 0.9:           bl         opt          cr         rs         rr\n",
       " 0  48.142857   74.142857   48.142857  68.142857  64.857143\n",
       " 1  31.428571   98.571429   97.142857  97.142857  92.857143\n",
       " 2  20.000000  100.000000  100.000000  80.000000  90.000000\n",
       " 3  45.000000   71.406250   47.500000  72.031250  68.125000\n",
       " 4  34.062500   33.437500   46.718750  26.875000  27.187500\n",
       " 5  30.000000  100.000000  100.000000  80.000000  90.000000\n",
       " 6  28.750000   35.000000   48.437500  26.562500  27.187500\n",
       " 7  44.843750   71.250000   48.750000  73.125000  70.312500\n",
       " 8  47.343750   71.406250   46.562500  71.875000  68.125000\n",
       " 9  43.437500   71.406250   50.312500  72.031250  68.281250}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a795f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vldb_exp_new(p_list = [0.1, 0.5, 0.9], t = 10, epsilon = 1):\n",
    "    \"\"\"\n",
    "    Run VLDB experiments. Implement the following algs. Return dictionary of dataframes\n",
    "    of the following experiments in different settings of p (probability that Alice has \n",
    "    her query answered at any time step):\n",
    "    - PMW (BL*: independent, strawman arg, generally a bad idea to prove our alg is better), \n",
    "    - PMW (OPT*: optimal in terms of overall error, we don’t care about desiderata, no changes)\n",
    "    - Seeded C&R\n",
    "    - PMW (Randomized Scheduler, p is always 0.1)\n",
    "    - PMW (RR*, always the same) \n",
    "    \n",
    "    Last updated: June 16, 2022\n",
    "    \"\"\"\n",
    "    df_dic = {}\n",
    "    \n",
    "    def save_value(alg, p, val):\n",
    "        \"\"\"\n",
    "        Helper function to save the value of the calculation into the dictionary df_dic\n",
    "        \"\"\"\n",
    "        if f'{alg}{p}' not in df_dic:\n",
    "            df_dic[f'{alg}{p}'] = []\n",
    "        df_dic[f'{alg}{p}'].append(val)\n",
    "    \n",
    "    for i in range(t):\n",
    "        # 1. generate workloads\n",
    "        # generate 10 workloads, one for each analyst\n",
    "        c = np.random.randint(len(W_lst))\n",
    "        analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "        workloads = [random.choice(W_lst) for i in analysts] # different workload for each analyst\n",
    "        \n",
    "        for p in p_list:\n",
    "            \n",
    "            # 2. use each algorithm\n",
    "\n",
    "            # bl - independent pmw, strawman arg\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, p) # random ordering\n",
    "            bl_pctans_dict = pmw_independent(W, \n",
    "                                             input_x=database, \n",
    "                                             input_T=40, \n",
    "                                             input_eps=epsilon/len(analysts), \n",
    "                                             labs=analyst_labels,\n",
    "                                             input_to_return=\"num_ans\")\n",
    "            save_value('Ind', p, sum(bl_pctans_dict.values()) / len(analysts))\n",
    "            \n",
    "            # opt - pmw with skewed ordering based on p\n",
    "            opt_pctans_dict = pmw_naive(W, \n",
    "                                        database, \n",
    "                                        analyst_labels, \n",
    "                                        eps=epsilon, \n",
    "                                        T=40, \n",
    "                                        to_return='num_ans', \n",
    "                                        count_threshold=0.01)\n",
    "            save_value('PMW', p, sum(opt_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # cr - c&r with skewed ordering based on p\n",
    "            cr_pctans_dict = cache_and_reconstruct(W, \n",
    "                                                   database, \n",
    "                                                   epsilon, \n",
    "                                                   5, \n",
    "                                                   analyst_labels, \n",
    "                                                   to_return = \"num_ans\", \n",
    "                                                   count_threshold=0.01)\n",
    "            save_value('SCR', p, sum(cr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rs - random scheduler, p is always 0.1\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, 0.1)\n",
    "            rs_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       to_return='num_ans', \n",
    "                                       count_threshold=0.01)\n",
    "            save_value('RS', p, sum(rs_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rr - pmw with round robin ordering\n",
    "            W, analyst_labels = rr_scheduler(analysts, workloads)\n",
    "            rr_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       to_return='num_ans',\n",
    "                                       count_threshold=0.01)\n",
    "            save_value('RR', p, sum(rr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "        test_data = pd.DataFrame(data=df_dic)\n",
    "        print(f'Epoch {i} complete')\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "53af788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n",
      "Epoch 10 complete\n",
      "Epoch 11 complete\n",
      "Epoch 12 complete\n",
      "Epoch 13 complete\n",
      "Epoch 14 complete\n",
      "Epoch 15 complete\n",
      "Epoch 16 complete\n",
      "Epoch 17 complete\n",
      "Epoch 18 complete\n",
      "Epoch 19 complete\n",
      "Epoch 20 complete\n",
      "Epoch 21 complete\n",
      "Epoch 22 complete\n",
      "Epoch 23 complete\n",
      "Epoch 24 complete\n",
      "Epoch 25 complete\n",
      "Epoch 26 complete\n",
      "Epoch 27 complete\n",
      "Epoch 28 complete\n",
      "Epoch 29 complete\n",
      "Epoch 30 complete\n",
      "Epoch 31 complete\n",
      "Epoch 32 complete\n",
      "Epoch 33 complete\n",
      "Epoch 34 complete\n",
      "Epoch 35 complete\n",
      "Epoch 36 complete\n",
      "Epoch 37 complete\n",
      "Epoch 38 complete\n",
      "Epoch 39 complete\n",
      "Epoch 40 complete\n",
      "Epoch 41 complete\n",
      "Epoch 42 complete\n",
      "Epoch 43 complete\n",
      "Epoch 44 complete\n",
      "Epoch 45 complete\n",
      "Epoch 46 complete\n",
      "Epoch 47 complete\n",
      "Epoch 48 complete\n",
      "Epoch 49 complete\n",
      "Epoch 50 complete\n",
      "Epoch 51 complete\n",
      "Epoch 52 complete\n",
      "Epoch 53 complete\n",
      "Epoch 54 complete\n",
      "Epoch 55 complete\n",
      "Epoch 56 complete\n",
      "Epoch 57 complete\n",
      "Epoch 58 complete\n",
      "Epoch 59 complete\n",
      "Epoch 60 complete\n",
      "Epoch 61 complete\n",
      "Epoch 62 complete\n",
      "Epoch 63 complete\n",
      "Epoch 64 complete\n",
      "Epoch 65 complete\n",
      "Epoch 66 complete\n",
      "Epoch 67 complete\n",
      "Epoch 68 complete\n",
      "Epoch 69 complete\n",
      "Epoch 70 complete\n",
      "Epoch 71 complete\n",
      "Epoch 72 complete\n",
      "Epoch 73 complete\n",
      "Epoch 74 complete\n",
      "Epoch 75 complete\n",
      "Epoch 76 complete\n",
      "Epoch 77 complete\n",
      "Epoch 78 complete\n",
      "Epoch 79 complete\n",
      "Epoch 80 complete\n",
      "Epoch 81 complete\n",
      "Epoch 82 complete\n",
      "Epoch 83 complete\n",
      "Epoch 84 complete\n",
      "Epoch 85 complete\n",
      "Epoch 86 complete\n",
      "Epoch 87 complete\n",
      "Epoch 88 complete\n",
      "Epoch 89 complete\n",
      "Epoch 90 complete\n",
      "Epoch 91 complete\n",
      "Epoch 92 complete\n",
      "Epoch 93 complete\n",
      "Epoch 94 complete\n",
      "Epoch 95 complete\n",
      "Epoch 96 complete\n",
      "Epoch 97 complete\n",
      "Epoch 98 complete\n",
      "Epoch 99 complete\n",
      "Epoch 100 complete\n",
      "Epoch 101 complete\n",
      "Epoch 102 complete\n",
      "Epoch 103 complete\n",
      "Epoch 104 complete\n",
      "Epoch 105 complete\n",
      "Epoch 106 complete\n",
      "Epoch 107 complete\n",
      "Epoch 108 complete\n",
      "Epoch 109 complete\n",
      "Epoch 110 complete\n",
      "Epoch 111 complete\n",
      "Epoch 112 complete\n",
      "Epoch 113 complete\n",
      "Epoch 114 complete\n",
      "Epoch 115 complete\n",
      "Epoch 116 complete\n",
      "Epoch 117 complete\n",
      "Epoch 118 complete\n",
      "Epoch 119 complete\n",
      "Epoch 120 complete\n",
      "Epoch 121 complete\n",
      "Epoch 122 complete\n",
      "Epoch 123 complete\n",
      "Epoch 124 complete\n",
      "Epoch 125 complete\n",
      "Epoch 126 complete\n",
      "Epoch 127 complete\n",
      "Epoch 128 complete\n",
      "Epoch 129 complete\n",
      "Epoch 130 complete\n",
      "Epoch 131 complete\n",
      "Epoch 132 complete\n",
      "Epoch 133 complete\n",
      "Epoch 134 complete\n",
      "Epoch 135 complete\n",
      "Epoch 136 complete\n",
      "Epoch 137 complete\n",
      "Epoch 138 complete\n",
      "Epoch 139 complete\n",
      "Epoch 140 complete\n",
      "Epoch 141 complete\n",
      "Epoch 142 complete\n",
      "Epoch 143 complete\n",
      "Epoch 144 complete\n",
      "Epoch 145 complete\n",
      "Epoch 146 complete\n",
      "Epoch 147 complete\n",
      "Epoch 148 complete\n",
      "Epoch 149 complete\n",
      "Epoch 150 complete\n",
      "Epoch 151 complete\n",
      "Epoch 152 complete\n",
      "Epoch 153 complete\n",
      "Epoch 154 complete\n",
      "Epoch 155 complete\n",
      "Epoch 156 complete\n",
      "Epoch 157 complete\n",
      "Epoch 158 complete\n",
      "Epoch 159 complete\n",
      "Epoch 160 complete\n",
      "Epoch 161 complete\n",
      "Epoch 162 complete\n",
      "Epoch 163 complete\n",
      "Epoch 164 complete\n",
      "Epoch 165 complete\n",
      "Epoch 166 complete\n",
      "Epoch 167 complete\n",
      "Epoch 168 complete\n",
      "Epoch 169 complete\n",
      "Epoch 170 complete\n",
      "Epoch 171 complete\n",
      "Epoch 172 complete\n",
      "Epoch 173 complete\n",
      "Epoch 174 complete\n",
      "Epoch 175 complete\n",
      "Epoch 176 complete\n",
      "Epoch 177 complete\n",
      "Epoch 178 complete\n",
      "Epoch 179 complete\n",
      "Epoch 180 complete\n",
      "Epoch 181 complete\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-7d23d9dc77d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvldb_exp_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-23561749fafa>\u001b[0m in \u001b[0;36mvldb_exp_new\u001b[0;34m(p_list, t, epsilon)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# cr - c&r with skewed ordering based on p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             cr_pctans_dict = cache_and_reconstruct(W, \n\u001b[0m\u001b[1;32m     57\u001b[0m                                                    \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                                    \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-93a216484891>\u001b[0m in \u001b[0;36mcache_and_reconstruct\u001b[0;34m(workload, x, eps, k, analyst_labels, to_return, count_threshold)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0msquared_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumAnalysts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# do i mult by 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mabs_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquared_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "test_data = vldb_exp_new(t=500)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850ea80",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04ad42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd3daac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifactspath = \"/Users/albertsun/Projects/artifacts/algexperiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d45591b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_1 = test_data.iloc[:,:5]\n",
    "test_data_1.columns = test_data_1.columns.str.rstrip(\"0.1\")\n",
    "ax = test_data_1.boxplot()\n",
    "ax.set_ylim(0, 50)\n",
    "#plt.title('Alice gets her queries \\nanswered with p = 0.1')\n",
    "#plt.ylabel('Queries Answered')\n",
    "#ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.savefig(artifactspath + '0.1acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c91045bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_2 = test_data.iloc[:,5:10]\n",
    "test_data_2.columns = test_data_2.columns.str.rstrip(\"0.5\")\n",
    "ax = test_data_2.boxplot()\n",
    "ax.set_ylim(0, 50)\n",
    "#plt.title('Alice gets her queries \\nanswered with p = 0.5')\n",
    "#plt.ylabel('Queries Answered')\n",
    "#ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.savefig(artifactspath + '0.5acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a43f2c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.9\n",
    "test_data_3 = test_data.iloc[:,10:15]\n",
    "test_data_3.columns = test_data_3.columns.str.rstrip(\"0.9\")\n",
    "ax = test_data_3.boxplot()\n",
    "ax.set_ylim(0, 50)\n",
    "#plt.title('Alice gets her queries \\nanswered with p = 0.9')\n",
    "#plt.ylabel('Queries Answered')\n",
    "#ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.savefig(artifactspath + '0.9acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f844df",
   "metadata": {},
   "source": [
    "Experiment parameters: \n",
    "- eps = 1, \n",
    "- count threshold = 0.01, \n",
    "- workload = random practical workload (identity, h2, census, etc.), \n",
    "- database = practical census size 64 database\n",
    "- exp run = 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24d355c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In PMW/C&R: code a to_return = \"first_analyst_err\", which represents the first analyst's error (aka. Alice's error)\n",
    "# Max Ratio: Alice's independent error / error with the collective\n",
    "    # PMW/C&R (Alice's workload/analyst label only, with 1/10 eps)\n",
    "    # PMW/C&R (whole workload)\n",
    "# Emp Int: CHOOSE ANLAYST WITH MAX ERROR: Error w random non-Alice / Error without random non-Alice\n",
    "    # PMW/C&R (whole workload)\n",
    "    # PMW/C&R (workload removing one random analyst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
