{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4090fe",
   "metadata": {},
   "source": [
    "# VLDB Experiments\n",
    "In this Jupyter Notebook, I wish to conduct the following experiments for VLDB.\n",
    "\n",
    "Edited: May 23, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb0649",
   "metadata": {},
   "source": [
    "Let's design the experiments we're going to use for VLDB with the following varying configs: \n",
    "- p = 0.1, 0.5, 1\n",
    "- Algos = PMW, PMW (random scheduler), PMW, PMW (Round Robin) and Seeded C&R\n",
    "- Measures = Total Utility, Max Ratio, Empirical Interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38945387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.hdmm.error import expected_error, strategy_supports_workload\n",
    "from src.hdmm.matrix import EkteloMatrix\n",
    "from typing import Tuple\n",
    "import string\n",
    "import random\n",
    "from itertools import cycle, islice\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from src.hdmm.workload import AllRange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84825da3",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "The following are the algorithms that we wish to implement. They are Private Multiplicative Weights and Cache and Reconstruct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5b282",
   "metadata": {},
   "source": [
    "### 1. PMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c37ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw_naive(workload, x, analyst_labels, T, eps=0.01, total_k=None, \n",
    "         show_messages=False, to_return='error', show_plot=False, show_failure_step=False, eta = None,\n",
    "             count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries where analysts can run out of privacy budget if they use too much of others'. \n",
    "    \n",
    "    In other words, all analysts share from the same privacy budget. \n",
    "    \n",
    "    Last Updated: 4-23-2022\n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - total_k = total number of update steps alloted for the entire group\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'error', pmw() returns a dictionary for the average absolute error for each analyst\n",
    "        - if 'pct_ans', pmw() returns a dictionary for the percent of queries answered that meets\n",
    "        the accuracy threshold set by count_threshold\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    - count_threshold - this is for the to_return = 'pct_ans' setting. It is the min error threshold \n",
    "    that a query answer for us to count the answer as \"reasonable\" as opposed to \"bot\". The default\n",
    "    is 0.1. This functions as another way to  measure the accuracy of the queries that is more similar \n",
    "    to how our other functions; i.e., cache and reconstruct either returns an accurate answer or \"bot\".\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    if(eta == None):\n",
    "        eta = (math.log(m, np.e) / ((math.sqrt(n))) )\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    # initialize total_k, the total number of update steps if not default\n",
    "    if total_k == None:\n",
    "        total_k = round(n * math.log(math.sqrt(m)) / 770) #770\n",
    "        #print(f'{total_k=}')\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        answer = np.dot(query, x_list[time])\n",
    "        if answer < 0:\n",
    "            pmw_answers.append(0)\n",
    "        else: \n",
    "            pmw_answers.append(answer)\n",
    "        x_list.append(x_list[time])\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    #print(rho + T)\n",
    "    \n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique; compute noisy answer by adding Laplacian noise\n",
    "        A_t = np.random.laplace(loc=0, scale=(total_k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # LAZY ROUND: QUERY USING THE SYNTHETIC DATABASE\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "\n",
    "        # UPDATE ROUND: UPDATE SYNTHETIC DATABASE AND RETURN NOISY ANSWER, A_T-HAT\n",
    "        else:\n",
    "            # noise\n",
    "            A_t = np.random.laplace(loc=0, scale=(2*total_k/eps), size=1)[0]\n",
    "            \n",
    "            # noisy answer\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i in range(len(y_t)):\n",
    "                y_t[i] = x_list[time][i] * math.exp(-( eta * r_t[i]))# eta is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if total_k == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t)\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                answer = a_t_hat / np.sum(x)\n",
    "                \n",
    "                if answer < 0:\n",
    "                    pmw_answers.append(0)\n",
    "                else: \n",
    "                    pmw_answers.append(answer)\n",
    "                \n",
    "                total_k -= 1 # use one of the total update steps\n",
    "        \n",
    "        #print(f'{x_list[time] - x_list[time - 1]=}')\n",
    "        \n",
    "        \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Synthetic Database (after) = {x_list[len(x_list) - 1] * sum(x)}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Synthetic Database (before) = {x_list[0]}\\n')\n",
    "        print(f'Synthetic Database (after, norm) = {x_list[len(x_list) - 1]}\\n')\n",
    "        print(f'Difference btw. Final Synthetic and true database = {x_list[len(x_list) - 1] - x_norm}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*total_k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*total_k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        #test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"tse\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data['squared_err'] = data['abs_error'] ** 2\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) & \n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbb3df",
   "metadata": {},
   "source": [
    "### 2. Cache and Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ab26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_and_reconstruct(workload, x, eps=0.01, k=0, analyst_labels=[]):\n",
    "    \"\"\"\n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    numAnalysts = len(budgets)\n",
    "    error_list = []\n",
    "    laplace_list = [] # if the algorithm simply added noise to the answer\n",
    "    used_reconstruct_list = []\n",
    "    used_reuse_list = []\n",
    "    \n",
    "    storage = {} # storage dictionary for reuse, k: query,v: error\n",
    "    strategy = workload[0:0] # workload matrix for reconstruction, \n",
    "    # make strategy = empty workload to create matrix of same dtype to be used in reconstruct step (avoid error)\n",
    "    \n",
    "    n = x.sum()\n",
    "    x_norm = x/sum(x) # normalize database\n",
    "    \n",
    "    def add_to_strategy(query, strategy):\n",
    "        \"\"\"Append query to the end fo the strategy matrix\"\"\"\n",
    "        return np.concatenate((strategy, query), axis = 0)\n",
    "    \n",
    "    for i, query in enumerate(workload): \n",
    "        query = np.expand_dims(query, axis = 0)\n",
    "        analyst = analyst_labels[i]\n",
    "        \n",
    "        # If query has answered before, then use old query answer\n",
    "        if is_reusable(query, storage): \n",
    "            abs_error = reuse(query, storage)\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            used_reconstruct_list.append(False) \n",
    "            laplace_list.append(False)\n",
    "            used_reuse_list.append(True)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst still has update steps left\n",
    "        elif budgets[analyst] > 0: \n",
    "            noise = np.random.laplace(0, (k * numAnalysts) / (n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            abs_error = np.abs(noisy_ans - true_ans)[0]\n",
    "            \n",
    "            error_list.append(abs_error) # *n\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            budgets[analyst] -= 1 \n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            laplace_list.append(True)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "        \n",
    "        # If query is reconstructable, then reconstruct\n",
    "        elif strategy_supports_workload(EkteloMatrix(query), EkteloMatrix(strategy)): # how to convert numpy array to ektelo matrix https://github.com/yikai-wu/Multi-Analyst-DP/blob/fadc7ac1d20199e8b31914f44323e51a05ed072d/src/hdmm/matrix.py#L34\n",
    "            \n",
    "            squared_error = expected_error(query, strategy, len(strategy) / (k * numAnalysts) * eps) # do i mult by 100\n",
    "            abs_error = math.sqrt(squared_error) / n #\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            error_list.append(abs_error)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(True) \n",
    "            used_reuse_list.append(False)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst ran out of update steps\n",
    "        else: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "        \n",
    "    d = {'queries': workload.tolist(), \n",
    "        'abs_error': error_list,\n",
    "        'used_reconstruct': used_reconstruct_list,\n",
    "        'used_reuse': used_reuse_list,\n",
    "        'laplace': laplace_list,\n",
    "        'analyst': analyst_labels,\n",
    "    }\n",
    "    test_data = pd.DataFrame(data=d)\n",
    "    test_data = test_data.round(3)\n",
    "    test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ed48d",
   "metadata": {},
   "source": [
    "# Schedulers\n",
    "The following are the schedulers that we will use. There are 2 schedulers: random scheduler and round robin scheduler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478b7ea",
   "metadata": {},
   "source": [
    "### 1. Random Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f4471",
   "metadata": {},
   "source": [
    "Create a scheduler that schedules Alice's queries with a probability of p and all other analysts' queries with a probability of (1 - p) / (number of analysts - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7483a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scheduler(analysts: list, workloads: list, p : int = 0.1) -> Tuple: \n",
    "    \"\"\"\n",
    "    In a system with n analysts, this system schedules Alice's queries with a probability of p and \n",
    "    other analysts' queries with an equal probability of (1 - p) / (n - 1), i.e. uniform probability.\n",
    "    \n",
    "    Returns new workload of queries (2D np.array) and analyst labels (list) that label each query in the \n",
    "    new workload. \n",
    "    \n",
    "    Takes: \n",
    "    - analysts: list of analyst names\n",
    "    - workloads: list of workloads in order where analyst[i] has workloads[i]\n",
    "    - p: probability that Alice has her query answered at any given step\n",
    "    \n",
    "    Returns: \n",
    "    - W_final: final workload\n",
    "    - analyst_labels: labels the final workload where analyst_labels[i] is the analyst with query at W_final[i]\n",
    "    \n",
    "    Date: 5-27-2022\n",
    "    \"\"\"\n",
    "\n",
    "    workloads_dict = dict(zip(analysts, workloads))\n",
    "\n",
    "    # gives alice p, all other analysts equal weight left\n",
    "    weights = [p if analyst=='a' else (1-p)/(len(analysts) - 1) for analyst in analysts] \n",
    "    # points the query that analyst is at, e.g., {'a': 0, 'b': 0, ...}\n",
    "    pointers = {analyst: 0 for analyst in analysts}\n",
    "\n",
    "    num_queries_left = {analyst: len(workloads_dict[analyst]) for analyst in analysts}\n",
    "\n",
    "    ordering = random.choices(analysts, weights, k=5000)\n",
    "    iterator = cycle(ordering)\n",
    "    \n",
    "    W = []\n",
    "    analyst_labels = []\n",
    "\n",
    "    for analyst in iterator: \n",
    "        if num_queries_left[analyst] > 0: \n",
    "            # add query to the workload\n",
    "            pointer = pointers[analyst]\n",
    "            W.append(workloads_dict[analyst][pointer])\n",
    "            analyst_labels.append(analyst)\n",
    "\n",
    "            num_queries_left[analyst] -= 1\n",
    "            pointers[analyst] += 1\n",
    "        if sum(num_queries_left.values()) == 0: # if no more queries left to ask\n",
    "            break\n",
    "\n",
    "    W_final = np.array(W)\n",
    "    #list(zip(analyst_labels, W_final))\n",
    "    return analyst_labels, W_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99742c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['h',\n",
       "  'c',\n",
       "  'a',\n",
       "  'j',\n",
       "  'a',\n",
       "  'g',\n",
       "  'c',\n",
       "  'e',\n",
       "  'b',\n",
       "  'd',\n",
       "  'b',\n",
       "  'g',\n",
       "  'h',\n",
       "  'd',\n",
       "  'e',\n",
       "  'i',\n",
       "  'i',\n",
       "  'f',\n",
       "  'f',\n",
       "  'j'],\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test random_scheduler(): \n",
    "analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "a = np.array([[1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "c = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "d = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "e = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "f = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "g = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "h = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "i = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "j = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "workloads = [a, b, c, d, e, f, g, h, i, j]\n",
    "\n",
    "random_scheduler(analysts, workloads, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aafc4d",
   "metadata": {},
   "source": [
    "### 2. Round Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49beaa6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    num_active = len(iterables)\n",
    "    nexts = cycle(iter(it).__next__ for it in iterables)\n",
    "    while num_active:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            # Remove the iterator we just exhausted from the cycle.\n",
    "            num_active -= 1\n",
    "            nexts = cycle(islice(nexts, num_active))\n",
    "\n",
    "def rr_scheduler(analysts: list, workloads: list) -> Tuple:\n",
    "    \"\"\"\n",
    "    Adapting itertools' roundrobin() code to np workloads and analyst labels. \n",
    "    \n",
    "    Takes two parallel lists: \n",
    "    - analysts - list of each analyst \n",
    "    - workloads - list of each workload; analysts[i] owns workloads[i]\n",
    "    \n",
    "    Returns Tuple of two parallel lists: \n",
    "    - analyst_labels - list of shuffled analyst labels s.t. analyst_labels[i] owns final_workload[i] query \n",
    "    - final_workload - np.array shuffled workload\n",
    "    \"\"\"\n",
    "    analyst_labels = list(roundrobin(*[[analysts[i]] * len(workloads[i]) for i in range(len(analysts))]))\n",
    "    final_workload = np.vstack(list(roundrobin(*workloads)))\n",
    "    \n",
    "    return analyst_labels, final_workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f423b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'd'],\n",
       " array([[1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test rr_scheduler():\n",
    "\n",
    "analysts = ['a', 'b', 'c', 'd']\n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "d = np.array([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])\n",
    "workloads = [a, b, c, d]\n",
    "\n",
    "rr_scheduler(analysts, workloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195951c8",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15752b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cases: \n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "\n",
    "# round robin would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 1 would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 0 would return: \n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "\n",
    "# skewed scheduler with p = 0.333 would return something similar to round robin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43acffd4",
   "metadata": {},
   "source": [
    "# 5-27 (Top Left Corner)\n",
    "\n",
    "First, let's start doing one box (the top left corner). For p = 0.1, let's find the total utility for PMW (random scheduler), PMW (Round Robin) and Seeded C&R. Let's do this 500 times for PMWRS, PMWRR, and SCAR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
