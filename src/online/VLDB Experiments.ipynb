{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLDB Experiments\n",
    "In this Jupyter Notebook, I wish to conduct the following experiments for VLDB.\n",
    "\n",
    "Edited: May 23, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's design the experiments we're going to use for VLDB with the following varying configs: \n",
    "- p = 0.1, 0.5, 1\n",
    "- Algos = PMW, PMW (random scheduler), PMW, PMW (Round Robin) and Seeded C&R\n",
    "- Measures = Total Utility, Max Ratio, Empirical Interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.hdmm.error import expected_error, strategy_supports_workload\n",
    "from src.hdmm.matrix import EkteloMatrix\n",
    "from typing import Tuple\n",
    "import string\n",
    "import random\n",
    "from itertools import cycle, islice\n",
    "import src.hdmm.workload as workload\n",
    "import src.census_workloads as census\n",
    "from src.workload_selection import workload_selection\n",
    "import src.online.online_workloads as online_workloads\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from src.hdmm.workload import AllRange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "The following are the algorithms that we wish to implement. They are Private Multiplicative Weights and Cache and Reconstruct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw_naive(workload, x, analyst_labels, T, eps=0.01, total_k=None, \n",
    "         show_messages=False, to_return='error', show_plot=False, show_failure_step=False, eta = None,\n",
    "             count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries where analysts can run out of privacy budget if they use too much of others'. \n",
    "    \n",
    "    In other words, all analysts share from the same privacy budget. \n",
    "    \n",
    "    Last Updated: 4-23-2022\n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - total_k = total number of update steps alloted for the entire group\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'error', pmw() returns a dictionary for the average absolute error for each analyst\n",
    "        - if 'pct_ans', pmw() returns a dictionary for the percent of queries answered that meets\n",
    "        the accuracy threshold set by count_threshold\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    - count_threshold - this is for the to_return = 'pct_ans' setting. It is the min error threshold \n",
    "    that a query answer for us to count the answer as \"reasonable\" as opposed to \"bot\". The default\n",
    "    is 0.1. This functions as another way to  measure the accuracy of the queries that is more similar \n",
    "    to how our other functions; i.e., cache and reconstruct either returns an accurate answer or \"bot\".\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    if(eta == None):\n",
    "        eta = (math.log(m, np.e) / ((math.sqrt(n))) )\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    # initialize total_k, the total number of update steps if not default\n",
    "    if total_k == None:\n",
    "        total_k = round(n * math.log(math.sqrt(m)) / 770) #770\n",
    "        #print(f'{total_k=}')\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        answer = np.dot(query, x_list[time])\n",
    "        if answer < 0:\n",
    "            pmw_answers.append(0)\n",
    "        else: \n",
    "            pmw_answers.append(answer)\n",
    "        x_list.append(x_list[time])\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    #print(rho + T)\n",
    "    \n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique; compute noisy answer by adding Laplacian noise\n",
    "        A_t = np.random.laplace(loc=0, scale=(total_k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # LAZY ROUND: QUERY USING THE SYNTHETIC DATABASE\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "\n",
    "        # UPDATE ROUND: UPDATE SYNTHETIC DATABASE AND RETURN NOISY ANSWER, A_T-HAT\n",
    "        else:\n",
    "            # noise\n",
    "            A_t = np.random.laplace(loc=0, scale=(2*total_k/eps), size=1)[0]\n",
    "            \n",
    "            # noisy answer\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i in range(len(y_t)):\n",
    "                y_t[i] = x_list[time][i] * math.exp(-( eta * r_t[i]))# eta is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if total_k == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t)\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                answer = a_t_hat / np.sum(x)\n",
    "                \n",
    "                if answer < 0:\n",
    "                    pmw_answers.append(0)\n",
    "                else: \n",
    "                    pmw_answers.append(answer)\n",
    "                \n",
    "                total_k -= 1 # use one of the total update steps\n",
    "        \n",
    "        #print(f'{x_list[time] - x_list[time - 1]=}')\n",
    "        \n",
    "        \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Synthetic Database (after) = {x_list[len(x_list) - 1] * sum(x)}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Synthetic Database (before) = {x_list[0]}\\n')\n",
    "        print(f'Synthetic Database (after, norm) = {x_list[len(x_list) - 1]}\\n')\n",
    "        print(f'Difference btw. Final Synthetic and true database = {x_list[len(x_list) - 1] - x_norm}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*total_k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*total_k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        #test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"tse\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data['squared_err'] = data['abs_error'] ** 2\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"num_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        num_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            num_answered[analyst] = data[(data['abs_error'] < count_threshold) & (data.analyst==analyst)]['abs_error'].count()\n",
    "        return num_answered\n",
    "    \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) &\n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 4, 'B': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pmw_independent: write pmw for one person. \n",
    "# create wrapper function called pmw_independent() that takes in the workloads and workload labels. Run PMW for each analyst, separate their workloads based on analysts. \n",
    "\n",
    "def pmw_independent(w, input_x, labs, input_T, input_eps=0.01, input_k=None, input_to_return='num_ans', threshold = 0.01):\n",
    "    \"\"\"\n",
    "    Wrapper function that calls pmw2() to simulate PMW for each independent person. \n",
    "    \n",
    "    Takes a stream of workloads and analyst labels and separates them into distinct workloads for each analyst. \n",
    "    Runs pmw_naive() on that particular workload for each analyst. Returns a dictionary of percent answered\n",
    "    \"\"\"\n",
    "    indices = {} # k: analyst, v: row indices of queries in the workloads\n",
    "    for i, analyst in enumerate(labs):\n",
    "        if analyst not in indices.keys(): \n",
    "            indices[analyst] = []\n",
    "        indices[analyst].append(i)\n",
    "\n",
    "    workloads = {} # k: analyst, v: the analyst's workload\n",
    "    for analyst in indices.keys():\n",
    "        workloads[analyst] = w[indices[analyst], :]\n",
    "    #print(workloads)\n",
    "\n",
    "    all_analyst_error_dic = {}\n",
    "    \n",
    "    for analyst in workloads.keys():\n",
    "        single_analyst_error = pmw_naive(workload=workloads[analyst], \n",
    "                                    eps=input_eps,\n",
    "                                    x=input_x, \n",
    "                                    T=input_T, \n",
    "                                    total_k = input_k,\n",
    "                                    analyst_labels=[analyst]*len(workloads[analyst]), \n",
    "                                    to_return=input_to_return,\n",
    "                                    count_threshold=threshold,\n",
    "                                    show_messages=False)\n",
    "        all_analyst_error_dic.update(single_analyst_error)\n",
    "    return all_analyst_error_dic\n",
    "\n",
    "pmw_independent(np.vstack((online_workloads.identity(5), \n",
    "                           online_workloads.identity(5))), \n",
    "                input_x=np.array([1, 1, 1, 1, 1]), \n",
    "                input_T=40, \n",
    "                input_eps=1, \n",
    "                labs=['A'] * 2 + ['B'] * 6 + ['A'] * 2, \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cache and Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(query, storage, ans, error):\n",
    "    \"\"\"caches query into a dictionary with values of (ans, error)\"\"\"\n",
    "    storage[np.array2string(query)] = (ans, error)\n",
    "    return storage\n",
    "    \n",
    "def is_reusable(query, storage):\n",
    "    \"\"\"returns whether or not a query is in a strategy matrix \n",
    "    (cache)\"\"\"\n",
    "    return np.array2string(query) in storage\n",
    "\n",
    "def reuse(query, storage):\n",
    "    \"\"\"returns tuple with (query answer, error) stored in \n",
    "    a storage dictionary\"\"\"\n",
    "    return storage[np.array2string(query)]\n",
    "\n",
    "def cache_and_reconstruct(workload, x, eps=0.01, k=0, analyst_labels=[], to_return = \"pd\", count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Seeded Cache and Reconstruct algorithm. \n",
    "    \n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    numAnalysts = len(budgets)\n",
    "    error_list = []\n",
    "    laplace_list = [] # if the algorithm simply added noise to the answer\n",
    "    used_reconstruct_list = []\n",
    "    used_reuse_list = []\n",
    "    \n",
    "    storage = {} # storage dictionary for reuse, k: query,v: error\n",
    "    strategy = workload[0:0] # workload matrix for reconstruction, \n",
    "    # make strategy = empty workload to create matrix of same dtype to be used in reconstruct step (avoid error)\n",
    "    \n",
    "    n = x.sum()\n",
    "    x_norm = x/sum(x) # normalize database\n",
    "    \n",
    "    def add_to_strategy(query, strategy):\n",
    "        \"\"\"Append query to the end fo the strategy matrix\"\"\"\n",
    "        return np.concatenate((strategy, query), axis = 0)\n",
    "    \n",
    "    for i, query in enumerate(workload): \n",
    "        query = np.expand_dims(query, axis = 0)\n",
    "        analyst = analyst_labels[i]\n",
    "        \n",
    "        # If query has answered before, then use old query answer\n",
    "        if is_reusable(query, storage): \n",
    "            abs_error = reuse(query, storage)\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            used_reconstruct_list.append(False) \n",
    "            laplace_list.append(False)\n",
    "            used_reuse_list.append(True)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst still has update steps left\n",
    "        elif budgets[analyst] > 0: \n",
    "            noise = np.random.laplace(0, (k * numAnalysts) / (n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            abs_error = np.abs(noisy_ans - true_ans)[0]\n",
    "            \n",
    "            error_list.append(abs_error) # *n\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            budgets[analyst] -= 1 \n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            laplace_list.append(True)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "        \n",
    "        # If query is reconstructable, then reconstruct\n",
    "        elif strategy_supports_workload(EkteloMatrix(query), EkteloMatrix(strategy)): # how to convert numpy array to ektelo matrix https://github.com/yikai-wu/Multi-Analyst-DP/blob/fadc7ac1d20199e8b31914f44323e51a05ed072d/src/hdmm/matrix.py#L34\n",
    "            \n",
    "            squared_error = expected_error(query, strategy, len(strategy) / (k * numAnalysts) * eps) # do i mult by 100\n",
    "            abs_error = math.sqrt(squared_error) / n #\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            error_list.append(abs_error)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(True) \n",
    "            used_reuse_list.append(False)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst ran out of update steps\n",
    "        else: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "            \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': error_list,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) & \n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered\n",
    "    \n",
    "    if to_return == \"num_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': error_list,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        num_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            num_answered[analyst] = data[(data['abs_error'] < count_threshold) & (data.analyst==analyst)]['abs_error'].count()\n",
    "        return num_answered\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        d = {'queries': workload.tolist(), \n",
    "            'abs_error': error_list,\n",
    "            'used_reconstruct': used_reconstruct_list,\n",
    "            'used_reuse': used_reuse_list,\n",
    "            'laplace': laplace_list,\n",
    "            'analyst': analyst_labels,\n",
    "        }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data = test_data.round(3)\n",
    "        test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedulers\n",
    "The following are the schedulers that we will use. There are 2 schedulers: random scheduler and round robin scheduler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scheduler that schedules Alice's queries with a probability of p and all other analysts' queries with a probability of (1 - p) / (number of analysts - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scheduler(analysts: list, workloads: list, p : int = 0.1) -> Tuple: \n",
    "    \"\"\"\n",
    "    In a system with n analysts, this system schedules Alice's queries with a probability of p and \n",
    "    other analysts' queries with an equal probability of (1 - p) / (n - 1), i.e. uniform probability.\n",
    "    \n",
    "    Returns new workload of queries (2D np.array) and analyst labels (list) that label each query in the \n",
    "    new workload. \n",
    "    \n",
    "    Takes: \n",
    "    - analysts: list of analyst names\n",
    "    - workloads: list of workloads in order where analyst[i] has workloads[i]\n",
    "    - p: probability that Alice has her query answered at any given step\n",
    "    \n",
    "    Returns: \n",
    "    - W_final: final workload\n",
    "    - analyst_labels: labels the final workload where analyst_labels[i] is the analyst with query at W_final[i]\n",
    "    \n",
    "    Date: 5-27-2022\n",
    "    \"\"\"\n",
    "\n",
    "    workloads_dict = dict(zip(analysts, workloads))\n",
    "\n",
    "    # gives alice p, all other analysts equal weight left\n",
    "    weights = [p if analyst=='a' else (1-p)/(len(analysts) - 1) for analyst in analysts] \n",
    "    # points the query that analyst is at, e.g., {'a': 0, 'b': 0, ...}\n",
    "    pointers = {analyst: 0 for analyst in analysts}\n",
    "\n",
    "    num_queries_left = {analyst: len(workloads_dict[analyst]) for analyst in analysts}\n",
    "\n",
    "    ordering = random.choices(analysts, weights, k=5000)\n",
    "    iterator = cycle(ordering)\n",
    "    \n",
    "    W = []\n",
    "    analyst_labels = []\n",
    "\n",
    "    for analyst in iterator: \n",
    "        if num_queries_left[analyst] > 0: \n",
    "            # add query to the workload\n",
    "            pointer = pointers[analyst]\n",
    "            W.append(workloads_dict[analyst][pointer])\n",
    "            analyst_labels.append(analyst)\n",
    "\n",
    "            num_queries_left[analyst] -= 1\n",
    "            pointers[analyst] += 1\n",
    "        if sum(num_queries_left.values()) == 0: # if no more queries left to ask\n",
    "            break\n",
    "\n",
    "    W_final = np.array(W)\n",
    "    #list(zip(analyst_labels, W_final))\n",
    "    return W_final, analyst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]),\n",
       " ['j',\n",
       "  'e',\n",
       "  'c',\n",
       "  'f',\n",
       "  'a',\n",
       "  'd',\n",
       "  'b',\n",
       "  'a',\n",
       "  'h',\n",
       "  'g',\n",
       "  'b',\n",
       "  'j',\n",
       "  'g',\n",
       "  'h',\n",
       "  'c',\n",
       "  'f',\n",
       "  'i',\n",
       "  'd',\n",
       "  'i',\n",
       "  'e'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test random_scheduler(): \n",
    "analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "a = np.array([[1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "c = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "d = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "e = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "f = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "g = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "h = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "i = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "j = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "workloads = [a, b, c, d, e, f, g, h, i, j]\n",
    "\n",
    "random_scheduler(analysts, workloads, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Round Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    num_active = len(iterables)\n",
    "    nexts = cycle(iter(it).__next__ for it in iterables)\n",
    "    while num_active:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            # Remove the iterator we just exhausted from the cycle.\n",
    "            num_active -= 1\n",
    "            nexts = cycle(islice(nexts, num_active))\n",
    "\n",
    "def rr_scheduler(analysts: list, workloads: list) -> Tuple:\n",
    "    \"\"\"\n",
    "    Adapting itertools' roundrobin() code to np workloads and analyst labels. \n",
    "    \n",
    "    Takes two parallel lists: \n",
    "    - analysts - list of each analyst \n",
    "    - workloads - list of each workload; analysts[i] owns workloads[i]\n",
    "    \n",
    "    Returns Tuple of two parallel lists: \n",
    "    - analyst_labels - list of shuffled analyst labels s.t. analyst_labels[i] owns final_workload[i] query \n",
    "    - final_workload - np.array shuffled workload\n",
    "    \"\"\"\n",
    "    analyst_labels = list(roundrobin(*[[analysts[i]] * len(workloads[i]) for i in range(len(analysts))]))\n",
    "    final_workload = np.vstack(list(roundrobin(*workloads)))\n",
    "    \n",
    "    return final_workload, analyst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0]]),\n",
       " ['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'd'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test rr_scheduler():\n",
    "\n",
    "analysts = ['a', 'b', 'c', 'd']\n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "d = np.array([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])\n",
    "workloads = [a, b, c, d]\n",
    "\n",
    "rr_scheduler(analysts, workloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "The following are test case workloads that I built to ensure that the schedulers were working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cases: \n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "\n",
    "# round robin would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 1 would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 0 would return: \n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "\n",
    "# skewed scheduler with p = 0.333 would return something similar to round robin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-27 (Top Left Corner)\n",
    "\n",
    "First, let's start doing one box (the top left corner). For p = 0.1, let's find the total utility for PMW (random scheduler), PMW (Round Robin) and Seeded C&R. Let's do this 500 times for PMWRS, PMWRR, and SCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workload parameters\n",
    "n=64\n",
    "W_name = ['identity', 'H2', 'race1', 'race2', 'race3', 'custom', 'prefix_sum']#, 'total',]\n",
    "W_lst = [online_workloads.identity(n), online_workloads.H2(n), online_workloads.race1(), online_workloads.race2(), online_workloads.race3(), online_workloads.custom(n), online_workloads.prefix_sum(n),] # online_workloads.total(n),]\n",
    "\n",
    "# database\n",
    "data_path = \"src/online/migration_tworace.csv\"\n",
    "x_race = pd.read_csv(data_path, header=None).to_numpy().T[1] \n",
    "database = np.concatenate([x_race[:32], x_race[:32]]) # truncate for the first 32 twice for symmetry purposes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vldb_exp(p_list = [0.1, 0.5, 0.9], t = 10, epsilon = 1):\n",
    "    \"\"\"\n",
    "    Run VLDB experiments. Implement the following algs. Return dictionary of dataframes\n",
    "    of the following experiments in different settings of p (probability that Alice has \n",
    "    her query answered at any time step):\n",
    "    - PMW (BL*: independent, strawman arg, generally a bad idea to prove our alg is better), \n",
    "    - PMW (OPT*: optimal in terms of overall error, we don’t care about desiderata, no changes)\n",
    "    - Seeded C&R\n",
    "    - PMW (Randomized Scheduler, p is always 0.1)\n",
    "    - PMW (RR*, always the same) \n",
    "    \"\"\"\n",
    "    test_data_dics = {}\n",
    "    \n",
    "    for p in p_list:\n",
    "        bl_pctans = []\n",
    "        rr_pctans = []\n",
    "        rs_pctans = []\n",
    "        opt_pctans = []\n",
    "        cr_pctans = []\n",
    "        for i in range(10):\n",
    "            # 1. generate workloads\n",
    "            # generate 10 workloads, one for each analyst\n",
    "            c = np.random.randint(len(W_lst))\n",
    "            analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "            workloads = [W_lst[c] for i in analysts]\n",
    "\n",
    "            # 2. use each algorithm\n",
    "\n",
    "            # bl - independent pmw, strawman arg\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, p) # random ordering\n",
    "            bl_pctans_dict = pmw_independent(W, \n",
    "                                             input_x=database, \n",
    "                                             input_T=40, \n",
    "                                             input_eps=epsilon/len(analysts),\n",
    "                                             threshold = 0.01,\n",
    "                                             labs=analyst_labels)\n",
    "            bl_pctans.append(sum(bl_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # opt - pmw with skewed ordering based on p\n",
    "            opt_pctans_dict = pmw_naive(W, \n",
    "                                        database, \n",
    "                                        analyst_labels, \n",
    "                                        eps=epsilon, \n",
    "                                        T=40, \n",
    "                                        to_return='pct_ans', \n",
    "                                        count_threshold=0.01)\n",
    "            opt_pctans.append(sum(opt_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # cr - c&r with skewed ordering based on p\n",
    "            cr_pctans_dict = cache_and_reconstruct(W, \n",
    "                                                   database, \n",
    "                                                   epsilon, \n",
    "                                                   5, \n",
    "                                                   analyst_labels, \n",
    "                                                   to_return = \"pct_ans\", \n",
    "                                                   count_threshold=0.01)\n",
    "            cr_pctans.append(sum(cr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rs - random scheduler, p is always 0.1\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, 0.1)\n",
    "            rs_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       to_return='pct_ans', \n",
    "                                       count_threshold=0.01)\n",
    "            rs_pctans.append(sum(rs_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rr - pmw with round robin ordering\n",
    "            W, analyst_labels = rr_scheduler(analysts, workloads)\n",
    "            rr_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       to_return='pct_ans',\n",
    "                                       count_threshold=0.01)\n",
    "            rr_pctans.append(sum(rr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "\n",
    "        d = {'bl': bl_pctans,\n",
    "             'opt': opt_pctans,\n",
    "             'cr': cr_pctans,\n",
    "             'rs': rs_pctans,\n",
    "            'rr': rr_pctans,\n",
    "            }\n",
    "\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data_dics[p] = test_data\n",
    "\n",
    "    return test_data_dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pmw_independent() got an unexpected keyword argument 'thresh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c5166b7d8153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvldb_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-97005cd9f8ad>\u001b[0m in \u001b[0;36mvldb_exp\u001b[0;34m(p_list, t, epsilon)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# bl - independent pmw, strawman arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyst_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkloads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# random ordering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             bl_pctans_dict = pmw_independent(W, \n\u001b[0m\u001b[1;32m     32\u001b[0m                                              \u001b[0minput_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                                              \u001b[0minput_T\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: pmw_independent() got an unexpected keyword argument 'thresh'"
     ]
    }
   ],
   "source": [
    "dics = vldb_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vldb_exp_new(p_list = [0.1, 0.5, 0.9], t = 10, epsilon = 1):\n",
    "    \"\"\"\n",
    "    Run VLDB experiments. Implement the following algs. Return dictionary of dataframes\n",
    "    of the following experiments in different settings of p (probability that Alice has \n",
    "    her query answered at any time step):\n",
    "    - PMW (BL*: independent, strawman arg, generally a bad idea to prove our alg is better), \n",
    "    - PMW (OPT*: optimal in terms of overall error, we don’t care about desiderata, no changes)\n",
    "    - Seeded C&R\n",
    "    - PMW (Randomized Scheduler, p is always 0.1)\n",
    "    - PMW (RR*, always the same) \n",
    "    \n",
    "    Last updated: June 16, 2022\n",
    "    \"\"\"\n",
    "    df_dic = {}\n",
    "    \n",
    "    def save_value(alg, p, val):\n",
    "        \"\"\"\n",
    "        Helper function to save the value of the calculation into the dictionary df_dic\n",
    "        \"\"\"\n",
    "        if f'{alg}{p}' not in df_dic:\n",
    "            df_dic[f'{alg}{p}'] = []\n",
    "        df_dic[f'{alg}{p}'].append(val)\n",
    "    \n",
    "    for i in range(t):\n",
    "        # 1. generate workloads\n",
    "        # generate 10 workloads, one for each analyst\n",
    "        #Tr = 0.008\n",
    "        Global_Threshold = 0.01\n",
    "        c = np.random.randint(len(W_lst))\n",
    "        analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "        workloads = [random.choice(W_lst) for i in analysts] # different workload for each analyst\n",
    "        \n",
    "        for p in p_list:\n",
    "            \n",
    "            # 2. use each algorithm\n",
    "\n",
    "            # bl - independent pmw, strawman arg\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, p) # random ordering\n",
    "            bl_pctans_dict = pmw_independent(W, \n",
    "                                             input_x=database, \n",
    "                                             input_T=40, \n",
    "                                             input_eps=epsilon/len(analysts), \n",
    "                                             labs=analyst_labels,\n",
    "                                             threshold = Global_Threshold,\n",
    "                                             #input_to_return=\"num_ans\")\n",
    "                                             input_to_return=\"pct_ans\")\n",
    "            save_value('Ind', p, sum(bl_pctans_dict.values()) / len(analysts))\n",
    "            \n",
    "            # opt - pmw with skewed ordering based on p\n",
    "            opt_pctans_dict = pmw_naive(W, \n",
    "                                        database, \n",
    "                                        analyst_labels, \n",
    "                                        eps=epsilon, \n",
    "                                        T=40, \n",
    "                                        #to_return='num_ans',\n",
    "                                        to_return=\"pct_ans\",\n",
    "                                        count_threshold=Global_Threshold)\n",
    "            save_value('PMW', p, sum(opt_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # cr - c&r with skewed ordering based on p\n",
    "            cr_pctans_dict = cache_and_reconstruct(W, \n",
    "                                                   database, \n",
    "                                                   epsilon, \n",
    "                                                   5, \n",
    "                                                   analyst_labels, \n",
    "                                                   #to_return = \"num_ans\", \n",
    "                                                   to_return=\"pct_ans\",\n",
    "                                                   count_threshold=Global_Threshold)\n",
    "            save_value('SCR', p, sum(cr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rs - random scheduler, p is always 0.1\n",
    "            W, analyst_labels = random_scheduler(analysts, workloads, 0.1)\n",
    "            rs_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       #to_return='num_ans', \n",
    "                                       to_return=\"pct_ans\",\n",
    "                                       count_threshold=Global_Threshold)\n",
    "            save_value('RS', p, sum(rs_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "            # rr - pmw with round robin ordering\n",
    "            W, analyst_labels = rr_scheduler(analysts, workloads)\n",
    "            rr_pctans_dict = pmw_naive(W, \n",
    "                                       database, \n",
    "                                       analyst_labels, \n",
    "                                       eps=epsilon, \n",
    "                                       T=40, \n",
    "                                       #to_return='num_ans',\n",
    "                                       to_return=\"pct_ans\",\n",
    "                                       count_threshold=Global_Threshold)\n",
    "            save_value('RR', p, sum(rr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "        test_data = pd.DataFrame(data=df_dic)\n",
    "        print(f'Epoch {i} complete')\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n",
      "--- 156.29501914978027 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "test_data = vldb_exp_new(t=10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifactspath = '/home/david/Documents/online_budgetshare/fig/'\n",
    "#artifactspath = \"/Users/albertsun/Projects/artifacts/algexperiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Ind        PMW        SCR         RS         RR\n",
      "0  44.159453  69.772679  52.269859  70.810922  71.240461\n",
      "1  33.681921  53.468632  45.213959  55.759336  53.135856\n",
      "2  41.080990  64.582677  65.119235  73.390326  75.947132\n",
      "3  30.547817  55.577702  40.497353  56.815844  55.251228\n",
      "4  44.432209  59.786727  44.353710  58.618923  56.685209\n",
      "5  46.457956  51.462230  42.941898  53.353650  52.454145\n",
      "6  34.322835  66.525111  51.768213  69.818898  67.779064\n",
      "7  36.228992  56.382353  41.569590  57.319853  55.365809\n",
      "8  37.265692  54.948978  55.609206  74.881447  65.808623\n",
      "9  34.270494  73.674022  59.228739  73.506259  71.960041\n",
      "      Ind0.1     PMW0.1     SCR0.1      RS0.1      RR0.1\n",
      "0  44.159453  69.772679  52.269859  70.810922  71.240461\n",
      "1  33.681921  53.468632  45.213959  55.759336  53.135856\n",
      "2  41.080990  64.582677  65.119235  73.390326  75.947132\n",
      "3  30.547817  55.577702  40.497353  56.815844  55.251228\n",
      "4  44.432209  59.786727  44.353710  58.618923  56.685209\n",
      "5  46.457956  51.462230  42.941898  53.353650  52.454145\n",
      "6  34.322835  66.525111  51.768213  69.818898  67.779064\n",
      "7  36.228992  56.382353  41.569590  57.319853  55.365809\n",
      "8  37.265692  54.948978  55.609206  74.881447  65.808623\n",
      "9  34.270494  73.674022  59.228739  73.506259  71.960041\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_1 = test_data.iloc[:,:5]\n",
    "test_data_1.columns = test_data_1.columns.str.rstrip(\"0.1\")\n",
    "ax = test_data_1.boxplot()\n",
    "#ax.set_ylim(0, 50)\n",
    "#plt.title('Alice gets her queries \\nanswered with p = 0.1')\n",
    "#plt.ylabel('Queries Answered')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.savefig(artifactspath + '0.1acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = test_data.iloc[:,5:10]\n",
    "test_data_2.columns = test_data_2.columns.str.rstrip(\"0.5\")\n",
    "ax = test_data_2.boxplot()\n",
    "#ax.set_ylim(0, 50)\n",
    "#plt.title('Alice gets her queries \\nanswered with p = 0.5')\n",
    "#plt.ylabel('Queries Answered')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.savefig(artifactspath + '0.5acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9\n",
    "test_data_3 = test_data.iloc[:,10:15]\n",
    "test_data_3.columns = test_data_3.columns.str.rstrip(\"0.9\")\n",
    "ax = test_data_3.boxplot()\n",
    "#ax.set_ylim(0, 50)\n",
    "#plt.title('Alice gets her queries \\nanswered with p = 0.9')\n",
    "#plt.ylabel('Queries Answered')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.savefig(artifactspath + '0.9acc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment parameters: \n",
    "- eps = 1, \n",
    "- count threshold = 0.01, \n",
    "- workload = random practical workload (identity, h2, census, etc.), \n",
    "- database = practical census size 64 database\n",
    "- exp run = 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In PMW/C&R: code a to_return = \"first_analyst_err\", which represents the first analyst's error (aka. Alice's error)\n",
    "# Max Ratio: Alice's independent error / error with the collective\n",
    "    # PMW/C&R (Alice's workload/analyst label only, with 1/10 eps)\n",
    "    # PMW/C&R (whole workload)\n",
    "# Emp Int: CHOOSE ANLAYST WITH MAX ERROR: Error w random non-Alice / Error without random non-Alice\n",
    "    # PMW/C&R (whole workload)\n",
    "    # PMW/C&R (workload removing one random analyst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
