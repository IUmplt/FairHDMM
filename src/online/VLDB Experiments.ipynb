{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4090fe",
   "metadata": {},
   "source": [
    "# VLDB Experiments\n",
    "In this Jupyter Notebook, I wish to conduct the following experiments for VLDB.\n",
    "\n",
    "Edited: May 23, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb0649",
   "metadata": {},
   "source": [
    "Let's design the experiments we're going to use for VLDB with the following varying configs: \n",
    "- p = 0.1, 0.5, 1\n",
    "- Algos = PMW, PMW (random scheduler), PMW, PMW (Round Robin) and Seeded C&R\n",
    "- Measures = Total Utility, Max Ratio, Empirical Interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38945387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.hdmm.error import expected_error, strategy_supports_workload\n",
    "from src.hdmm.matrix import EkteloMatrix\n",
    "from typing import Tuple\n",
    "import string\n",
    "import random\n",
    "from itertools import cycle, islice\n",
    "import src.hdmm.workload as workload\n",
    "import src.census_workloads as census\n",
    "from src.workload_selection import workload_selection\n",
    "import online_workloads as online_workloads\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from src.hdmm.workload import AllRange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84825da3",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "The following are the algorithms that we wish to implement. They are Private Multiplicative Weights and Cache and Reconstruct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5b282",
   "metadata": {},
   "source": [
    "### 1. PMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c37ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw_naive(workload, x, analyst_labels, T, eps=0.01, total_k=None, \n",
    "         show_messages=False, to_return='error', show_plot=False, show_failure_step=False, eta = None,\n",
    "             count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries where analysts can run out of privacy budget if they use too much of others'. \n",
    "    \n",
    "    In other words, all analysts share from the same privacy budget. \n",
    "    \n",
    "    Last Updated: 4-23-2022\n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - total_k = total number of update steps alloted for the entire group\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'error', pmw() returns a dictionary for the average absolute error for each analyst\n",
    "        - if 'pct_ans', pmw() returns a dictionary for the percent of queries answered that meets\n",
    "        the accuracy threshold set by count_threshold\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    - count_threshold - this is for the to_return = 'pct_ans' setting. It is the min error threshold \n",
    "    that a query answer for us to count the answer as \"reasonable\" as opposed to \"bot\". The default\n",
    "    is 0.1. This functions as another way to  measure the accuracy of the queries that is more similar \n",
    "    to how our other functions; i.e., cache and reconstruct either returns an accurate answer or \"bot\".\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    if(eta == None):\n",
    "        eta = (math.log(m, np.e) / ((math.sqrt(n))) )\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    # initialize total_k, the total number of update steps if not default\n",
    "    if total_k == None:\n",
    "        total_k = round(n * math.log(math.sqrt(m)) / 770) #770\n",
    "        #print(f'{total_k=}')\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        answer = np.dot(query, x_list[time])\n",
    "        if answer < 0:\n",
    "            pmw_answers.append(0)\n",
    "        else: \n",
    "            pmw_answers.append(answer)\n",
    "        x_list.append(x_list[time])\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    #print(rho + T)\n",
    "    \n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique; compute noisy answer by adding Laplacian noise\n",
    "        A_t = np.random.laplace(loc=0, scale=(total_k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # LAZY ROUND: QUERY USING THE SYNTHETIC DATABASE\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "\n",
    "        # UPDATE ROUND: UPDATE SYNTHETIC DATABASE AND RETURN NOISY ANSWER, A_T-HAT\n",
    "        else:\n",
    "            # noise\n",
    "            A_t = np.random.laplace(loc=0, scale=(2*total_k/eps), size=1)[0]\n",
    "            \n",
    "            # noisy answer\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + A_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i in range(len(y_t)):\n",
    "                y_t[i] = x_list[time][i] * math.exp(-( eta * r_t[i]))# eta is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if total_k == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t)\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                answer = a_t_hat / np.sum(x)\n",
    "                \n",
    "                if answer < 0:\n",
    "                    pmw_answers.append(0)\n",
    "                else: \n",
    "                    pmw_answers.append(answer)\n",
    "                \n",
    "                total_k -= 1 # use one of the total update steps\n",
    "        \n",
    "        #print(f'{x_list[time] - x_list[time - 1]=}')\n",
    "        \n",
    "        \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Synthetic Database (after) = {x_list[len(x_list) - 1] * sum(x)}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Synthetic Database (before) = {x_list[0]}\\n')\n",
    "        print(f'Synthetic Database (after, norm) = {x_list[len(x_list) - 1]}\\n')\n",
    "        print(f'Difference btw. Final Synthetic and true database = {x_list[len(x_list) - 1] - x_norm}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*total_k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*total_k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        #test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"tse\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data['squared_err'] = data['abs_error'] ** 2\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(sorted(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "    \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) & \n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "973c8ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 100.0, 'B': 100.0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pmw_independent: write pmw for one person. \n",
    "# create wrapper function called pmw_independent() that takes in the workloads and workload labels. Run PMW for each analyst, separate their workloads based on analysts. \n",
    "\n",
    "def pmw_independent(w, input_x, labs, input_T, input_eps=0.01, input_k=None):\n",
    "    \"\"\"\n",
    "    Wrapper function that calls pmw2() to simulate PMW for each independent person. \n",
    "    \n",
    "    Takes a stream of workloads and analyst labels and separates them into distinct workloads for each analyst. \n",
    "    Runs pmw_naive() on that particular workload for each analyst. Returns a dictionary of percent answered\n",
    "    \"\"\"\n",
    "    indices = {} # k: analyst, v: row indices of queries in the workloads\n",
    "    for i, analyst in enumerate(labs):\n",
    "        if analyst not in indices.keys(): \n",
    "            indices[analyst] = []\n",
    "        indices[analyst].append(i)\n",
    "\n",
    "    workloads = {} # k: analyst, v: the analyst's workload\n",
    "    for analyst in indices.keys():\n",
    "        workloads[analyst] = w[indices[analyst], :]\n",
    "    #print(workloads)\n",
    "\n",
    "    all_analyst_error_dic = {}\n",
    "    \n",
    "    for analyst in workloads.keys():\n",
    "        single_analyst_error = pmw_naive(workload=workloads[analyst], \n",
    "                                    eps=input_eps,\n",
    "                                    x=input_x, \n",
    "                                    T=input_T, \n",
    "                                    total_k = input_k,\n",
    "                                    analyst_labels=[analyst]*len(workloads[analyst]), \n",
    "                                    to_return=\"pct_ans\",\n",
    "                                    count_threshold=0.01,\n",
    "                                    show_messages=False)\n",
    "        all_analyst_error_dic.update(single_analyst_error)\n",
    "    return all_analyst_error_dic\n",
    "\n",
    "pmw_independent(np.vstack((online_workloads.identity(5), \n",
    "                           online_workloads.identity(5))), \n",
    "                input_x=np.array([1, 1, 1, 1, 1]), \n",
    "                input_T=40, \n",
    "                input_eps=1, \n",
    "                labs=['A'] * 2 + ['B'] * 6 + ['A'] * 2, \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "872c62fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 73.4375,\n",
       " 'b': 73.4375,\n",
       " 'c': 73.4375,\n",
       " 'd': 73.4375,\n",
       " 'e': 73.4375,\n",
       " 'f': 73.4375,\n",
       " 'g': 73.4375,\n",
       " 'h': 73.4375,\n",
       " 'i': 73.4375,\n",
       " 'j': 73.4375}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing code for pmw independent: \n",
    "c = np.random.randint(len(W_lst))\n",
    "analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "workloads = [W_lst[c] for i in analysts]\n",
    "W, lbls = rr_scheduler(analysts, workloads)\n",
    "len(W)\n",
    "data_path = \"migration_tworace.csv\"\n",
    "x_race = pd.read_csv(data_path, header=None).to_numpy().T[1] \n",
    "database = np.concatenate([x_race[:32], x_race[:32]]) # truncate for the first 32 twice for symmetry purposes\n",
    "pmw_independent(W, \n",
    "                input_x=database, \n",
    "                input_T=40, \n",
    "                input_eps=1, \n",
    "                labs=lbls, \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbb3df",
   "metadata": {},
   "source": [
    "### 2. Cache and Reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ab26ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache(query, storage, ans, error):\n",
    "    \"\"\"caches query into a dictionary with values of (ans, error)\"\"\"\n",
    "    storage[np.array2string(query)] = (ans, error)\n",
    "    return storage\n",
    "    \n",
    "def is_reusable(query, storage):\n",
    "    \"\"\"returns whether or not a query is in a strategy matrix \n",
    "    (cache)\"\"\"\n",
    "    return np.array2string(query) in storage\n",
    "\n",
    "def reuse(query, storage):\n",
    "    \"\"\"returns tuple with (query answer, error) stored in \n",
    "    a storage dictionary\"\"\"\n",
    "    return storage[np.array2string(query)]\n",
    "\n",
    "def cache_and_reconstruct(workload, x, eps=0.01, k=0, analyst_labels=[], to_return = \"pd\", count_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    numAnalysts = len(budgets)\n",
    "    error_list = []\n",
    "    laplace_list = [] # if the algorithm simply added noise to the answer\n",
    "    used_reconstruct_list = []\n",
    "    used_reuse_list = []\n",
    "    \n",
    "    storage = {} # storage dictionary for reuse, k: query,v: error\n",
    "    strategy = workload[0:0] # workload matrix for reconstruction, \n",
    "    # make strategy = empty workload to create matrix of same dtype to be used in reconstruct step (avoid error)\n",
    "    \n",
    "    n = x.sum()\n",
    "    x_norm = x/sum(x) # normalize database\n",
    "    \n",
    "    def add_to_strategy(query, strategy):\n",
    "        \"\"\"Append query to the end fo the strategy matrix\"\"\"\n",
    "        return np.concatenate((strategy, query), axis = 0)\n",
    "    \n",
    "    for i, query in enumerate(workload): \n",
    "        query = np.expand_dims(query, axis = 0)\n",
    "        analyst = analyst_labels[i]\n",
    "        \n",
    "        # If query has answered before, then use old query answer\n",
    "        if is_reusable(query, storage): \n",
    "            abs_error = reuse(query, storage)\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            used_reconstruct_list.append(False) \n",
    "            laplace_list.append(False)\n",
    "            used_reuse_list.append(True)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst still has update steps left\n",
    "        elif budgets[analyst] > 0: \n",
    "            noise = np.random.laplace(0, (k * numAnalysts) / (n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            abs_error = np.abs(noisy_ans - true_ans)[0]\n",
    "            \n",
    "            error_list.append(abs_error) # *n\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            budgets[analyst] -= 1 \n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            laplace_list.append(True)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "        \n",
    "        # If query is reconstructable, then reconstruct\n",
    "        elif strategy_supports_workload(EkteloMatrix(query), EkteloMatrix(strategy)): # how to convert numpy array to ektelo matrix https://github.com/yikai-wu/Multi-Analyst-DP/blob/fadc7ac1d20199e8b31914f44323e51a05ed072d/src/hdmm/matrix.py#L34\n",
    "            \n",
    "            squared_error = expected_error(query, strategy, len(strategy) / (k * numAnalysts) * eps) # do i mult by 100\n",
    "            abs_error = math.sqrt(squared_error) / n #\n",
    "            \n",
    "            storage[np.array2string(query)] = abs_error\n",
    "            error_list.append(abs_error)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(True) \n",
    "            used_reuse_list.append(False)\n",
    "            strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "        # If analyst ran out of update steps\n",
    "        else: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            laplace_list.append(False)\n",
    "            used_reconstruct_list.append(False)\n",
    "            used_reuse_list.append(False)\n",
    "            \n",
    "    if to_return == \"pct_ans\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': error_list,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        \n",
    "        pct_answered = {}\n",
    "        for analyst in sorted(list(set(analyst_labels))):\n",
    "            pct_answered[analyst] = data[(data['abs_error'] < count_threshold) & \n",
    "                                         (data.analyst==analyst)]['abs_error'].count()/len(data[data.analyst==analyst]) * 100\n",
    "        return pct_answered\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        d = {'queries': workload.tolist(), \n",
    "            'abs_error': error_list,\n",
    "            'used_reconstruct': used_reconstruct_list,\n",
    "            'used_reuse': used_reuse_list,\n",
    "            'laplace': laplace_list,\n",
    "            'analyst': analyst_labels,\n",
    "        }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data = test_data.round(3)\n",
    "        test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3ed48d",
   "metadata": {},
   "source": [
    "# Schedulers\n",
    "The following are the schedulers that we will use. There are 2 schedulers: random scheduler and round robin scheduler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478b7ea",
   "metadata": {},
   "source": [
    "### 1. Random Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f4471",
   "metadata": {},
   "source": [
    "Create a scheduler that schedules Alice's queries with a probability of p and all other analysts' queries with a probability of (1 - p) / (number of analysts - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd1b2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scheduler(analysts: list, workloads: list, p : int = 0.1) -> Tuple: \n",
    "    \"\"\"\n",
    "    In a system with n analysts, this system schedules Alice's queries with a probability of p and \n",
    "    other analysts' queries with an equal probability of (1 - p) / (n - 1), i.e. uniform probability.\n",
    "    \n",
    "    Returns new workload of queries (2D np.array) and analyst labels (list) that label each query in the \n",
    "    new workload. \n",
    "    \n",
    "    Takes: \n",
    "    - analysts: list of analyst names\n",
    "    - workloads: list of workloads in order where analyst[i] has workloads[i]\n",
    "    - p: probability that Alice has her query answered at any given step\n",
    "    \n",
    "    Returns: \n",
    "    - W_final: final workload\n",
    "    - analyst_labels: labels the final workload where analyst_labels[i] is the analyst with query at W_final[i]\n",
    "    \n",
    "    Date: 5-27-2022\n",
    "    \"\"\"\n",
    "\n",
    "    workloads_dict = dict(zip(analysts, workloads))\n",
    "\n",
    "    # gives alice p, all other analysts equal weight left\n",
    "    weights = [p if analyst=='a' else (1-p)/(len(analysts) - 1) for analyst in analysts] \n",
    "    # points the query that analyst is at, e.g., {'a': 0, 'b': 0, ...}\n",
    "    pointers = {analyst: 0 for analyst in analysts}\n",
    "\n",
    "    num_queries_left = {analyst: len(workloads_dict[analyst]) for analyst in analysts}\n",
    "\n",
    "    ordering = random.choices(analysts, weights, k=5000)\n",
    "    iterator = cycle(ordering)\n",
    "    \n",
    "    W = []\n",
    "    analyst_labels = []\n",
    "\n",
    "    for analyst in iterator: \n",
    "        if num_queries_left[analyst] > 0: \n",
    "            # add query to the workload\n",
    "            pointer = pointers[analyst]\n",
    "            W.append(workloads_dict[analyst][pointer])\n",
    "            analyst_labels.append(analyst)\n",
    "\n",
    "            num_queries_left[analyst] -= 1\n",
    "            pointers[analyst] += 1\n",
    "        if sum(num_queries_left.values()) == 0: # if no more queries left to ask\n",
    "            break\n",
    "\n",
    "    W_final = np.array(W)\n",
    "    #list(zip(analyst_labels, W_final))\n",
    "    return W_final, analyst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9501c3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]]),\n",
       " ['a',\n",
       "  'f',\n",
       "  'a',\n",
       "  'c',\n",
       "  'b',\n",
       "  'b',\n",
       "  'c',\n",
       "  'g',\n",
       "  'j',\n",
       "  'h',\n",
       "  'j',\n",
       "  'h',\n",
       "  'd',\n",
       "  'i',\n",
       "  'i',\n",
       "  'd',\n",
       "  'f',\n",
       "  'e',\n",
       "  'e',\n",
       "  'g'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test random_scheduler(): \n",
    "analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "a = np.array([[1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "c = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "d = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "e = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "f = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "g = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "h = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "i = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "j = np.array([[0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "workloads = [a, b, c, d, e, f, g, h, i, j]\n",
    "\n",
    "random_scheduler(analysts, workloads, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aafc4d",
   "metadata": {},
   "source": [
    "### 2. Round Robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49beaa6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def roundrobin(*iterables):\n",
    "    \"roundrobin('ABC', 'D', 'EF') --> A D E B F C\"\n",
    "    # Recipe credited to George Sakkis\n",
    "    num_active = len(iterables)\n",
    "    nexts = cycle(iter(it).__next__ for it in iterables)\n",
    "    while num_active:\n",
    "        try:\n",
    "            for next in nexts:\n",
    "                yield next()\n",
    "        except StopIteration:\n",
    "            # Remove the iterator we just exhausted from the cycle.\n",
    "            num_active -= 1\n",
    "            nexts = cycle(islice(nexts, num_active))\n",
    "\n",
    "def rr_scheduler(analysts: list, workloads: list) -> Tuple:\n",
    "    \"\"\"\n",
    "    Adapting itertools' roundrobin() code to np workloads and analyst labels. \n",
    "    \n",
    "    Takes two parallel lists: \n",
    "    - analysts - list of each analyst \n",
    "    - workloads - list of each workload; analysts[i] owns workloads[i]\n",
    "    \n",
    "    Returns Tuple of two parallel lists: \n",
    "    - analyst_labels - list of shuffled analyst labels s.t. analyst_labels[i] owns final_workload[i] query \n",
    "    - final_workload - np.array shuffled workload\n",
    "    \"\"\"\n",
    "    analyst_labels = list(roundrobin(*[[analysts[i]] * len(workloads[i]) for i in range(len(analysts))]))\n",
    "    final_workload = np.vstack(list(roundrobin(*workloads)))\n",
    "    \n",
    "    return final_workload, analyst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743fd580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0],\n",
       "        [1, 0, 1, 0]]),\n",
       " ['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'd'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test rr_scheduler():\n",
    "\n",
    "analysts = ['a', 'b', 'c', 'd']\n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "d = np.array([[1, 0, 1, 0], [1, 0, 1, 0], [1, 0, 1, 0]])\n",
    "workloads = [a, b, c, d]\n",
    "\n",
    "rr_scheduler(analysts, workloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc54ed8",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15752b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test cases: \n",
    "a = np.array([[1, 1, 1, 1],\n",
    "              [1, 1, 1, 1]])\n",
    "b = np.array([[0, 0, 0, 0],\n",
    "              [0, 0, 0, 0]])\n",
    "c = np.array([[1, 0, 1, 0],\n",
    "              [1, 0, 1, 0]])\n",
    "\n",
    "# round robin would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [0, 0, 0, 0]\n",
    "# [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 1 would return: \n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "\n",
    "# skewed scheduler with p = 0 would return: \n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# either [0, 0, 0, 0] or [1, 0, 1, 0]\n",
    "# [1, 1, 1, 1]\n",
    "# [1, 1, 1, 1]\n",
    "\n",
    "# skewed scheduler with p = 0.333 would return something similar to round robin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43acffd4",
   "metadata": {},
   "source": [
    "# 5-27 (Top Left Corner)\n",
    "\n",
    "First, let's start doing one box (the top left corner). For p = 0.1, let's find the total utility for PMW (random scheduler), PMW (Round Robin) and Seeded C&R. Let's do this 500 times for PMWRS, PMWRR, and SCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329e4a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workload parameters\n",
    "n=64\n",
    "W_name = ['identity', 'H2', 'race1', 'race2', 'race3', 'custom', 'prefix_sum']#, 'total',]\n",
    "W_lst = [online_workloads.identity(n), online_workloads.H2(n), online_workloads.race1(), online_workloads.race2(), online_workloads.race3(), online_workloads.custom(n), online_workloads.prefix_sum(n),] # online_workloads.total(n),]\n",
    "\n",
    "# database\n",
    "data_path = \"migration_tworace.csv\"\n",
    "x_race = pd.read_csv(data_path, header=None).to_numpy().T[1] \n",
    "database = np.concatenate([x_race[:32], x_race[:32]]) # truncate for the first 32 twice for symmetry purposes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598203e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a1e45e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vldb_exp(p = 0.1, t = 10, epsilon = 1): #p_list = [0.1, 0.5, 0.9]\n",
    "    \"\"\"\n",
    "    Run VLDB experiments. Implement the following algs and return their percent answered:\n",
    "    - PMW (BL*: independent, strawman arg, generally a bad idea to prove our alg is better), \n",
    "    - PMW (OPT*: optimal in terms of overall error, we don’t care about desiderata, no changes)\n",
    "    - Seeded C&R\n",
    "    - PMW (Randomized Scheduler, p is always 0.1)\n",
    "    - PMW (RR*, always the same) \n",
    "    \"\"\"\n",
    "    bl_pctans = []\n",
    "    rr_pctans = []\n",
    "    rs_pctans = []\n",
    "    opt_pctans = []\n",
    "    cr_pctans = []\n",
    "    for i in range(10):\n",
    "        # 1. generate workloads\n",
    "        # generate 10 workloads, one for each analyst\n",
    "        c = np.random.randint(len(W_lst))\n",
    "        analysts = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "        workloads = [W_lst[c] for i in analysts]\n",
    "        \n",
    "        # 2. use each algorithm\n",
    "\n",
    "        # bl - independent pmw, strawman arg\n",
    "\n",
    "        W, analyst_labels = random_scheduler(analysts, workloads, p) # random ordering\n",
    "        bl_pctans_dict = pmw_independent(W, \n",
    "                                         input_x=database, \n",
    "                                         input_T=40, \n",
    "                                         input_eps=epsilon/len(analysts), \n",
    "                                         labs=analyst_labels)\n",
    "        bl_pctans.append(sum(bl_pctans_dict.values()) / len(analysts))\n",
    "        \n",
    "        # opt - pmw with skewed ordering based on p\n",
    "        opt_pctans_dict = pmw_naive(W, \n",
    "                                    database, \n",
    "                                    analyst_labels, \n",
    "                                    eps=epsilon, \n",
    "                                    T=40, \n",
    "                                    to_return='pct_ans', \n",
    "                                    count_threshold=0.01)\n",
    "        opt_pctans.append(sum(opt_pctans_dict.values()) / len(analysts))\n",
    "        \n",
    "        # cr - c&r with skewed ordering based on p\n",
    "        cr_pctans_dict = cache_and_reconstruct(W, \n",
    "                                               database, \n",
    "                                               epsilon, \n",
    "                                               5, \n",
    "                                               analyst_labels, \n",
    "                                               to_return = \"pct_ans\", \n",
    "                                               count_threshold=0.01)\n",
    "        cr_pctans.append(sum(cr_pctans_dict.values()) / len(analysts))\n",
    "        \n",
    "        # rs - random scheduler, p is always 0.1\n",
    "        W, analyst_labels = random_scheduler(analysts, workloads, 0.1)\n",
    "        rs_pctans_dict = pmw_naive(W, \n",
    "                                   database, \n",
    "                                   analyst_labels, \n",
    "                                   eps=epsilon, \n",
    "                                   T=40, \n",
    "                                   to_return='pct_ans', \n",
    "                                   count_threshold=0.01)\n",
    "        rs_pctans.append(sum(rs_pctans_dict.values()) / len(analysts))\n",
    "        \n",
    "        # rr - pmw with round robin ordering\n",
    "        W, analyst_labels = rr_scheduler(analysts, workloads)\n",
    "        rr_pctans_dict = pmw_naive(W, \n",
    "                                   database, \n",
    "                                   analyst_labels, \n",
    "                                   eps=epsilon, \n",
    "                                   T=40, \n",
    "                                   to_return='pct_ans',\n",
    "                                   count_threshold=0.01)\n",
    "        rr_pctans.append(sum(rr_pctans_dict.values()) / len(analysts))\n",
    "\n",
    "\n",
    "    d = {'bl': bl_pctans,\n",
    "         'opt': opt_pctans,\n",
    "         'cr': cr_pctans,\n",
    "         'rs': rs_pctans,\n",
    "        'rr': rr_pctans,\n",
    "        }\n",
    "\n",
    "    test_data = pd.DataFrame(data=d)\n",
    "\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ecabaae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bl</th>\n",
       "      <th>opt</th>\n",
       "      <th>cr</th>\n",
       "      <th>rs</th>\n",
       "      <th>rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.285714</td>\n",
       "      <td>95.714286</td>\n",
       "      <td>97.142857</td>\n",
       "      <td>97.142857</td>\n",
       "      <td>95.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.763780</td>\n",
       "      <td>42.992126</td>\n",
       "      <td>63.700787</td>\n",
       "      <td>41.732283</td>\n",
       "      <td>41.496063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.137615</td>\n",
       "      <td>39.449541</td>\n",
       "      <td>33.944954</td>\n",
       "      <td>40.275229</td>\n",
       "      <td>40.825688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.843750</td>\n",
       "      <td>71.875000</td>\n",
       "      <td>46.093750</td>\n",
       "      <td>72.968750</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.312500</td>\n",
       "      <td>25.625000</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>25.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.781250</td>\n",
       "      <td>26.875000</td>\n",
       "      <td>53.281250</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>25.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>47.981651</td>\n",
       "      <td>40.183486</td>\n",
       "      <td>35.504587</td>\n",
       "      <td>41.009174</td>\n",
       "      <td>42.018349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43.593750</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>52.343750</td>\n",
       "      <td>71.562500</td>\n",
       "      <td>68.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>67.142857</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>65.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bl         opt          cr         rs         rr\n",
       "0  24.285714   95.714286   97.142857  97.142857  95.714286\n",
       "1  39.763780   42.992126   63.700787  41.732283  41.496063\n",
       "2  45.137615   39.449541   33.944954  40.275229  40.825688\n",
       "3  44.843750   71.875000   46.093750  72.968750  70.000000\n",
       "4  30.000000  100.000000  100.000000  90.000000  90.000000\n",
       "5  35.312500   25.625000   53.750000  27.500000  25.781250\n",
       "6  30.781250   26.875000   53.281250  26.562500  25.937500\n",
       "7  47.981651   40.183486   35.504587  41.009174  42.018349\n",
       "8  43.593750   70.000000   52.343750  71.562500  68.593750\n",
       "9  49.000000   67.142857   56.000000  67.857143  65.285714"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vldb_exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f844df",
   "metadata": {},
   "source": [
    "Experiment parameters: \n",
    "- eps = 1, \n",
    "- count threshold = 0.01, \n",
    "- workload = random practical workload (identity, h2, census, etc.), \n",
    "- database = practical census size 64 database\n",
    "- exp run = 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65cf26c",
   "metadata": {},
   "source": [
    "### p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c13853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_one = vldb_exp(p = 0.1, t = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d2a884e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Percent of Queries Answered')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_one.boxplot()\n",
    "plt.title('Alice gets her queries answered with p = 0.1')\n",
    "plt.ylabel('Percent of Queries Answered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a07a8b",
   "metadata": {},
   "source": [
    "### p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_five = vldb_exp(p = 0.5, t = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_five.boxplot()\n",
    "plt.title('Alice gets her queries answered with p = 0.5')\n",
    "plt.ylabel('Percent of Queries Answered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f409f13",
   "metadata": {},
   "source": [
    "### p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nine = vldb_exp(p = 0.9, t = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef34f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nine.boxplot()\n",
    "plt.title('Alice gets her queries answered with p = 0.9')\n",
    "plt.ylabel('Percent of Queries Answered')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
