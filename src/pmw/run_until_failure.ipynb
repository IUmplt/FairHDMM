{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d096984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from src.hdmm import workload, fairtemplates, error, fairmechanism, matrix, mechanism, templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47272f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw(workload, x, eps=0.01, beta=0.1, k=0, show_messages=True, to_return='pd', analyst_labels = []):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries. New arguments to allow for optimizing the amount of\n",
    "    privacy budget used in each step.\n",
    "    \n",
    "    to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query (query, d_t_hat, updated, algo_ans, real_ans, abs_error, \n",
    "        rel_error). \n",
    "        - if 'update_count', pmw() returns the update count for the total\n",
    "        amount of queries\n",
    "\n",
    "    - W = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    if k==0: # essentially, if k hasn't been changed from its default value, use the length of the workload\n",
    "        k = len(workload)  # num of queries\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    eta = (math.log(m, np.e) ** (1 / 4)) / (math.sqrt(n))\n",
    "    sigma = 10 * math.log(1 / delta, np.e) * ((math.log(m, np.e)) ** (1 / 4)) / (\n",
    "            math.sqrt(n) * eps)\n",
    "    threshold = 4 * sigma * (math.log(k, np.e) + math.log(1 / beta, np.e))\n",
    "    \n",
    "    # synthetic databases at time 0 (prior to any queries)\n",
    "    y_t = np.ones(m) / m\n",
    "    x_t = np.ones(m) / m\n",
    "\n",
    "    # append to list of databases y_t and x_t\n",
    "    x_list = [x_t]\n",
    "    \n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = []\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    failure_mode = False # if reaches failure, failure mode because true and only runs lazy rounds\n",
    "    \n",
    "    def lazy_round():\n",
    "        update_list.append('no')\n",
    "        pmw_answers.append(np.dot(query, x_list[time]))\n",
    "        x_list.append(x_list[time])\n",
    "        \n",
    "    \n",
    "    # iterate through time = (0, k)\n",
    "    for time, query in enumerate(workload):\n",
    "        # compute noisy answer by adding Laplacian noise\n",
    "        a_t = np.random.laplace(loc=0, scale=sigma, size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "\n",
    "        # difference between noisy and maintained histogram answer\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        d_t_hat_list.append(d_t_hat)\n",
    "\n",
    "        # lazy round: use maintained histogram to answer the query\n",
    "        if abs(d_t_hat) <= threshold or failure_mode:\n",
    "            lazy_round()\n",
    "            continue\n",
    "\n",
    "        # update round: update histogram and return noisy answer\n",
    "        else:\n",
    "            update_times.append(time)\n",
    "\n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i, v in enumerate(y_t):\n",
    "                y_t[i] = x_list[time][i] * math.exp(-eta * r_t[i])\n",
    "    \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            if update_count > n * math.log(m, np.e) ** (1 / 2): # threshold for num updates is reached, enter failure_mode\n",
    "                failure_mode = True\n",
    "                if show_messages:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "            else: # threshold for num updates is not reached yet\n",
    "                x_list.append(x_t)\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                pmw_answers.append(a_t_hat / np.sum(x))\n",
    "                \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    \n",
    "    def print_outputs():\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Updated Database = {x_t}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{threshold=}\\n')\n",
    "        print(f'Error Scale = {sigma}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "    \n",
    "    def plot_error():\n",
    "        \"\"\"Plot absolute and relative error\"\"\"\n",
    "        plt.xticks(range(0, k, 5))\n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.locator_params(axis='x', nbins=10)\n",
    "        plt.legend(handles=[rel_line, abs_line])\n",
    "    \n",
    "    if show_messages:\n",
    "        print_outputs()\n",
    "        plot_error()\n",
    "        \n",
    "    if to_return == \"update_count\":\n",
    "        return update_count\n",
    "\n",
    "    if to_return == \"pd\":\n",
    "        x_list.pop(0).tolist() # remove the first synthetic database to keep length of lists consistent-x_list[t] represents the synthetic database at the end of time t\n",
    "        d = {\n",
    "            'queries': workload.tolist(), \n",
    "            'd_t_hat': d_t_hat_list, \n",
    "            'updated': update_list,\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce32ea",
   "metadata": {},
   "source": [
    "# Failure Scenario:\n",
    "Alice and Bob are analysts who query from a database, x_small, that uses private multiplicative weights in an online setting. Alice submits a set of 500 queries that only queries the first half of the database (indexes 0, 1, 2, 3). Alice's queries come first and use all the budget. Practically, that means Alice runs queries until output = failure. Then Bob does queries on index 5-7 on the synthetic database.\n",
    "Parameters:\n",
    "- x_small: [1, 8, 1, 1, 1, 9, 1, 1]\n",
    "- Number of Alice's queries: 500, they only query from the first four slots in x_small\n",
    "- Number of Bob's queries: 500, they only query from the last four slots in x_small\n",
    "- individual Alice or Bob settings: eps=250, beta=0.2, k=500\n",
    "- collective Alice and Bob settings: eps=500, beta=0.2, k=1000\n",
    "\n",
    "Results:\n",
    "- alice's total error individually: 7.286189769066673\n",
    "- bob's total error individually: 9.116719651841597\n",
    "- alice's total error in collective: 3.5804403438238794\n",
    "- bob's total error in collective: 7.894955328194034\n",
    "\n",
    "Conclusion:\n",
    "- In this specific experiment, the Sharing incentive and Non-interference desideratas don't seem to be violated.\n",
    "\n",
    "Next Steps:\n",
    "- Try this on the new implementation of pmw. An epsilon of 250 and 500 are absurdly high, but they were the numbers I needed to use to reach the failure mode relatively consistently in the experiments where both Alice and Bob were submitting queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a073ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04347826 0.34782609 0.04347826 0.04347826 0.04347826 0.39130435\n",
      " 0.04347826 0.04347826]\n",
      "the threshold for failure is 33.16661839182031\n"
     ]
    }
   ],
   "source": [
    "#x_small = np.array([10, 80, 13, 12, 90, 14, 17, 17])\n",
    "x_small = np.array([1, 8, 1, 1, 1, 9, 1, 1])\n",
    "normalized = x_small / x_small.sum()\n",
    "print(normalized)\n",
    "m = x_small.size  # database len\n",
    "n = x_small.sum()\n",
    "print(f'the threshold for failure is {n * math.log(m, np.e) ** (1 / 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dcb2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = np.random.randint(2, size=(500,4))\n",
    "zero_array = np.zeros((500,4))\n",
    "alice = np.hstack((random_array, zero_array))\n",
    "bob = np.hstack((zero_array, random_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0adbcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's total error individually: 7.286189769066673\n"
     ]
    }
   ],
   "source": [
    "# just alice\n",
    "alice_labels = ['Alice'] * 500\n",
    "\n",
    "alice_error_list = []\n",
    "for i in range(1000):\n",
    "    random_array = np.random.randint(2, size=(500,4))\n",
    "    alice = np.hstack((random_array, zero_array))\n",
    "    alice_query_data = pmw(workload=alice, x=x_small, eps=250, beta=0.2, k=500, to_return='pd', \n",
    "                           analyst_labels = alice_labels, show_messages=False)\n",
    "    alice_error_list.append(sum(alice_query_data.abs_error))\n",
    "print(f\"alice's total error individually: {sum(alice_error_list) / len(alice_error_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3db8050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob's total error individually: 9.116719651841597\n"
     ]
    }
   ],
   "source": [
    "# just bob\n",
    "bob_labels = ['Bob'] * 500\n",
    "\n",
    "bob_error_list = []\n",
    "for i in range(1000):\n",
    "    random_array = np.random.randint(2, size=(500,4))\n",
    "    bob = np.hstack((zero_array, random_array))\n",
    "    bob_query_data = pmw(workload=bob, x=x_small, eps=250, beta=0.2, k=500, to_return='pd', \n",
    "                         analyst_labels = bob_labels, show_messages=False)\n",
    "    bob_error_list.append(sum(bob_query_data.abs_error))\n",
    "print(f\"bob's total error individually: {sum(bob_error_list) / len(bob_error_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "477c65b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice's total error in collective: 3.5804403438238794\n",
      "bob's total error in collective: 7.894955328194034\n"
     ]
    }
   ],
   "source": [
    "# alice and bob combined\n",
    "combined_alice_error_list = []\n",
    "combined_bob_error_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    random_array = np.random.randint(2, size=(500,4))\n",
    "    alice = np.hstack((random_array, zero_array))\n",
    "    bob = np.hstack((zero_array, random_array))\n",
    "    combined_query_data = pmw(workload=np.vstack((alice, bob)), x=x_small, eps=500, beta=0.2, k=1000, to_return='pd', \n",
    "                        analyst_labels = alice_labels + bob_labels, show_messages=False)\n",
    "    combined_alice_error_list.append(sum(combined_query_data[combined_query_data.analyst=='Alice'].abs_error))\n",
    "    combined_bob_error_list.append(sum(combined_query_data[combined_query_data.analyst=='Bob'].abs_error))\n",
    "    \n",
    "print(f\"alice's total error in collective: {sum(combined_alice_error_list) / len(combined_alice_error_list)}\")\n",
    "print(f\"bob's total error in collective: {sum(combined_bob_error_list) / len(combined_bob_error_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a808c",
   "metadata": {},
   "source": [
    "Failure Task: \n",
    "- [DO] Run test on new iteration of PMW\n",
    "- [DO] Try to create an even more adversarial setting where Alice tries to take all the updates (i.e., give Alice more queries than Bob)\n",
    "- Calculate error difference. \n",
    "- Create normal distribution workloads\n",
    "- Use a smaller database so the threshold is less\n",
    "- Output when failure happened, \n",
    "- no longer update from that point and just use synthetic database (only do lazy rounds)\n",
    "- in order to make it only do lazy rounds, create variable that goes into failure_mode\n",
    "- fix synthetic database so that it actually updates\n",
    "- Create a parallel list of people - output the labelled person, i.e. \"alice\" into a list. output this as a column as well\n",
    "- PMW with just Alice and just bob - Split k and epsilon in half"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
