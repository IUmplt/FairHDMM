{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52b58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from src.hdmm.error import expected_error, strategy_supports_workload\n",
    "from src.hdmm.matrix import EkteloMatrix\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from src.hdmm.workload import AllRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec2d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:0.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64eae0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBounds(df):\n",
    "    \"\"\"\n",
    "    Returns [upper bound error, lower bound error]\n",
    "    \"\"\"\n",
    "    return [df.abs_error.min(), df.abs_error.max()]\n",
    "\n",
    "def getAverageError(df):\n",
    "    \"\"\"\n",
    "    Returns average error across all queries\n",
    "    \"\"\"\n",
    "    return df.abs_error.sum() / len(df)\n",
    "\n",
    "def printBoundsAndAvgError(df):\n",
    "    print(f'Average error is {getAverageError(df)}. Lower bound is {getBounds(df)[0]} and upper bound is {getBounds(df)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77bd3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw2(workload, x, T, eps=0.01, k=0, analyst_labels = [], \n",
    "         show_messages=True, to_return='pd', show_plot=False, show_failure_step=True):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries. \n",
    "\n",
    "    Algorithm Parameters: \n",
    "    - workload = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - T = update threshold\n",
    "    - eps = privacy budget\n",
    "    - k = number of update steps PER ANALYST\n",
    "    - analyst_labels = list of analyst names corresponding to each query in the workload\n",
    "    \n",
    "    Output Controls: \n",
    "    - show_messages argument determines whether the function will print information such as \n",
    "    error scale, threshold, update steps used, etc.\n",
    "    - to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query in the workload(showing query, d_t_hat, updated, algo_ans, real_ans, \n",
    "        abs_error, rel_error). \n",
    "        - if 'update_count', pmw() returns the update count for the total\n",
    "        amount of queries.\n",
    "    - show_plot - T/F whether the function will display a plot\n",
    "    - show_failure_step - T/F whether function prints what step failure mode is reached\n",
    "    \"\"\" \n",
    "    \n",
    "    update_steps = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        update_steps[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    eta = (math.log(m, np.e) ** (1 / 4)) / (math.sqrt(n))\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    \n",
    "    # initialize synthetic databases at time 0 (prior to any queries)\n",
    "    x_t = np.ones(m) / m\n",
    "    y_t = np.ones(m) / m\n",
    "\n",
    "    # initialize tracker lists to construct pandas dataframe at the end \n",
    "    x_list = [x_t] # create a list of x_t synthetic database at every time step\n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = [] # record times that database is updated\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    def lazy_round():\n",
    "        \"\"\"\n",
    "        \"Lazy Round\" of querying using the stored synthetic database, x_t, in list x_list.\n",
    "        \n",
    "        We call this the lazy round because it is contrasted with the updated step where we update the \n",
    "        sythetic database and answer the query using the real database.\n",
    "        \"\"\"\n",
    "        update_list.append('no')\n",
    "        pmw_answers.append(np.dot(query, x_list[time]))\n",
    "        x_list.append(x_list[time].round(3))\n",
    "    \n",
    "    # inititate first instance of SVT with half the budget and k updates; will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 = ((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    \n",
    "    for time, query in enumerate(workload):\n",
    "        \n",
    "        analyst = analyst_labels[time]\n",
    "        \n",
    "        # Do one round of sparse vector technique \n",
    "        \n",
    "        # Compute noisy answer by adding Laplacian noise\n",
    "        a_t = np.random.laplace(loc=0, scale=(2*k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "\n",
    "        # Difference between noisy and maintained histogram answer\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # Lazy round: use synthetic base to answer the query\n",
    "        if (abs(d_t_hat) <= T + rho):\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "            continue\n",
    "\n",
    "        # update round: update histogram and return noisy answer\n",
    "        else:\n",
    "            #make a new noisy query answer using some of the leftover budget\n",
    "            a_t = np.random.laplace(loc=0, scale=(2*k/eps), size=1)[0]\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            update_times.append(time)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i, v in enumerate(y_t):\n",
    "                y_t[i] = x_list[time][i] * math.exp((d_t_hat/(2*n)) * query[i]) * 20 # 20 is the learning rate\n",
    "            \n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            # if threshold for num updates is reached, just do a lazy round (synthetic database) answer\n",
    "            if update_steps[analyst] == 0: \n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "                \n",
    "            # if there are still update steps that the analyst can use, \n",
    "            # 1. update the synthetic database\n",
    "            # 2. answer the query using the noisy answer from the database itself \n",
    "            else: \n",
    "                x_list.append(x_t.round(3))\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                pmw_answers.append(a_t_hat / np.sum(x))\n",
    "                update_steps[analyst] -= 1 # use one of analyst's update steps\n",
    "\n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    if show_messages:\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Updated Database = {x_t}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.title('Error across queries:')\n",
    "        rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line,rel_line])\n",
    "        plt.xticks(range(0, len(workload), round(len(workload)/5)))\n",
    "    \n",
    "    if to_return == \"pd\":\n",
    "        # hacky fix: remove the first synthetic database to keep length of lists consistent with the\n",
    "        # other lists that comprise of the pandas dataframe\n",
    "        x_list.pop(0).tolist() \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(set(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17ca88",
   "metadata": {},
   "source": [
    "### Initializing workloads and databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a073ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small = np.array([20, 160, 20, 20, 20, 160, 20, 20])\n",
    "normalized = x_small / x_small.sum()\n",
    "m = x_small.size  # database len\n",
    "n = x_small.sum()\n",
    "#print(f'the threshold for failure is {n * math.log(m, np.e) ** (1 / 2)}')\n",
    "\n",
    "random_array = np.random.randint(2, size=(500,4))\n",
    "zero_array = np.zeros((500,4))\n",
    "alice = np.hstack((random_array, zero_array))\n",
    "bob = np.hstack((zero_array, random_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ca2fd",
   "metadata": {},
   "source": [
    "We've shown that Alice can use up all the privacy budget. \n",
    "\n",
    "Next, let's take some of the basic adaptations of pmw and see if we can get the same effects to happen or a similar effect were people get similar results indpenedently\n",
    "\n",
    "### To Dos: \n",
    "\n",
    "Instead of having a communal pool of update steps we can do, split the amount of update steps evenly across all analysts. If your update steps are not a multiple of the analysts, you can change the number of update steps.  \n",
    "\n",
    "Look for the same kind of violation where either Bob or Alice will have more overall error in the joint case as opposed to the independent case.\n",
    "\n",
    "In the independent state, you can use the existing pmw algorihtm.\n",
    "\n",
    "Suggestion: When you split it to their individual settings, give them the same amount of update steps that they would've gotten in the group. \n",
    "\n",
    "Individually - 1 ep, 5 k. together - 2 ep, 10k. \n",
    "\n",
    "### Experiments: \n",
    "Try original pmw, adapted w equal update steps pmw, individual: \n",
    "1. [done] A and B query disjoint sections\n",
    "2. [done] A queries the entire dataset except for last index. B queries entire dataset, last index inclusive. \n",
    "3. [done] A asks singleton, B asks all range queries\n",
    "4. [if time] Is total error the right metric? Context: You might run into a case where you get flat error across all of your queries. You may get a lot worse error on one specific query, but the overall error is better. Now Alice and Bob care about the same data. Alice eats all the budget (entire database except for last). Bob cares about entire database, but his queries about the last index has higher error. \n",
    "    \n",
    "    \n",
    "Scenarios to look for: \n",
    "1. Regular pmw performs poorly, but adapted pmw works well. (probably in disjoint setting)\n",
    "2. Scenarios where regular AND adapted pmw perform poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36962c66",
   "metadata": {},
   "source": [
    "## Scenario 1: Disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24d855ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_ans</th>\n",
       "      <th>real_ans</th>\n",
       "      <th>queries</th>\n",
       "      <th>updated</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>rel_error</th>\n",
       "      <th>synthetic database</th>\n",
       "      <th>analyst</th>\n",
       "      <th>d_t_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[0.122, 0.133, 0.122, 0.133, 0.122, 0.122, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>74.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[0.115, 0.136, 0.125, 0.126, 0.125, 0.125, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-68.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.53</td>\n",
       "      <td>[0.115, 0.136, 0.125, 0.126, 0.125, 0.125, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-27.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>[0.119, 0.14, 0.122, 0.13, 0.122, 0.122, 0.122...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>45.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[0.124, 0.145, 0.121, 0.128, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>43.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>[0.125, 0.146, 0.122, 0.121, 0.122, 0.122, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-57.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.66</td>\n",
       "      <td>[0.125, 0.146, 0.122, 0.121, 0.122, 0.122, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-32.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[0.125, 0.146, 0.122, 0.116, 0.122, 0.122, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-38.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[0.125, 0.146, 0.122, 0.116, 0.122, 0.122, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>34.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.125, 0.146, 0.122, 0.116, 0.122, 0.122, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>15.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.123, 0.15, 0.126, 0.12, 0.12, 0.12, 0.12, 0...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>39.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.121, 0.164, 0.124, 0.118, 0.118, 0.118, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>94.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>[0.113, 0.168, 0.116, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-76.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-37.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>99.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-10.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.66</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>31.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.49</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.54</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-61.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>74.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.46</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>54.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.48</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-48.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.111, 0.165, 0.11, 0.119, 0.119, 0.129, 0.11...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>75.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>[0.114, 0.169, 0.113, 0.122, 0.11, 0.132, 0.12...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-92.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.09</td>\n",
       "      <td>[0.115, 0.17, 0.114, 0.123, 0.104, 0.133, 0.12...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-50.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[0.113, 0.168, 0.112, 0.121, 0.106, 0.136, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>29.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[0.11, 0.163, 0.109, 0.118, 0.115, 0.148, 0.11...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>99.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>[0.111, 0.164, 0.11, 0.119, 0.116, 0.149, 0.11...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-48.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.30</td>\n",
       "      <td>[0.112, 0.165, 0.111, 0.12, 0.117, 0.15, 0.12,...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-55.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>[0.112, 0.165, 0.111, 0.12, 0.117, 0.15, 0.12,...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-37.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.157, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>60.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.16</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>24.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.57</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>118.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.63</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>29.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.57</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-32.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.57</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>87.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-15.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-18.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.38</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-29.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>64.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.68</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-21.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.54</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-90.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.36</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.57</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>110.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.57</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-28.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.35</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.63</td>\n",
       "      <td>[0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-62.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    algo_ans  real_ans                                   queries updated  \\\n",
       "0       0.42      0.41  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "1       0.10      0.09  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "2       0.12      0.04  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "3       0.48      0.46  [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "4       0.36      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "5      -0.00      0.04  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "6       0.12      0.04  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "7       0.03      0.04  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "8       0.39      0.46  [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "9       0.51      0.50  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "10      0.47      0.46  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "11      0.36      0.36  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "12      0.07      0.09  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "13      0.03      0.04  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "14      0.17      0.36  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "15      0.00      0.00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "16      0.51      0.50  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "17      0.12      0.04  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "18      0.28      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "19      0.11      0.04  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "20      0.35      0.14  [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "21      0.17      0.36  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "22      0.11      0.04  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "23      0.29      0.41  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "24      0.23      0.09  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "25      0.41      0.41  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]     yes   \n",
       "26      0.04      0.09  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]     yes   \n",
       "27     -0.00      0.04  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]     yes   \n",
       "28      0.42      0.46  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]     yes   \n",
       "29      0.47      0.41  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]     yes   \n",
       "30      0.01      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]     yes   \n",
       "31     -0.01      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]     yes   \n",
       "32      0.02      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]     yes   \n",
       "33      0.51      0.46  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]     yes   \n",
       "34      0.52      0.50  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]     yes   \n",
       "35      0.38      0.46  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]      no   \n",
       "36      0.16      0.36  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]      no   \n",
       "37      0.24      0.09  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]      no   \n",
       "38      0.12      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]      no   \n",
       "39      0.16      0.36  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]      no   \n",
       "40      0.00      0.00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "41      0.51      0.50  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]      no   \n",
       "42      0.11      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]      no   \n",
       "43      0.28      0.41  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]      no   \n",
       "44      0.12      0.04  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]      no   \n",
       "45      0.35      0.14  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]      no   \n",
       "46      0.16      0.36  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]      no   \n",
       "47      0.12      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]      no   \n",
       "48      0.27      0.41  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]      no   \n",
       "49      0.24      0.09  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]      no   \n",
       "\n",
       "    abs_error  rel_error                                 synthetic database  \\\n",
       "0        0.01       0.03  [0.122, 0.133, 0.122, 0.133, 0.122, 0.122, 0.1...   \n",
       "1        0.01       0.10  [0.115, 0.136, 0.125, 0.126, 0.125, 0.125, 0.1...   \n",
       "2        0.07       1.53  [0.115, 0.136, 0.125, 0.126, 0.125, 0.125, 0.1...   \n",
       "3        0.03       0.06  [0.119, 0.14, 0.122, 0.13, 0.122, 0.122, 0.122...   \n",
       "4        0.05       0.12  [0.124, 0.145, 0.121, 0.128, 0.121, 0.121, 0.1...   \n",
       "5        0.05       1.05  [0.125, 0.146, 0.122, 0.121, 0.122, 0.122, 0.1...   \n",
       "6        0.08       1.66  [0.125, 0.146, 0.122, 0.121, 0.122, 0.122, 0.1...   \n",
       "7        0.01       0.25  [0.125, 0.146, 0.122, 0.116, 0.122, 0.122, 0.1...   \n",
       "8        0.07       0.15  [0.125, 0.146, 0.122, 0.116, 0.122, 0.122, 0.1...   \n",
       "9        0.01       0.02  [0.125, 0.146, 0.122, 0.116, 0.122, 0.122, 0.1...   \n",
       "10       0.02       0.04  [0.123, 0.15, 0.126, 0.12, 0.12, 0.12, 0.12, 0...   \n",
       "11       0.00       0.00  [0.121, 0.164, 0.124, 0.118, 0.118, 0.118, 0.1...   \n",
       "12       0.02       0.21  [0.113, 0.168, 0.116, 0.121, 0.121, 0.121, 0.1...   \n",
       "13       0.01       0.30  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "14       0.20       0.54  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "15       0.00       0.00  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "16       0.01       0.03  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "17       0.08       1.66  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "18       0.13       0.31  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "19       0.07       1.49  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "20       0.21       1.54  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "21       0.20       0.54  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "22       0.07       1.46  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "23       0.12       0.29  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "24       0.13       1.48  [0.113, 0.168, 0.112, 0.121, 0.121, 0.121, 0.1...   \n",
       "25       0.00       0.01  [0.111, 0.165, 0.11, 0.119, 0.119, 0.129, 0.11...   \n",
       "26       0.05       0.60  [0.114, 0.169, 0.113, 0.122, 0.11, 0.132, 0.12...   \n",
       "27       0.05       1.09  [0.115, 0.17, 0.114, 0.123, 0.104, 0.133, 0.12...   \n",
       "28       0.03       0.07  [0.113, 0.168, 0.112, 0.121, 0.106, 0.136, 0.1...   \n",
       "29       0.06       0.14  [0.11, 0.163, 0.109, 0.118, 0.115, 0.148, 0.11...   \n",
       "30       0.04       0.79  [0.111, 0.164, 0.11, 0.119, 0.116, 0.149, 0.11...   \n",
       "31       0.06       1.30  [0.112, 0.165, 0.111, 0.12, 0.117, 0.15, 0.12,...   \n",
       "32       0.02       0.53  [0.112, 0.165, 0.111, 0.12, 0.117, 0.15, 0.12,...   \n",
       "33       0.05       0.11  [0.109, 0.161, 0.108, 0.117, 0.122, 0.157, 0.1...   \n",
       "34       0.02       0.03  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "35       0.07       0.16  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "36       0.21       0.57  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "37       0.15       1.63  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "38       0.07       1.57  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "39       0.21       0.57  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "40       0.00       0.00  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "41       0.01       0.01  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "42       0.06       1.38  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "43       0.13       0.32  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "44       0.08       1.68  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "45       0.21       1.54  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "46       0.21       0.57  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "47       0.07       1.57  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "48       0.14       0.35  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "49       0.15       1.63  [0.109, 0.161, 0.108, 0.117, 0.122, 0.158, 0.1...   \n",
       "\n",
       "   analyst  d_t_hat  \n",
       "0    Alice    74.77  \n",
       "1    Alice   -68.06  \n",
       "2    Alice   -27.76  \n",
       "3    Alice    45.82  \n",
       "4    Alice    43.52  \n",
       "5    Alice   -57.28  \n",
       "6    Alice   -32.14  \n",
       "7    Alice   -38.16  \n",
       "8    Alice    34.87  \n",
       "9    Alice    15.42  \n",
       "10   Alice    39.06  \n",
       "11   Alice    94.50  \n",
       "12   Alice   -76.13  \n",
       "13   Alice   -37.08  \n",
       "14   Alice    99.46  \n",
       "15   Alice     1.26  \n",
       "16   Alice   -10.95  \n",
       "17   Alice   -26.55  \n",
       "18   Alice    31.95  \n",
       "19   Alice    -3.98  \n",
       "20   Alice   -61.80  \n",
       "21   Alice    74.18  \n",
       "22   Alice   -14.99  \n",
       "23   Alice    54.38  \n",
       "24   Alice   -48.18  \n",
       "25     Bob    75.08  \n",
       "26     Bob   -92.98  \n",
       "27     Bob   -50.12  \n",
       "28     Bob    29.40  \n",
       "29     Bob    99.20  \n",
       "30     Bob   -48.14  \n",
       "31     Bob   -55.74  \n",
       "32     Bob   -37.69  \n",
       "33     Bob    60.01  \n",
       "34     Bob     5.27  \n",
       "35     Bob    24.43  \n",
       "36     Bob   118.21  \n",
       "37     Bob    29.74  \n",
       "38     Bob   -32.83  \n",
       "39     Bob    87.87  \n",
       "40     Bob   -15.06  \n",
       "41     Bob   -18.55  \n",
       "42     Bob   -29.98  \n",
       "43     Bob    64.42  \n",
       "44     Bob   -21.09  \n",
       "45     Bob   -90.18  \n",
       "46     Bob   110.93  \n",
       "47     Bob   -28.89  \n",
       "48     Bob    28.05  \n",
       "49     Bob   -62.10  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmw2(workload=np.vstack((s1alice_q, s1bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ced25535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_first</th>\n",
       "      <th>individual</th>\n",
       "      <th>bob_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.48</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1.47</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alice_first  individual  bob_first\n",
       "Alice         1.48        2.20       1.48\n",
       "Bob           1.47        2.19       1.49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize\n",
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1zero_array = np.zeros((25,4))\n",
    "s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "s1bob_q = np.hstack((s1zero_array, s1random_array))\n",
    "\n",
    "s1combined_list = []\n",
    "s1bobfirst_list = []\n",
    "s1individual_list = []\n",
    "\n",
    "for i in range(1000):\n",
    "    # combined\n",
    "    s1combined = pmw2(workload=np.vstack((s1alice_q, s1bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1combined_list.append(s1combined)\n",
    "    \n",
    "    s1bobfirst = pmw2(workload=np.vstack((s1bob_q, s1alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Bob'] * 25 + ['Alice'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1bobfirst_list.append(s1bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s1a = pmw2(workload=s1alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1b = pmw2(workload=s1bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1individual = {**s1a, **s1b}\n",
    "    s1individual_list.append(s1individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s1combined_average = dict(pd.DataFrame(s1combined_list).mean())\n",
    "s1bobfirst_average = dict(pd.DataFrame(s1bobfirst_list).mean())\n",
    "s1individual_average = dict(pd.DataFrame(s1individual_list).mean())\n",
    "\n",
    "d = {'alice_first': s1combined_average, 'individual': s1individual_average, 'bob_first': s1bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36abc58",
   "metadata": {},
   "source": [
    "Bob always receives more error in the combined setting than in the individual setting.\n",
    "\n",
    "Questions: \n",
    "\n",
    "1. Why does Bob always receives more error than Alice in the individual setting if their queries are not related? I would expect instead that their individual error would be very similar. **Bob's spike is larger**\n",
    "    \n",
    "2. Alice receives substantially more error in the individual setting than the combined setting. Is this supposed to happen? Although she receives less update steps in the individual setting, shouldn't the smaller epsilon value in the inidivual case counteract this effect? **Alice gets more update steps in the combined setting (eats Bob's)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b47e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 0.09053999999999998. Lower bound is 0.0 and upper bound is 0.248\n"
     ]
    }
   ],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s1alice_q, s1bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac519d",
   "metadata": {},
   "source": [
    "We measure average error becauase we want to think about infinite query sequences - the types of sequences that PMW are very good at. Average error is better for longer query sequences. PMW is designed to make guarantees on average error. The error will be less than $\\alpha$ with some probability of failure $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52e699",
   "metadata": {},
   "source": [
    "# Scenario 2: Last Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02ad865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_first</th>\n",
       "      <th>individual</th>\n",
       "      <th>bob_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.99</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>3.18</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alice_first  individual  bob_first\n",
       "Alice         1.99        2.94       2.93\n",
       "Bob           3.18        2.86       1.39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s2combined_list = []\n",
    "s2individual_list = []\n",
    "s2bobfirst_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    # combined\n",
    "    s2alice_q = np.hstack((np.random.randint(2, size=(25,7)), np.zeros((25,1))))\n",
    "    s2bob_q = np.random.randint(2, size=(25,8))\n",
    "\n",
    "    s2combined = pmw2(workload=np.vstack((s2alice_q, s2bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2combined_list.append(s2combined)\n",
    "\n",
    "    \n",
    "    s2bobfirst = pmw2(workload=np.vstack((s2bob_q, s2alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels= ['Bob'] * 25 + ['Alice'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2bobfirst_list.append(s1bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s2a = pmw2(workload=s2alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2b = pmw2(workload=s2bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s2individual = {**s2a, **s2b}\n",
    "    s2individual_list.append(s2individual)\n",
    "\n",
    "# find mean over multiple trials\n",
    "s2combined_average = dict(pd.DataFrame(s2combined_list).mean())\n",
    "s2individual_average = dict(pd.DataFrame(s2individual_list).mean())\n",
    "s2bobfirst_average = dict(pd.DataFrame(s1bobfirst_list).mean())\n",
    "\n",
    "d = {'alice_first': s2combined_average, 'individual': s2individual_average, 'bob_first': s2bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f9750",
   "metadata": {},
   "source": [
    "all indices except last -> all indices: 1.29 difference\n",
    "all indices -> all indices except last: 1.69 difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632f973",
   "metadata": {},
   "source": [
    "Alice is doing better than Bob in the individual and combined setting. \n",
    "\n",
    "When Bob goes first, he suffers less error than alice did when she went first. \n",
    "\n",
    "**Alice's error** in `bob_first` > **Bob's error** in `alice_first`. This makes the empirical point that if the second person queries less from the dataset than the first person, they face more error than going second if you query more from the dataset than the first person. This doesn't make sense to me. Shouldn't the second person that explores more of the dataset that has been previously unexplored experience more error than the second person in the other scenario that explores less of the dataset that had already been previous explored?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b070f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 0.11274. Lower bound is 0.0 and upper bound is 0.396\n"
     ]
    }
   ],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s2alice_q, s2bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abce05",
   "metadata": {},
   "source": [
    "# Scenario 3: Incompatible Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3a6d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_first</th>\n",
       "      <th>individual</th>\n",
       "      <th>bob_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>2.69</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>3.84</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alice_first  individual  bob_first\n",
       "Alice         2.69        3.33       3.51\n",
       "Bob           3.84        3.54       2.95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3combined_list = []\n",
    "s3individual_list = []\n",
    "s3bobfirst_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    lst = [[0] * 8 for i in range(36)]\n",
    "    for i in range(len(lst)):\n",
    "        lst[i][np.random.randint(0, 8)] = 1\n",
    "    s3bob_q = np.array(lst)\n",
    "    s3alice_q = AllRange(8).dense_matrix()\n",
    "\n",
    "    # combined\n",
    "    s3combined = pmw2(workload=np.vstack((s3alice_q, s3bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 36 + ['Bob'] * 36, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3combined_list.append(s3combined)\n",
    "    \n",
    "    \n",
    "    s3bobfirst = pmw2(workload=np.vstack((s3bob_q, s3alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Bob'] * 36 + ['Alice'] * 36, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3bobfirst_list.append(s3bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s3a = pmw2(workload=s3alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 36, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3b = pmw2(workload=s3bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 36, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s3individual = {**s3a, **s3b}\n",
    "    s3individual_list.append(s3individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s3combined_average = dict(pd.DataFrame(s3combined_list).mean())\n",
    "s3individual_average = dict(pd.DataFrame(s3individual_list).mean())\n",
    "s3bobfirst_average = dict(pd.DataFrame(s3bobfirst_list).mean())\n",
    "\n",
    "d = {'alice_first': s3combined_average, 'individual': s3individual_average, 'bob_first': s3bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b2e89",
   "metadata": {},
   "source": [
    "Alice = All Range\n",
    "\n",
    "Bob = Singleton\n",
    "\n",
    "In All Range -> Singleton case, 1.22 more error for second person\n",
    "\n",
    "In Singleton -> All Range case, 0.62 more error for second person\n",
    "\n",
    "This makes sense to me because the All Range workload includes the Singleton queries, so the synthetic database had already been updated to respond to those types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff21a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 0.08918055555555555. Lower bound is 0.0 and upper bound is 0.253\n"
     ]
    }
   ],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s3alice_q, s3bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 36 + ['Bob'] * 36, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832dd9c",
   "metadata": {},
   "source": [
    "# experiment 4: exact same workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973dc5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_first</th>\n",
       "      <th>individual</th>\n",
       "      <th>bob_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>2.05</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>3.17</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alice_first  individual  bob_first\n",
       "Alice         2.05        2.93       3.10\n",
       "Bob           3.17        2.99       1.91"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s4combined_list = []\n",
    "s4individual_list = []\n",
    "s4bobfirst_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    s4alice_q = np.random.randint(2, size=(25,8))\n",
    "    s4bob_q = s4alice_q\n",
    "\n",
    "    # combined\n",
    "    s4combined = pmw2(workload=np.vstack((s4alice_q, s4bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4combined_list.append(s4combined)\n",
    "    \n",
    "    s4bobfirst = pmw2(workload=np.vstack((s4bob_q, s4alice_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Bob'] * 25 + ['Alice'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4bobfirst_list.append(s4bobfirst)\n",
    "    \n",
    "    # individual\n",
    "    s4a = pmw2(workload=s4alice_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4b = pmw2(workload=s4bob_q, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s4individual = {**s4a, **s4b}\n",
    "    s4individual_list.append(s4individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s4combined_average = dict(pd.DataFrame(s4combined_list).mean())\n",
    "s4individual_average = dict(pd.DataFrame(s4individual_list).mean())\n",
    "s4bobfirst_average = dict(pd.DataFrame(s4bobfirst_list).mean())\n",
    "\n",
    "d = {'alice_first': s4combined_average, 'individual': s4individual_average, 'bob_first': s4bobfirst_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395753a8",
   "metadata": {},
   "source": [
    "Makes sense to me. We are just switching the orders in which Alice and Bob are querying, and they have the exact same queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594131a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 0.10706000000000002. Lower bound is 0.0 and upper bound is 0.316\n"
     ]
    }
   ],
   "source": [
    "printBoundsAndAvgError(pmw2(workload=np.vstack((s4alice_q, s4bob_q)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='pd', show_plot=False, show_messages=False, show_failure_step=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb6d0e",
   "metadata": {},
   "source": [
    "# To Do's (10/12)\n",
    "1. [DONE] Do 1000 Trials for scenario 2 and 3\n",
    "2. [DONE] Explaining the scenarios (why we chose these scenarios)\n",
    "- Output the 3 tables. Practice explaining the tables to someone who doesn't know what's going on. \n",
    "- The general idea is that we want to show that the problem exist. These experiments show that standard online answering algorithms still have problems. \n",
    "    - experiment 1: disjoint, most adversarial setting. \n",
    "    - experiment 2: if we make a less extreme setting, alice only cares about most of the dataset, we still have this problem \n",
    "    - experiment 3: even when we use the entire database and use different types of database, we still run into this problem. Bob's workload is even embedded in Alice's workload!!\n",
    "    - experiment 4: give them the exact same things, and bob is stil worse off. \n",
    "        - opposite of the free-rider problem - some folks can freely benefit from the public road without paying for it. in this case, if Bob had better error than Alice, then it would be free-rider problem. Not only are update steps better for making ur synthetic database better, update steps are better than any synthetic answer at all\n",
    "    \n",
    "    \n",
    "    \n",
    "- the multiplicative update step (non-private) = no regret learning - suppose there are true weights you give to weather experts who are guessing the weather - everytime you make an update step, the relative entropy between the weights you have and the true weights should go down. This is an average case guarantee. the problem with fairness topics is that average means nothing. \n",
    "- after tuesday (next friday) - implement PMW where each analyst is given some fraction of the total update stpes and see if the problem still remains. different from individual setting because they'd be sharing the same synthetic database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e2a24",
   "metadata": {},
   "source": [
    "# TO DO'S (10/17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1fcb55",
   "metadata": {},
   "source": [
    "- [DONE] Do experiments with Bob first, see if Alice faces the same error. \n",
    "- [DONE] What is the average error of a query?\n",
    "- [DONE] What is the query with the least and most error? \n",
    "    - To figure out what things look like for each analyst and an upper/lower bound on error\n",
    "- Write code to put the functions into production for multiple tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b108c",
   "metadata": {},
   "source": [
    "# To Do's (10/18)\n",
    "\n",
    "## Conclusions...\n",
    "We did a sanity check by reversing the order of Alice and Bob. \n",
    "\n",
    "There are mechanisms that are very specific to types of queries. H-trees are good for range queries. PMW could be the case where that PMW is good for some class of queries. We've proved that it's not\n",
    "\n",
    "## Next…\n",
    "\n",
    "Update steps matter, update steps matter but end synthetic database is also valuable. \n",
    "\n",
    "- If only the update steps matter, then if we expand these query sets to very long, they should have relatively same error as doing over the entire sequence. \n",
    "\n",
    "- If the final synthetic database is also valuable, then there should be a noticable difference \n",
    "\n",
    "**To Do:** try to make an adaptation where once you make your experiment, for some large number of timestamps, randomly choose a query: 25/25 normal, for next 950 query, pick one on random and ask it repeatedly\n",
    "\n",
    "we want to see the average error from queries as time goes on. we will dilute the effect of the update steps. you should know which analysts it's from. \n",
    "\n",
    "Alice asks queries, bob asks queries. After they've asked their 25 each. Flip a coin. If heads, alice asks her queries at random. If tails, bob asks her queries at random. we want to see the effects of answering their queries on the synthetic database. In the case where we ask incompatible workloads, we saw there was the difference. do this once for each for the four queries, loook at the average error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec6b5d",
   "metadata": {},
   "source": [
    "# Randomly Stretched Workloads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ba5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomQuery(workload):\n",
    "    \"\"\"\n",
    "    Gets random query from a workload.\n",
    "    \"\"\"\n",
    "    return workload[np.random.randint(0, workload.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b142bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomAnalyst='Bob'\n",
      "random_query=[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Alice's avg error = 0.26\n",
      "Bob's avg error = 0.26\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scenario 1\n",
    "analysts = ['Alice', 'Bob']\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "workloads = {'Alice': s1alice_q, 'Bob': s1bob_q}\n",
    "random_query = getRandomQuery(workloads[randomAnalyst])\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "\n",
    "s1combined = pmw2(workload=np.vstack((s1alice_q, s1bob_q, np.array([getRandomQuery(workloads[randomAnalyst]) for i in range(950)]))), \n",
    "                  x=x_small, eps=2, T=40, k=10,  \n",
    "                  analyst_labels=['Alice'] * 25 + ['Bob'] * 25 + [randomAnalyst] * 950, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s1combined[s1combined.analyst=='Alice'].real_ans.mean(), 2)}\")\n",
    "print(f\"Bob's avg error = {round(s1combined[s1combined.analyst=='Bob'].real_ans.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9810f376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo_ans</th>\n",
       "      <th>real_ans</th>\n",
       "      <th>queries</th>\n",
       "      <th>updated</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>rel_error</th>\n",
       "      <th>synthetic database</th>\n",
       "      <th>analyst</th>\n",
       "      <th>d_t_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[0.118, 0.127, 0.118, 0.127, 0.127, 0.127, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-64.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>[0.126, 0.136, 0.116, 0.125, 0.125, 0.125, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>75.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.128, 0.138, 0.109, 0.118, 0.127, 0.127, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-65.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.125, 0.147, 0.116, 0.115, 0.124, 0.124, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>72.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.125, 0.147, 0.116, 0.115, 0.124, 0.124, 0.1...</td>\n",
       "      <td>Alice</td>\n",
       "      <td>-13.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.53</td>\n",
       "      <td>[0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-17.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.53</td>\n",
       "      <td>[0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>[0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>44.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>16.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>no</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...</td>\n",
       "      <td>Bob</td>\n",
       "      <td>-21.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     algo_ans  real_ans                                   queries updated  \\\n",
       "0        0.10      0.09  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "1        0.42      0.41  [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "2        0.09      0.09  [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "3        0.41      0.41  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]     yes   \n",
       "4        0.00      0.00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "..        ...       ...                                       ...     ...   \n",
       "995      0.12      0.04  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]      no   \n",
       "996      0.23      0.09  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]      no   \n",
       "997      0.34      0.46  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]      no   \n",
       "998      0.00      0.00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "999      0.00      0.00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      no   \n",
       "\n",
       "     abs_error  rel_error                                 synthetic database  \\\n",
       "0         0.01       0.15  [0.118, 0.127, 0.118, 0.127, 0.127, 0.127, 0.1...   \n",
       "1         0.01       0.02  [0.126, 0.136, 0.116, 0.125, 0.125, 0.125, 0.1...   \n",
       "2         0.00       0.01  [0.128, 0.138, 0.109, 0.118, 0.127, 0.127, 0.1...   \n",
       "3         0.00       0.01  [0.125, 0.147, 0.116, 0.115, 0.124, 0.124, 0.1...   \n",
       "4         0.00       0.00  [0.125, 0.147, 0.116, 0.115, 0.124, 0.124, 0.1...   \n",
       "..         ...        ...                                                ...   \n",
       "995       0.07       1.53  [0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...   \n",
       "996       0.14       1.53  [0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...   \n",
       "997       0.11       0.24  [0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...   \n",
       "998       0.00       0.00  [0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...   \n",
       "999       0.00       0.00  [0.123, 0.195, 0.118, 0.106, 0.115, 0.115, 0.1...   \n",
       "\n",
       "    analyst  d_t_hat  \n",
       "0     Alice   -64.03  \n",
       "1     Alice    75.82  \n",
       "2     Alice   -65.73  \n",
       "3     Alice    72.82  \n",
       "4     Alice   -13.48  \n",
       "..      ...      ...  \n",
       "995     Bob   -17.86  \n",
       "996     Bob    13.50  \n",
       "997     Bob    44.40  \n",
       "998     Bob    16.12  \n",
       "999     Bob   -21.46  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14636139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04545455, 0.36363636, 0.04545455, 0.04545455, 0.04545455,\n",
       "       0.36363636, 0.04545455, 0.04545455])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_small/sum(x_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12d9403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomAnalyst='Alice'\n",
      "random_query=[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Alice's avg error = 0.06\n",
      "Bob's avg error = 0.45\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scenario 2\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "s2combined = pmw2(workload=np.vstack((s2alice_q, s2bob_q, np.array([random_query for i in range(950)]))), \n",
    "                  x=x_small, eps=2, T=40, k=10, \n",
    "                  analyst_labels=['Alice'] * 25 + ['Bob'] * 25 + [randomAnalyst] * 950, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s2combined[s2combined.analyst=='Alice'].real_ans.mean(), 2)}\")\n",
    "print(f\"Bob's avg error = {round(s2combined[s2combined.analyst=='Bob'].real_ans.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167dd5c5",
   "metadata": {},
   "source": [
    "Interesting. When Bob's queries are stretched really far, he has less error than Alice. When Alice's queries are stretched really far, she has more error than Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61910dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomAnalyst='Bob'\n",
      "random_query=[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Alice's avg error = 0.43\n",
      "Bob's avg error = 0.05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvRElEQVR4nO3deXhU1fnA8e+bCSEhILusAsGigggRAoKCQhFEBRFRARfEnxapdW3FqrWIS1ur1h2lIogrYBERFaqiRTYXAgXLIpadgJUksu9J3t8f9ybMTCbJJJkhmZv38zzzZO6555w5Zwhvzpx75lxRVYwxxnhXXEU3wBhjTHRZoDfGGI+zQG+MMR5ngd4YYzzOAr0xxnicBXpjjPE4C/TGeJCIPCAir1Z0O0zlILaO3pSViGwGGgG5fslTVPW2immRMSaU+IpugIl5A1V1XkmZRCReVXOC0nyqmltUmRB1lCp/KeoVnEFPXqTrrgih3mtTtdnUjYkKERkpIotF5BkR+RkYJyJTRORlEZkjIgeA3iLSVkTmi8huEVktIpf51VEof4jXuVFE1orIPhHZKCK3BJ0fJCIrRGSviGwQkf5u+nwR+ZOILAYOAq1F5FwRWSoie9yf5wb1Z6P7OptE5Fo3/Rci8qVbJktEphfznlwvIltEJFtE/iAim0XkQr++PuaXt5eIZPgdNxWR90Qk0339O/zOjRORGSLylojsBUa6aW/55ekmIkvc93mliPQqqW/GQ1TVHvYo0wPYDFxYxLmRQA5wO84nxyRgCrAHOA9nkFELWA88ACQAvwT2Aae7dQTnTwzxOpcCpwICXIATtDu557q65fu65ZsBZ7jn5gNbgTPd9jUCdgHXu8fD3eP6QDKw169dTYAz3edTgT/ktw/oUcT70Q7YD5wPVAeedt+fC/36+phf/l5Ahvs8DlgGjHXfp9bARuAi9/w44BhwuZs3yU17yz3fDMgGLnHP93WPG5bQtxbAbqBFRf+u2aN8DxvRm/Ka5Y4S8x+/8ju3Q1VfUNUcVT3kpn2gqovVmSZJBWoCj6vqUVX9AvgIJ8gSnF9VDwe/uKp+rKob1PEl8CnQ0z19EzBZVT9zy29X1e/9ik9R1dXqTHP0A/6rqm+67Z0KfA8MdPPmAe1FJElVf1TV1W76MaAl0FRVD6vqoiLepyuBj1R1gaoeAf7o1hmOLkBDVX3EfZ82AhOBYX55vlLVWW4/DwWVvw6Yo6pz3POfAek4gb/IvqnqVlWto6pbw2ynqaQs0JvyutwNBvmPiX7ntoXI75/WFNimgXPjW3BGoMXVUUBELhaRr0XkZxHZjRO8GrinTwE2FFM8uC1bgs5vAZqp6gFgKDAa+FFEPhaRM9w89+J8mvjWnXr6vyJeq6n/67l1ZhfXNz8tgab+f1BxPgU1KqIvocpfFVS+B9CkhL4Zj7BAb6Ip1JIu/7QdwCki4v972ALYXkIdAIhIdeA94CmgkarWAebgBF5wgt+pYbZvB05A9FfQFlX9RFX74kxtfI8zokZV/6eqv1LVpsAtwEsi8osQr/Ujzh+e/LbXwJkWyncAqOF33Njv+TZgU9Af1FqqeolfnuKWz20D3gwqn6yqjxfXN+MdFuhNRfoGJ8DdKyLV3AuEA4FpYZZPwJnvzgRyRORinCmYfJOAG0Wkj4jEiUizYkarc4DTROQaEYkXkaE48+ofiUgjEblMRJKBIzhz7bkAInKViDR369iFE3BDrQyaAQwQkR4ikgA8QuD/vxXAJSJST0QaA3f5nfsW2CsivxeRJBHxiUh7EekS1rsEbwEDReQit2yie7G3eXF9M95hgd6U14cist/v8X64BVX1KHAZcDGQBbwEjAiaRy+u/D7gDuBdnCB7DTDb7/y3wI3AMzgXZb+k8Kg9P282MAD4Hc6Uyr3AAFXNwvl/8jucUf/POBd9b3WLdgG+EZH97mvfqaqbQtS/GvgN8A7O6H4XkOGX5U1gJc4F7k+B6X5lc3H+AKYCm3Deq1eB2iW8RfnltwGDcKZ7MnFG+GPcfhXZNxFp4f6btgjndUzlZV+YMqaCiPOFs5s1jO8hGFMeNqI3xhiPs0BvjDEeZ1M3xhjjcTaiN8YYj6uUm5o1aNBAW7VqVbbCK1ZAbojVYTVrwumnl6dZxhhTaS1btixLVRuGOlcpA32rVq1IT08vW+E6dWDPnsA0nw86d4b588vbNGOMqZREJPib3QVs6sYYYzyuUo7oy+WBBwqP3Js1g6FDK6Q5xhhT0Srlqpu0tDQt89SNMcZUQSKyTFXTQp3z3oh++nRYsiQwrWlTuOgiSE2tkCYZY0xF8l6gv+WW0Bdj5861i7HGmCqpxEAvIpNxNnvaqartQ5wfA+TfeiweaItzk4Sf3b089uHshpdT1McKY4wx0RPOqpspQP+iTqrqk6qaqqqpwP3Al6r6s1+W3u55C/LGGFMBSgz0qroAZ/vScAzHuYdmhXjh8/+Sk1f5Li4bY0xFitg6eveOOf1x7viTT4FPRWSZiIwqofwoEUkXkfTMzMwyteGl+Rss0BtjTJBIXowdCCwOmrY5T1V3iMjJwGci8r37CaEQVX0FeAWc5ZVlbcTnI+/m0l3rAxObNYPLLy9rlcYYE9MiGeiHETRto6o73J873TsPdQVCBvpIEIEVFw/l0kvbResljDEm5kQk0ItIbZxbkF3nl5YMxKnqPvd5P5z7ZEZV6pzp8E4RI/pzz432yxtjTKUTzvLKqUAvoIGIZAAPAdUAVHWCm20w8KmqHvAr2gh4X0TyX+cdVf1n5Joeoq1AnynPwMF9gSd8Pvj2W1tHb4ypkkoM9Ko6PIw8U3CWYfqnbQQ6lrVhxhhjIsNT34x1Pz1E3LHcPI7k5EWlbmOMySdAcvXIh2VPBfri5KnS+r6PefDSttzcs3WJ+Z/57Aee+/y/J6BlxhjjaFCzOukPXhjxej0V6Isbz+fkOis2Jy7cGFagDw7yfds1omureuVpnjHGFCsxwReVej0V6AE+vHUsVx3dFpjYtCl7z+0FH2dR1l2Zzz21Pjeel1Lu9hljzInmrUAvsOb8i2HgmYVO5ew5DB9/XgGNMsaYiuWtQA+cO2MSvPx9YGKzZiQMGFyueqNzmdcYY6LPU4FegJ4zJsLB/YEnfD5qrl0HPX5f9rqjtKLHGGOizW4ObowxHuepQB/NUbcN6I0xscpTgR6cfZGNMcYc56lAX9pRd26eokHrLVWVvBB72tuA3hgTqzx1MRbg3Xue4Ib4rMDExo3Zc/Y5MOP4+vrs/Ufo/Ng8xg1sx0i/9fHXTfqGxeuzC1dsczfGmBjlqUAvwIZOPWFQoXuYk7f3MHA80P+45zAA/1iWERDoQwZ5Y4yJYZ4K9AC9334BnloTmNi0KQlXXA0kFsof7p0HbTxvjIlVngr0IkK3j98JuY4+ecePcN7v/fI6P4Pn6I0xxms8FeiL43+B9UhObqE9b1SVzP1HiixvU/TGmFjlqUBfVCxWYMW23QXHpz/4T5rVSXLOuQH/za+3MPaD1cXUbZHeGBObPLW8siihZme27z4UcLxmx94T1BpjjDmxvDWiL3LQXfQ8/Lqf9vHLp+azMetAkXmKr9sYYyq3cG4OPhkYAOxU1ULrFkWkF/ABsMlNmqmqj7jn+gPPAT7gVVV9PDLNLtprYydwa4PDAWlvrT/Ay3tOAkKH/JKCvDHGxLJwRvRTgBeBN4rJs1BVB/gniIgPGA/0BTKApSIyW1XXhKogMoSM0zrA4LMCUlfP+I4f07cVUSbcmo0xJjaVGOhVdYGItCpD3V2B9aq6EUBEpgGDgCgGerhk0uPwcOBF1ZGSzIEWPfio7fllrtembowxsSpSc/TdRWQlsAO4R1VXA83w/yqqM6o/p6gKRGQUMAqgRYsWZWqECHT+1+xC6+hPi4vjuuy95Qr0xhgTqyKx6mY50FJVOwIvALPc9FBj4CKviqrqK6qapqppDRs2jECzIsuWVxpjYlW5A72q7lXV/e7zOUA1EWmAM4I/xS9rc5wRf9RYKDbGmMLKHehFpLG4d/wQka5undnAUqCNiKSISAIwDJhd3terMPZXxBgTo8JZXjkV6AU0EJEM4CGgGoCqTgCuBH4tIjnAIWCYOhvI5IjIbcAnOMsrJ7tz91ETzgXTsm5tY3HeGBOrwll1M7yE8y/iLL8MdW4OMKdsTSubF/78FveeXj0gbdy/tvHRoeQT2QxjjKk0vPXNWITsZinQv0NA+rotX7Fr08/lq9vWVxpjYpSnAj3AFS8/BH8IXKo/NjeJKaf3ZsZZF1ZQq4wxpuJ4KtCLQIev5xVaR99W4rjyaG65Ar2N540xsapK7F5pjDFVmacCfSRH3SO6twys24b0xpgY5alAH0kt6tUIOLZAb4yJVZ4K9JFcGWOrbIwxXuGpi7EAf37uQx7t2SQg7YZ3/kP6/vIFbtvrxhgTqzwX6A+eVBdOPz0gLbveTg4fKd2tAi2sG2O8wnOB/tpn74V71gakPadJvNG2D291ujTseoJnbmwmxxgTqzwV6EWg7colhdbRnypxDJCE0gX6SDfOGGMqiKcuxkbatFHdKroJxhhTbp4K9JGcXhERurWuz2mNahYcG2NMLPJUoI8ki+vGGK/wVKAPbwlkeBvSS8FPCTg2xphY46lAD3D/pAXO3UX8Hpc+/S+GXfN4ueq1Eb4xJlZ5KtCLhDteD7MyY4zxAG8trwR+9cSdcMf3Ael/lxq81a4PE8+5olR1BR5b4DfGxCZPjegBWq/7N2RmBjyaZ26jz4ZvS1WPDeiNMV7hqUAfjSWQ+VVa4DfGxKoSA72ITBaRnSKyqojz14rId+5jiYh09Du3WUT+IyIrRCQ9kg2PtuCpGovzxphYFc6IfgrQv5jzm4ALVLUD8CjwStD53qqaqqppZWti+MJaXBnm1VobwRtjvKLEi7GqukBEWhVzfonf4ddA8wi0q8xyffGFonReXByH46uXqp5CF2Mt8BtjYlSk5+hvAub6HSvwqYgsE5FRxRUUkVEiki4i6ZmZmWV7dYH7J3wOeXkBj4FPfc7Iqx8uW53GGBPjIra8UkR64wT6Hn7J56nqDhE5GfhMRL5X1QWhyqvqK7jTPmlpaWVeDh+pdfSFR/A2pDfGxKaIjOhFpAPwKjBIVbPz01V1h/tzJ/A+0DUSr1dkO4Db/zQa6tYNeEx+dBi3L55ayrqCLsZanDfGxKhyB3oRaQHMBK5X1R/80pNFpFb+c6AfEHLlTiS12LQWdu8OeDTa9RPnbVlZuooKllVahDfGxLYSp25EZCrQC2ggIhnAQ0A1AFWdAIwF6gMvuUExx11h0wh4302LB95R1X9GoQ/+bY1e3VGr2RhjoiucVTfDSzh/M3BziPSNQMfCJSpWuHP4FtiNMV7hrW/GRrIuCZ6jt9BvjIlNngr0AEerJ0FcXMAjxxfPrqSTANBwvzEVxMK8MSZWeWv3SoH7X5jLy9d1Dkgf9OwCvv/fPqD0yy8twBtjYp3nRvRlHLAXYt+MNcZ4hacCvSDc+/CNUKtWwOOth67g3i+nAJH7Q2CMMbHCU1M3AI13bIJD+wPS6spBOm3/vogSxbNtio0xsc5bI/owgnHZL8ZapDfGxCZPBXpjjDGFVblAX+YpehvQG2NilOcC/YHkWuDzgc9Hns9HblwcR6sl8GOtBk4GuxhrjKliPHUxVkR44G+zmTjCuZnV5S8u4ruMPeWs0/1Z3sYZY0wF8dyIvqRrrWUd0NsWCMaYWOWtET3wx7HXwuitAPwjJ488hYMJiXzQrhePXFjsTa6KqNMCvDEmtnkq0AM0zNwBhw8DkOCmVTucQ7udG4HSL69U9zOAhXtjTKzy1NRNWOvoo98MY4ypVDwV6MNR2u9L5U/d2BS9MSZWeSrQRzIYB9dlc/XGmFjluTn63XXqUyPnCAA5eYoqHKpWnY31mgHH59xLkj/yt5G8MSbWeSrQC8KDf/4Hk0d2AWBIBNbRF9RtAd8YE6NKnLoRkckislNEVhVxXkTkeRFZLyLfiUgnv3P9RWSde+6+SDa8KCWtqrFtio0xVU04I/opwIvAG0Wcvxho4z7OAV4GzhERHzAe6AtkAEtFZLaqrilvo4siAn964Gq4ZQcA7/lN3Xx8Rg8e6H97qeoKOI5kQ42phI4dO0ZGRgaH3eXJpnJKTEykefPmVKtWLewyJQZ6VV0gIq2KyTIIeEOdofTXIlJHRJoArYD1qroRQESmuXmjFugB6uzJhmPHgOOdizuaR+uftwPhL6+0kb+pajIyMqhVqxatWrWyb4JXUqpKdnY2GRkZpKSkhF0uEqtumgHb/I4z3LSi0kMSkVEiki4i6ZmZmWVqSDR+NaXQE2O86fDhw9SvX9+CfCUmItSvX7/Un7oiEehD/VZoMekhqeorqpqmqmkNGzYsc2NKHIiHOVK35ZWmKrIgX/mV5d8oEoE+AzjF77g5sKOY9OgJ4w0Id3llaeo0xkTO+++/j4jw/ffHb/85f/58BgwYUO66R44cyYwZM4rNM3/+fJYsWVKqeufPn0/t2rVJTU0teMybN688TY2oSAT62cAId/VNN2CPqv4ILAXaiEiKiCQAw9y8UZXVoAkkJkJiIkfjEzjsS2BPYk3WnNy6XPVavDfmxJg6dSo9evRg2rRpFfL6ZQn0AD179mTFihUFjwsvvDDgvKqSl5dX5HFRcnNzS92WYOEsr5wKfAWcLiIZInKTiIwWkdFuljnARmA9MBG4FUBVc4DbgE+AtcC7qrq63C0urq3AH8e9BYcOwaFDXP3sF7S9Zyad73inYOdKu8hqTOW1f/9+Fi9ezKRJkwoF+r179zJ48GDatWvH6NGjycvLIzc3l5EjR9K+fXvOOussnnnmGQBWrFhBt27d6NChA4MHD2bXrl2FXqtVq1ZkZWUBkJ6eTq9evdi8eTMTJkzgmWeeITU1lYULF5KZmcmQIUPo0qULXbp0YfHixWH3Z/PmzbRt25Zbb72VTp06sXDhwoDjbdu2MWbMmIL2T58+HXD+2PTu3ZtrrrmGs846q6xvZ4FwVt0ML+G8Ar8p4twcnD8EJ0xZb/5dEhvQmypl7n3wv/9Ets7GZ8HFjxebZdasWfTv35/TTjuNevXqsXz5cjp1cr6a8+2337JmzRpatmxJ//79mTlzJikpKWzfvp1Vq5yv+ezevRuAESNG8MILL3DBBRcwduxYHn74YZ599tkSm9iqVStGjx5NzZo1ueeeewC45ppruPvuu+nRowdbt27loosuYu3atYXKLly4kNTU1ILj9957D5/Px7p163jttdd46aWX2Lx5c8Dxe++9x4oVK1i5ciVZWVl06dKF888/v6C/q1atKtXqmqJ465uxAn/7/WC4ZScA76mCwpH4anzapjt3D7zHbjxiTCU2depU7rrrLgCGDRvG1KlTCwJ9165dad3amYIdPnw4ixYtok+fPmzcuJHbb7+dSy+9lH79+rFnzx52797NBRdcAMANN9zAVVddVeY2zZs3jzVrjq8K37t3L/v27aNWrVoB+Xr27MlHH30UkLZ582ZatmxJt27dCtL8jxctWsTw4cPx+Xw0atSICy64gKVLl3LSSSfRtWvXiAR58FigB0g+uA/cOS2fm1Y95xhN9mWVqT4L76ZKKmHkHQ3Z2dl88cUXrFq1ChEhNzcXEeGJJ54ACg+2RIS6deuycuVKPvnkE8aPH8+7775bMH1Tkvj4+II58uKWK+bl5fHVV1+RlJRUpn4lJycXeVzcDERwufLw1u6VYeQp69SODeiNia4ZM2YwYsQItmzZwubNm9m2bRspKSksWrQIcKYyNm3aRF5eHtOnT6dHjx5kZWWRl5fHkCFDePTRR1m+fDm1a9embt26LFy4EIA333yzYHTvr1WrVixbtgxwplny1apVi3379hUc9+vXjxdffLHgeMWKFRHr8/nnn8/06dPJzc0lMzOTBQsW0LVr14jVn89TgT4cdi3WmMpp6tSpDB48OCBtyJAhvPPOOwB0796d++67j/bt25OSksLgwYPZvn07vXr1IjU1lZEjR/KXv/wFgNdff50xY8bQoUMHVqxYwdixYwu93kMPPcSdd95Jz5498fl8BekDBw7k/fffL7gY+/zzz5Oenk6HDh1o164dEyZMCNn+/Dn6/EdJyzgBBg8eTIcOHejYsSO//OUveeKJJ2jcuHHY71m4JFoXL8sjLS1N09PTS11uyMtLeON3F5F8aD9wPKjnShzpzdsx7JrHEQlv5c3TV3fkik7NuXz8YlZs282M0d1Ja1Wv1G0yJlasXbuWtm3bVnQzTBhC/VuJyDJVTQuV33Nz9DuatKTNzi0AHD6WS26esr96DZY3OwMo+/JKm7oxxsQqTwV6Acbd/ypv3+xc0R7ujsbLVacFeGNMjPPcHH0lnIkyxpgK5a0RvcCLYwbC6J+B4+voj/ni+depXfj14AdKVZcxxniBpwI9QPWjh8FdG5v/cSU+L5e6h/aWqp6Ce8ZGsG3GGFMRPDV1Y1sJG2NMYZ4K9MaY2Obz+UhNTaV9+/YMHDiwYO+aoowbN46nnnqq2DyzZs0K2MJg7NixEdlCeOTIkaSkpBSsmz/33HPLXWe0eCvQR3BAHzxHbxd5jYm+pKQkVqxYwapVq6hXrx7jx48vd53Bgf6RRx4ptIVwWT355JMF2xKH2to4Jyen2OOihJsvXN4K9MDGFqdDnTpQpw77k2qxp3oy209qyOKWHUtVjwV2YypW9+7d2b7dudfzhg0b6N+/P507d6Znz54BNyXJN3HiRLp06ULHjh0ZMmQIBw8eZMmSJcyePZsxY8aQmprKhg0bCm4+MnfuXK6++uqC8vPnz2fgwIEAfPrpp3Tv3p1OnTpx1VVXsX///rDbPW7cOEaNGkW/fv0YMWJEoeMtW7bQp08fOnToQJ8+fdi6dSvgfEL47W9/S+/evfn9739fnreuEE9djBXgsbtfYPot3QG4PiLr6G3e31Q9D3+4mjU7SreAoSTtmp7EQwPPDCtvbm4un3/+OTfddBMAo0aNYsKECbRp04ZvvvmGW2+9lS+++CKgzBVXXMGvfvUrAB588EEmTZrE7bffzmWXXcaAAQO48sorA/L37duXW265hQMHDpCcnMz06dMZOnQoWVlZPPbYY8ybN4/k5GT++te/8vTTT4fcRmHMmDE89thjAJx55pm8/fbbACxbtoxFixaRlJTEuHHjAo4HDhzIiBEjuOGGG5g8eTJ33HEHs2bNAuCHH35g3rx5AVsyRIKnAj0E7mVTnhhdaOqm7FUZY8J06NAhUlNT2bx5M507d6Zv377s37+fJUuWBGw1fOTIkUJlV61axYMPPsju3bvZv38/F110UbGvFR8fT//+/fnwww+58sor+fjjj3niiSf48ssvWbNmDeeddx4AR48epXv37iHrePLJJwv9AQG47LLLAna79D/+6quvmDlzJgDXX3899957b0G+q666KuJBHjwW6EVg4u8uhl87I5H3FEDJifOxpGUqI69+uELbZ0ysCHfkHWn5c/R79uxhwIABjB8/npEjR1KnTp0Sd40cOXIks2bNomPHjkyZMoX58+eX+HpDhw5l/Pjx1KtXjy5dulCrVi1Ulb59+zJ16tQy96O4rYmD+c8aRHJrYn+em6P35eY6E+yqCIoAcaok5hQeARhjKqfatWvz/PPP89RTT5GUlERKSgr/+Mc/AGer8ZUrVxYqs2/fPpo0acKxY8cKplCg8LbD/nr16sXy5cuZOHEiQ4cOBaBbt24sXryY9evXA3Dw4EF++OGHiPXt3HPPLbhN4ttvv02PHj0iVndRPBXoo7GO3mbojakYZ599Nh07dmTatGm8/fbbTJo0iY4dO3LmmWfywQcfFMr/6KOPcs4559C3b1/OOOOMgvRhw4bx5JNPcvbZZ7Nhw4aAMj6fjwEDBjB37lwGDBgAQMOGDZkyZQrDhw+nQ4cOdOvWLeTFX6DgIm/+4+jRoyX26/nnn+e1116jQ4cOvPnmmzz33HOleVvKJKxtikWkP/Aczk2bXlXVx4POjwGudQ/jgbZAQ1X9WUQ2A/uAXCCnqG00/ZV1m+Lhr3zNq3f1LXab4nA9M7Qjg89uzpUvLyF9yy7+Mbo7XWybYuNhtk1x7Ij4NsUi4gPGA32BDGCpiMxW1YKFqar6JPCkm38gcLeq/uxXTW9VLdu9/EohmgtkbLmlMSZWhXMxtiuwXlU3AojINGAQsKaI/MOBsl/FKKe1p3Yg7af/ArDn8DGO5Si7kmrx+alluz2Xra40xsS6cAJ9M2Cb33EGcE6ojCJSA+gP3OaXrMCnIqLA31X1lSLKjgJGAbRo0SKMZoWqAx6/9Ulm/Nr5KvKNLy3m31t3l6muYJXxTlzGGBOOcC7GhhrTFhX1BgKLg6ZtzlPVTsDFwG9E5PxQBVX1FVVNU9W0hg0bhtGs0CwcG1N2NqCp/MrybxTOiD4DOMXvuDmwo4i8wwiatlHVHe7PnSLyPs5U0IJStzQMgvDG7y6CW52LsTPd9LJcjC1Ut83hGI9LTEwkOzub+vXr2+97JaWqZGdnk5iYWKpy4QT6pUAbEUkBtuME82uCM4lIbeAC4Dq/tGQgTlX3uc/7AY+UqoWlFp0RiY10jNc1b96cjIwMMjMzK7opphiJiYk0b968VGVKDPSqmiMitwGf4CyvnKyqq0VktHt+gpt1MPCpqh7wK94IeN8dHcQD76jqP0vVwlKIxiDE9rg3VUW1atVISUmp6GaYKAhrCwRVnQPMCUqbEHQ8BZgSlLYRKN22kZWUjeeNMbHKU9+MjaSCkbwN6I0xMc5Tm5oBLG97Dj0znXX0mfuOcCw3j+watfnojJ6lqkfzx/A2lDfGxDhPBXoR4W//9wg9f+NsLzr6pcUsj9A6emOMiVWeCvQAyft3w7p1ADT+3xZaZu3lSLXq7K5xEoerlW5JEmBTN8aYmOepQC/A38cNhfuchT/5d5ssyzr64NU2trrSGBOr7GJsEfLn6G1Ab4yJdZ4K9FHdvdKuyhpjYpSnAn0k2ReljDFe4alAH83QbIHfGBOrPHUxFmBJai/6/eyso9+x+xCHj+WSlVyXGWddWK56berGGBOrPBXoRYQXrrmPfrc7N9u94+UlLNuyq9gyXVPq8e0mZ1flUxsmsyHTWbHTp+3Jbp1RbLAxxpwAngr0AE1/2gL/dLYp7rB6NUk/HWBfYjJb6zZhV43aAXkTfHG8e0t3Wt33MQCXdmjKb/ueFrpiG9AbY2KUpwK9AH/72y3wJ2dUPtZND3cdffX4wpcsbG7eGBPrPHUxtrxCBXqbmzfGxDpPBfryzqcnVvNFpiHGGFOJeCrQl1eCTd0YYzzIY4G+fEE51NRNPpvAMcbEKk9djAWY16U/l+9dD8CmrAMcOprDzpr1eC+MdfShpm5seaUxJtZ5KtCLwN+H3Mnldzo3GRlTwjr65nWTAo7r1kgolKfRSc7WxkkJNn9vjIlNYQV6EekPPIdzc/BXVfXxoPO9gA+ATW7STFV9JJyykdZm02qY9AMAvRatJ+XnA+yqUZs1jU7lx5MaFuS79KwmPDSwHQDPDUtlS/ZBurSqW6i+Ry9vT49fNKBTi8LnjDEmFpQY6EXEh7O1e18gA1gqIrNVdU1Q1oWqOqCMZSNCgD///R447Kyjv81ND7WO/qL2jTnZHa0PSm1WZJ01q8czpHPzaDTXGGNOiHAuxnYF1qvqRlU9CkwDBoVZf3nKGmOMiYBwAn0zYJvfcYabFqy7iKwUkbkicmYpyyIio0QkXUTSMzMzw2hWqDpKkbdMr2CMMbEnnEAfKiYGrzZcDrRU1Y7AC8CsUpR1ElVfUdU0VU1r2LBhqCzGGGPKIJxAnwGc4nfcHNjhn0FV96rqfvf5HKCaiDQIp2wklebLTbZs0hhTVYSz6mYp0EZEUoDtwDDgGv8MItIY+ElVVUS64vwByQZ2l1Q20j7oeQXXHnIW/6zdsZf9R47xU836zGrfO5ova4wxlVaJgV5Vc0TkNuATnCWSk1V1tYiMds9PAK4Efi0iOcAhYJiqKhCybJT6ggi8fvFNXHv3BQA8NGEJSzeHXkdvWxsYY6qKsNbRu9Mxc4LSJvg9fxF4Mdyy0dR5zTfw6AIABn+7ha67D5OVXJelp7RnY31bJmmMqXo8983YP7z1SME6+uFueqh19DZHb4ypKjy2qZkxxphgngr0pVp1E8V2GGNMZeKpQG+MMaYwbwX60nwz1ob0xpgqwlMXYwHe/uW13KLOrgvLt+xi96Fj/FSrPh+3Pb+CW2aMMRXDU4FegOm9h3PLPb0AeLyYdfQ2S2+MqSo8FejjRLjg31/Ane8DMPK7HfTfe4SdNeuxsHVn1jRqXcEtNMaYE89TgT4+TvjtzKcL1tFf4qbnShy9Ny0LWEdvd4E1xlQVnroYGxcX/nRMbl4UG2KMMZWIpwJ9fGkCvdqI3hhTNXgq0MfFSdgzMnl5FuiNMVWDpwJ9aUb0eTaiN8ZUEZ66GBsnwtMX/h8P1c4GYOEPWWQdOMJPterzWZvuAXlzbURvjKkiPBXo4+OEqZ0u4aFH+gPw4oSv+HbzzyHz2ojeGFNVeCrQ++KEIekfw7VvAnBb0Ih+efO2BXlt1Y0xpqrwXKC/54vX4Iizjr6nm54rcZz94w8B6+htRG+MqSo8eDE2vABugd4YU1V4KtDnf2EqnBBuF2ONMVWFpwJ9qb4wZYHeGFNFhBXoRaS/iKwTkfUicl+I89eKyHfuY4mIdPQ7t1lE/iMiK0QkPZKND1aaLRBs6sYYU1WUeDFWRHzAeKAvkAEsFZHZqrrGL9sm4AJV3SUiFwOvAOf4ne+tqlkRbHdI8XHCA/1u4+kWB0jw+Zjz3Q7+57d7pT9bdWOMqSrCWXXTFVivqhsBRGQaMAgoCPSqusQv/9dA80g2MlxxInzU7nz+9FA/EpKq8frfv+LbTbaO3hhTtYUT6JsB2/yOMwgcrQe7CZjrd6zApyKiwN9V9ZVQhURkFDAKoEWLFmE0q7D4OGHU1zNIuvwF8MVx39Zd7Dp4/A5Ti1ulFuS1OXpjTFURTqAPNfEdMkqKSG+cQN/DL/k8Vd0hIicDn4nI96q6oFCFzh+AVwDS0tLKFIV9ccJtX79LtSMHATjbTc+VOFrv2hEQ6G1Eb4ypKsK5GJsBnOJ33BzYEZxJRDoArwKDVDU7P11Vd7g/dwLv40wFRYUvruTu/CV+IqN9s53dKw9kwwtp8L9V8OqFMPsOGFfbeRwMPeVjjDGxJpxAvxRoIyIpIpIADANm+2cQkRbATOB6Vf3BLz1ZRGrlPwf6Aasi1fhg4SyvHB7/L+6rNs3Zj37dHMj+L8y+DTKWwvLXj2dcPy9azTTGmBOqxKkbVc0RkduATwAfMFlVV4vIaPf8BGAsUB94SUQAclQ1DWgEvO+mxQPvqOo/o9ITynGHqYPZReYzxphYF9ZeN6o6B5gTlDbB7/nNwM0hym0EOganR0tpvjB1cdZrIO4Hmt1bi864dwcseQH6PQZxvnK20BhjTjxPbWoWFyfcPvBe/tb6GA1qVmfGsgw2Zx8gK7kuS09pH5C344YJsCGMSmff7kzjnHYRtO4VlXYbY0w0eSrQx8cJX56aRvZd59OgcS3mvPYt/1qXWb5Kc486P22VjjEmRnkq0MeJ8NsFb9Lsi8egejz3/7SPXx88yk816zOrfW8+/0Vxy/+Lkj8dZIHeGBObPBXom2+bTe/lM0k4cgyANm56rsTR8ODusgV6cQO9jeiNMTHKU4G+/TdjgGMoocffNTlYhlptRG+MiW2e2qa4OL+Q7axKLLQwqBhugJfwV/IYY0xlVCUCfRxKA9lbylJa7KExxsSKKhPoSy0vN+j4WGQaY4wxJ5in5ugBuK4GY7bfBED1aj6OHMvlqdoToUkpu1oQ2N2pm/xllsYYE2O8F+ibx/Nhg94cIaEg6anE14spUIS8HOdn/hx9ro3ojTGxyXuBfu4hPth0F7n+s1InHYDUBGhfLfx6cnOCjm1Eb4yJTd4L9CuPcfqRoL1rsoCco6UL9Pkjepu6McbEOO8F+kjZvQX+MwPWf+Ycr/snHCjndgrGGFOcasnQ/daIV+upQK/iC3k7rDL5ZoLzyPfDXOdhjDHRknyyBfqS/HTJJBr/5YroVP7HrOjUa4wxUeapQC/xicefF5MvPbkXaXkroU4LaNYZTr8E6p8Ki56F9Z/DrV/Bjyvg+49h61fQ+UbwlWJ+3xhjKhFvBfqEJLg5GdmVF3giUaD+8VU4h+KSYMzmwhVc9vzx5ynnOw9jjIlxngr0cdVqQAOf8yhGvH3L1RhThXgq0EtCdZh9ELYEbV9QU+DsBGctPRCvtlTSGFN1hLXXjYj0F5F1IrJeRO4LcV5E5Hn3/Hci0incspHkq1YD1uTAzxr42JYHK46P4s9qnBTNZhhjTKVSYqAXER8wHrgYaAcMF5F2QdkuxrnPRxtgFPByKcpGTFy18AJ44ukXRqsJxhhT6YQzddMVWK+qGwFEZBowCFjjl2cQ8IaqKvC1iNQRkSZAqzDKRk5CYsCh4rf6punZMOJJaHQW1KgXlZc3xpjKKJypm2bANr/jDDctnDzhlAVAREaJSLqIpGdmlu0bqLVOqkdOXPWCO0wVBPm4OEhIhta9ILm+3UzEGFOlhBPoQ0XF4A3ei8oTTlknUfUVVU1T1bSGDRuG0azCJC6O+IREpNALW2A3xlRd4UzdZACn+B03B3aEmSchjLKRtX49ZGcHpiUlQYMGUX1ZY4yprMIJ9EuBNiKSAmwHhgHXBOWZDdzmzsGfA+xR1R9FJDOMspHVoIEFdWOM8VNioFfVHBG5DfgE8AGTVXW1iIx2z08A5gCXAOuBg8CNxZWNSk/yDRsGS5YEpjVsCDfdBLdGfrMgY4yp7MRZKFO5pKWlaXp6etkK16kDe/YEpvl80KMHzJ9f3qYZY0ylJCLLVDUt1LkqcXNwY4ypyizQG2OMx1mgN8YYj7NAb4wxHlcpL8a6yzK3lLF4A5zbgVclVa3PVa2/YH2uKsrT55aqGvLbppUy0JeHiKQXdeXZq6pan6taf8H6XFVEq882dWOMMR5ngd4YYzzOi4H+lYpuQAWoan2uav0F63NVEZU+e26O3hhjTCAvjuiNMcb4sUBvjDEe55lAfyJvQn4iicgpIvIvEVkrIqtF5E43vZ6IfCYi/3V/1vUrc7/7PqwTkYsqrvVlJyI+Efm3iHzkHnu9v3VEZIaIfO/+W3evAn2+2/2dXiUiU0Uk0Wt9FpHJIrJTRFb5pZW6jyLSWUT+4557XqSUt8lT1Zh/4GyBvAFojXOzk5VAu4puV4T61gTo5D6vBfyAc6P1J4D73PT7gL+6z9u5/a8OpLjvi6+i+1GGfv8WeAf4yD32en9fB252nycAdbzcZ5xbim4Cktzjd4GRXuszcD7QCVjll1bqPgLfAt1xbpc3F7i4NO3wyoi+4AbmqnoUyL8JecxT1R9Vdbn7fB+wFuc/ySCc4ID783L3+SBgmqoeUdVNOPcI6HpCG11OItIcuBR41S/Zy/09CScgTAJQ1aOquhsP99kVDySJSDxQA+fuc57qs6ouAH4OSi5VH0WkCXCSqn6lTtR/w69MWLwS6MO+CXksE5FWwNnAN0AjVf0RnD8GwMluNi+8F88C9wJ5fmle7m9rIBN4zZ2uelVEkvFwn1V1O/AUsBX4EeeudJ/i4T77KW0fm7nPg9PD5pVAH/ZNyGOViNQE3gPuUtW9xWUNkRYz74WIDAB2quqycIuESIuZ/rricT7ev6yqZwMHcD7SFyXm++zOSw/CmaJoCiSLyHXFFQmRFlN9DkNRfSx3370S6MO5gXnMEpFqOEH+bVWd6Sb/5H6kw/25002P9ffiPOAyEdmMMwX3SxF5C+/2F5w+ZKjqN+7xDJzA7+U+XwhsUtVMVT0GzATOxdt9zlfaPma4z4PTw+aVQF9wA3MRScC5CfnsCm5TRLhX1ycBa1X1ab9Ts4Eb3Oc3AB/4pQ8TkeruTdnb4FzIiQmqer+qNlfVVjj/jl+o6nV4tL8Aqvo/YJuInO4m9QHW4OE+40zZdBORGu7veB+c609e7nO+UvXRnd7ZJyLd3PdqhF+Z8FT0VekIXt2+BGdFygbgDxXdngj2qwfOx7TvgBXu4xKgPvA58F/3Zz2/Mn9w34d1lPLqfGV6AL04vurG0/0FUoF09995FlC3CvT5YeB7YBXwJs5qE0/1GZiKcw3iGM7I/Kay9BFIc9+nDcCLuLsahPuwLRCMMcbjvDJ1Y4wxpggW6I0xxuMs0BtjjMdZoDfGGI+zQG+MMR5ngd4YYzzOAr0xxnjc/wMIlYJREASQXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scenario 3\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "s3combined = pmw2(workload=np.vstack((s3alice_q, s3bob_q, np.array([random_query for i in range(930)]))),\n",
    "                  x=x_small, eps=2, T=40, k=10, \n",
    "                  analyst_labels=['Alice'] * 36 + ['Bob'] * 36 + [randomAnalyst] * 930, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s3combined[s3combined.analyst=='Alice'].real_ans.mean(), 2)}\")\n",
    "print(f\"Bob's avg error = {round(s3combined[s3combined.analyst=='Bob'].real_ans.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a3a09",
   "metadata": {},
   "source": [
    "Alice = all range\n",
    "\n",
    "Bob = singleton\n",
    "\n",
    "Alice has substantially more error than (.5 vs .11) Bob when her query is stretched far.\n",
    "\n",
    "Bob only has a little bit more error (.49 vs .43) than Alice when his query is stretched far.\n",
    "\n",
    "Perhaps all range queries are more susceptible to error on synthetic databases than singleton queries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c02ad2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomAnalyst='Alice'\n",
      "random_query=[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Alice's avg error = 0.056\n",
      "Bob's avg error = 0.469\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scenario 4\n",
    "randomAnalyst=analysts[np.random.randint(0, 2)]\n",
    "print(f'{randomAnalyst=}')\n",
    "print(f'random_query={list(random_query)}')\n",
    "s4combined = pmw2(workload=np.vstack((s4alice_q, s4bob_q, np.array([random_query for i in range(950)]))),\n",
    "                  x=x_small, eps=2, T=40, k=10, \n",
    "                  analyst_labels=['Alice'] * 25 + ['Bob'] * 25 + [randomAnalyst] * 950, \n",
    "                  to_return='pd', \n",
    "                  show_plot=True, show_messages=False, show_failure_step=False)\n",
    "\n",
    "print(f\"Alice's avg error = {round(s4combined[s4combined.analyst=='Alice'].real_ans.mean(), 3)}\")\n",
    "print(f\"Bob's avg error = {round(s4combined[s4combined.analyst=='Bob'].real_ans.mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1acfc8",
   "metadata": {},
   "source": [
    "Their errors are about the same, even when one of the analysts has their queries stretched really far out. Very interesting. This means that the synthetic database is doing a pretty good job. \n",
    "\n",
    "Moreover, the analyst that has their query stretched out actually ends up with less error than the analyst who didn't have their query stretched out. (0.505 > 0.5). I wonder why this is. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff92d70",
   "metadata": {},
   "source": [
    "# 10/26 Notes\n",
    "- Do a new random query for all of the 950 queries. If too slow, then copy the entire workload over many times.\n",
    "- Goal: show that very simple mechanisms don't have this bad behavior. \n",
    "\n",
    "### Cache and Reuse\n",
    "- Algorithm.\n",
    "    - For the first k queries that analysts ask, answer those queries using a constant fraction of the privacy budget. Once that's done, if someone else asks those same queries, you can output the answer that you already used. \n",
    "    - Privacy budget is split between Bob and Alice. \n",
    "        - What would've been null before is no longer null because Bob can piggy back off of Alice's answers. \n",
    "        - In the individual setting, they have 1 privacy budget. In the joint setting, they each have 1 privacy budget. Alice can't eat into Bob's privacy budget. They own their own resources, but they can collaborate s.t. no one is worse off. \n",
    "    - After you use all the privacy budget, you respond with null if it's a query that you haven't seen before. \n",
    "\n",
    "- What to look for: \n",
    "    - With the same settings, show that joint version has less error than individual error. It won't fail the sharing incentive. Measure this in both total error and total number of queries answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdca8c2",
   "metadata": {},
   "source": [
    "Psuedo code: \n",
    "- If k doesn't equal 0\n",
    "    - answer the query using laplace mechanism\n",
    "    - calculate error \n",
    "    - append to error list\n",
    "    - decrement k\n",
    "- If k equals 0\n",
    "    - append null to the error list\n",
    "    - return error list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69c2fcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = np.random.randint(2, size=(11,8))[0] \n",
    "storage = {}\n",
    "\n",
    "def cache(query, storage, ans, error):\n",
    "    \"\"\"caches query into a dictionary with values of (ans, error)\"\"\"\n",
    "    storage[np.array2string(query)] = (ans, error)\n",
    "    return storage\n",
    "    \n",
    "def is_reusable(query, storage):\n",
    "    \"\"\"returns whether or not a query is in a strategy matrix \n",
    "    (cache)\"\"\"\n",
    "    return np.array2string(query) in storage\n",
    "\n",
    "def reuse(query, storage):\n",
    "    \"\"\"returns tuple with (query answer, error) stored in \n",
    "    a storage dictionary\"\"\"\n",
    "    return storage[np.array2string(query)]\n",
    "    \n",
    "\n",
    "cache(query, storage, 0.5, 0.5)\n",
    "is_reusable(query, storage)\n",
    "reuse(query, storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d2030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_and_reuse(workload, x, eps=0.01, k=0, analyst_labels=[]):\n",
    "    \"\"\"\n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update stepss\n",
    "    \n",
    "    error_list = []\n",
    "    ans_list = []\n",
    "    updated_list = []\n",
    "    used_cache_list = []\n",
    "    \n",
    "    n = x_small.sum()\n",
    "    x_norm = x_small/sum(x_small)\n",
    "    storage = {}\n",
    "    for i, query in enumerate(workload): \n",
    "        analyst = analyst_labels[i]\n",
    "        if is_reusable(query, storage): # this analyst' query has been asked before and can be reused\n",
    "            noisy_ans, abs_error = reuse(query, storage)\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            ans_list.append(noisy_ans)\n",
    "            updated_list.append(False)\n",
    "            used_cache_list.append(True)\n",
    "        elif budgets[analyst] != 0: # this analyst still has update steps left\n",
    "            noise = np.random.laplace(0, k/(n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            abs_error = np.abs(noisy_ans - true_ans)\n",
    "            error_list.append(abs_error)\n",
    "            budgets[analyst] -= 1\n",
    "            storage = cache(query, storage, noisy_ans, abs_error)\n",
    "            \n",
    "            updated_list.append(True)\n",
    "            ans_list.append(noisy_ans)\n",
    "            used_cache_list.append(False)\n",
    "        elif budgets[analyst] == 0: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            ans_list.append(None)\n",
    "            updated_list.append(False)\n",
    "            used_cache_list.append(False)\n",
    "    d = {'queries': workload.tolist(), \n",
    "        'abs_error': error_list,\n",
    "        'ans': ans_list,\n",
    "        'updated': updated_list,\n",
    "        'used_cache': used_cache_list,\n",
    "        #'abs_error': abs_error,               \n",
    "        #'rel_error': rel_error,\n",
    "        #'synthetic database': x_list,\n",
    "        'analyst': analyst_labels,\n",
    "        #'d_t_hat': d_t_hat_list, \n",
    "    }\n",
    "    test_data = pd.DataFrame(data=d)\n",
    "    test_data = test_data.round(3)\n",
    "    test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "    return test_data\n",
    "\n",
    "random_workload = np.random.randint(2, size=(11,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58882bd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_joint</th>\n",
       "      <th>bob_joint</th>\n",
       "      <th>alice_ind</th>\n",
       "      <th>bob_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Absolute Error</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Queries Answered</th>\n",
       "      <td>21.19</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.19</td>\n",
       "      <td>21.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      alice_joint  bob_joint  alice_ind  bob_ind\n",
       "Total Absolute Error         0.24       0.25       0.25     0.23\n",
       "# Queries Answered          21.19      22.10      21.19    21.19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cache_and_reuse_s1(trials):\n",
    "    \"\"\"scenario 1\"\"\"\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        s1random_array = np.random.randint(2, size=(25,4))\n",
    "        s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "        s1bob_q = np.hstack((s1zero_array, s1random_array))\n",
    "        \n",
    "        s1_cr_ab = cache_and_reuse(np.vstack((s1alice_q, s1bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        num_q_unanswered['alice_joint'] += (~s1_cr_ab[s1_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s1_cr_ab[s1_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s1_cr_ab[s1_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s1_cr_ab[s1_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        s1_cr_a = cache_and_reuse(s1alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        num_q_unanswered['alice_ind'] += (~s1_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s1_cr_a.abs_error.sum()\n",
    "\n",
    "        s1_cr_b = cache_and_reuse(s1bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        num_q_unanswered['bob_ind'] += (~s1_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s1_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_and_reuse_s1(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd529308",
   "metadata": {},
   "source": [
    "Bob can answer more queries in the joint case than in the individual case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c12aff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_joint</th>\n",
       "      <th>bob_joint</th>\n",
       "      <th>alice_ind</th>\n",
       "      <th>bob_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Absolute Error</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Queries Answered</th>\n",
       "      <td>11.55</td>\n",
       "      <td>11.65</td>\n",
       "      <td>11.55</td>\n",
       "      <td>10.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      alice_joint  bob_joint  alice_ind  bob_ind\n",
       "Total Absolute Error         0.13       0.13       0.14     0.13\n",
       "# Queries Answered          11.55      11.65      11.55    10.81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cache_and_reuse_s2(trials):\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        s2alice_q = np.hstack((np.random.randint(2, size=(25,7)), np.zeros((25,1))))\n",
    "        s2bob_q = np.random.randint(2, size=(25,8))\n",
    "\n",
    "        s2_cr_ab = cache_and_reuse(np.vstack((s2alice_q, s2bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        num_q_unanswered['alice_joint'] += (~s2_cr_ab[s2_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s2_cr_ab[s2_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s2_cr_ab[s2_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s2_cr_ab[s2_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        s2_cr_a = cache_and_reuse(s2alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        num_q_unanswered['alice_ind'] += (~s2_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s2_cr_a.abs_error.sum()\n",
    "\n",
    "        s2_cr_b = cache_and_reuse(s2bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        num_q_unanswered['bob_ind'] += (~s2_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s2_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_and_reuse_s2(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67967352",
   "metadata": {},
   "source": [
    "Bob is able to answer slightly less queries in the independent case than in the joint case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94628cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_joint</th>\n",
       "      <th>bob_joint</th>\n",
       "      <th>alice_ind</th>\n",
       "      <th>bob_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Absolute Error</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Queries Answered</th>\n",
       "      <td>36.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      alice_joint  bob_joint  alice_ind  bob_ind\n",
       "Total Absolute Error         0.42       0.22       0.28     0.19\n",
       "# Queries Answered          36.00      18.00      36.00    10.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let Alice be the singleton asker, and Bob be the all range asker in this case: \n",
    "\n",
    "def cache_and_reuse_s3(trials):\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        lst = [[0] * 8 for i in range(36)]\n",
    "        for i in range(len(lst)):\n",
    "            lst[i][np.random.randint(0, 8)] = 1\n",
    "        s3alice_q = np.array(lst)\n",
    "        s3bob_q = AllRange(8).dense_matrix()\n",
    "        print(s3bob_q)\n",
    "\n",
    "        s3_cr_ab = cache_and_reuse(np.vstack((s3alice_q, s3bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 36 + ['Bob'] * 36)\n",
    "        num_q_unanswered['alice_joint'] += (~s3_cr_ab[s3_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s3_cr_ab[s3_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s3_cr_ab[s3_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s3_cr_ab[s3_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        s3_cr_a = cache_and_reuse(s3alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 36)\n",
    "        num_q_unanswered['alice_ind'] += (~s3_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s3_cr_a.abs_error.sum()\n",
    "\n",
    "        s3_cr_b = cache_and_reuse(s3bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 36)\n",
    "        num_q_unanswered['bob_ind'] += (~s3_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s3_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_and_reuse_s3(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d6617",
   "metadata": {},
   "source": [
    "Bob can ask 10 queries using the update steps and 8 from reusing Alice's singletons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4aa969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_joint</th>\n",
       "      <th>bob_joint</th>\n",
       "      <th>alice_ind</th>\n",
       "      <th>bob_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Absolute Error</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th># Queries Answered</th>\n",
       "      <td>10.57</td>\n",
       "      <td>20.93</td>\n",
       "      <td>10.57</td>\n",
       "      <td>10.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      alice_joint  bob_joint  alice_ind  bob_ind\n",
       "Total Absolute Error         0.12       0.24       0.12     0.12\n",
       "# Queries Answered          10.57      20.93      10.57    10.57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cache_and_reuse_s4(trials):\n",
    "    num_q_unanswered = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "    abs_error_dict = dict.fromkeys(['alice_joint', 'bob_joint', 'alice_ind', 'bob_ind'], 0)\n",
    "\n",
    "    for i in range(trials):\n",
    "        s4alice_q = np.random.randint(2, size=(25,8))\n",
    "        s4bob_q = s4alice_q\n",
    "\n",
    "        s4_cr_ab = cache_and_reuse(np.vstack((s4alice_q, s4bob_q)), x_small, eps=2, k=10, analyst_labels=['Alice'] * 25 + ['Bob'] * 25)\n",
    "        num_q_unanswered['alice_joint'] += (~s4_cr_ab[s4_cr_ab.analyst=='Alice'].isNa).sum()\n",
    "        num_q_unanswered['bob_joint'] += (~s4_cr_ab[s4_cr_ab.analyst=='Bob'].isNa).sum()\n",
    "        abs_error_dict['alice_joint'] += s4_cr_ab[s4_cr_ab.analyst=='Alice'].abs_error.sum()\n",
    "        abs_error_dict['bob_joint'] += s4_cr_ab[s4_cr_ab.analyst=='Bob'].abs_error.sum()\n",
    "\n",
    "        s4_cr_a = cache_and_reuse(s4alice_q, x_small, eps=2, k=10, analyst_labels=['Alice'] * 25)\n",
    "        num_q_unanswered['alice_ind'] += (~s4_cr_a.isNa).sum()\n",
    "        abs_error_dict['alice_ind'] += s4_cr_a.abs_error.sum()\n",
    "\n",
    "        s4_cr_b = cache_and_reuse(s4bob_q, x_small, eps=2, k=10, analyst_labels=['Bob'] * 25)\n",
    "        num_q_unanswered['bob_ind'] += (~s4_cr_b.isNa).sum()\n",
    "        abs_error_dict['bob_ind'] += s4_cr_b.abs_error.sum()\n",
    "\n",
    "\n",
    "    avg_q_ans = {k: v / trials for k, v in num_q_unanswered.items()}\n",
    "    avg_abs_error = {k: round(v / trials, 2) for k, v in abs_error_dict.items()}\n",
    "\n",
    "    #visualization\n",
    "    display(pd.DataFrame([avg_abs_error, avg_q_ans], index=['Total Absolute Error', '# Queries Answered']))\n",
    "\n",
    "cache_and_reuse_s4(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1db800",
   "metadata": {},
   "source": [
    "Bob can ask exactly double because he is able to conserve his own update steps by using the query answers that Alice answered for him. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31f19b",
   "metadata": {},
   "source": [
    "# To-do's (11/9): \n",
    "- For generating workloads, don't allow repeated queries to be asked in a workload.\n",
    "- Implement average error. \n",
    "- Implement the number of times we cannot answer the query\n",
    "- Try to expand this to cache and reconstruct - essentially replace reuse with reconstruct. \n",
    "\n",
    "Reconstruction step: \n",
    "\n",
    "reconstruction - i don't have this exact query, but the sum of queries i already have might be the answer you are looking for. \n",
    "\n",
    "Reconstruction step is already pre-coded. There is a function in the matrix mechanism files that is the expected error of a workload. Store your cache in matrix form. takes a workload, strategy A, and an epsilon, and gives you an expected error. \n",
    "\n",
    "Workload would be single query\n",
    "\n",
    "Strategy of all the queries that have been saved in the cache\n",
    "\n",
    "eps you use for the function = n / k * epsilon, where n = # of queries in the strategy matrix, k = is the total number of update steps across all analysts. (take a look at the hdmm paper if you still want to learn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113aa760",
   "metadata": {},
   "source": [
    "### Nov 12 Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0897bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0.]]\n",
      "22.0\n",
      "0.0022\n"
     ]
    }
   ],
   "source": [
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "\n",
    "print(s1alice_q[0:1])\n",
    "print(s1alice_q)\n",
    "\n",
    "print(expected_error(s1alice_q, s1alice_q[0:1], eps = 1))\n",
    "print(expected_error(s1alice_q, s1alice_q[0:1], eps = 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d14695",
   "metadata": {},
   "source": [
    "Realistically the error should be zero for this query, because the query is literally drawn from the first query in the strategy matrix. Not sure why the error is a positive number. \n",
    "\n",
    "However, the behavior of error decreasing when epsilon approaches infinity is accurate in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1ad76a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing on separate parts of the array: \n",
    "expected_error(s1bob_q[0:1], s1alice_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54906555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 1, 1]])\n",
    "b = np.array([[1, 1, 1]])\n",
    "np.concatenate((a, b), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8321243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 1, 1]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(a, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4035b",
   "metadata": {},
   "source": [
    "eps you use for the function = n / k * epsilon, where n = # of queries in the strategy matrix, k = is the total number of update steps across all analysts. (take a look at the hdmm paper if you still want to learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9b8ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_strategy(query, strategy):\n",
    "    \"\"\"Append query to the end fo the strategy matrix\"\"\"\n",
    "    return np.concatenate((strategy, query), axis = 0)\n",
    "\n",
    "def cache_and_reconstruct(workload, x, eps=0.01, k=0, analyst_labels=[]):\n",
    "    \"\"\"\n",
    "    Takes in workload, database, eps (privacy budget), k (number of total update steps PER ANALYST). \n",
    "    \n",
    "    Returns list of error per query.\n",
    "    \"\"\"\n",
    "    budgets = {}\n",
    "    for analyst in list(set(analyst_labels)): \n",
    "        budgets[analyst] = k # each analyst starts with k update steps\n",
    "    \n",
    "    numAnalysts = len(budgets)\n",
    "    error_list = []\n",
    "    updated_list = []\n",
    "    used_reconstruct_list = []\n",
    "    \n",
    "    n = x_small.sum()\n",
    "    x_norm = x_small/sum(x_small) # normalize database\n",
    "    strategy = workload[0 : 1]\n",
    "    for i, query in enumerate(workload): \n",
    "        query = np.expand_dims(query, axis = 0)\n",
    "        analyst = analyst_labels[i]\n",
    "        \n",
    "        if budgets[analyst] != 0: # this analyst still has update steps left\n",
    "            noise = np.random.laplace(0, k/(n * eps), 1)[0]\n",
    "            noisy_ans = (np.dot(query, x_norm)) + noise\n",
    "            true_ans = np.matmul(query, x_norm)\n",
    "            error_list.append(np.abs(noisy_ans - true_ans)[0]) \n",
    "            budgets[analyst] -= 1 \n",
    "            if i != 0:\n",
    "                strategy = add_to_strategy(query, strategy)\n",
    "            \n",
    "            updated_list.append(True)\n",
    "            used_reconstruct_list.append(False)\n",
    "            \n",
    "        elif strategy_supports_workload(EkteloMatrix(query), EkteloMatrix(strategy)): # how to convert numpy array to ektelo matrix https://github.com/yikai-wu/Multi-Analyst-DP/blob/fadc7ac1d20199e8b31914f44323e51a05ed072d/src/hdmm/matrix.py#L34\n",
    "            \n",
    "            abs_error = expected_error(query, strategy, eps = len(strategy) / (k * numAnalysts) * eps) # do i mult by 100\n",
    "            \n",
    "            error_list.append(abs_error)\n",
    "            updated_list.append(False)\n",
    "            used_reconstruct_list.append(True) \n",
    "            \n",
    "        elif budgets[analyst] == 0: # this analyst has run out of update steps\n",
    "            error_list.append(None)\n",
    "            updated_list.append(False)\n",
    "            used_reconstruct_list.append(False)\n",
    "        \n",
    "            \n",
    "    d = {'queries': workload.tolist(), \n",
    "        'abs_error': error_list,\n",
    "        'updated': updated_list,\n",
    "        'used_reconstruct': used_reconstruct_list,\n",
    "        'analyst': analyst_labels,\n",
    "    }\n",
    "    test_data = pd.DataFrame(data=d)\n",
    "    test_data = test_data.round(3)\n",
    "    test_data['isNa'] = np.where(test_data.abs_error.isnull(), True, False)\n",
    "    return test_data\n",
    "\n",
    "random_workload = np.random.randint(2, size=(11,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2ab2088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queries</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>updated</th>\n",
       "      <th>used_reconstruct</th>\n",
       "      <th>analyst</th>\n",
       "      <th>isNa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.03</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>48.24</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>43.67</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>68.04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>68.04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>55.35</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>23.36</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>48.24</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>48.24</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>38.08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>38.08</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>31.48</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>47.22</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>49.76</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>48.24</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>31.99</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Alice</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>12.06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>10.92</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>17.01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>17.01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>13.84</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>5.84</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>12.06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>12.06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>9.52</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>9.52</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>7.87</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>11.81</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>12.44</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>12.06</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>8.00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Bob</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     queries  abs_error  updated  \\\n",
       "0   [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]       0.00     True   \n",
       "1   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]       0.01     True   \n",
       "2   [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.01     True   \n",
       "3   [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.01     True   \n",
       "4   [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.02     True   \n",
       "5   [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]       0.00     True   \n",
       "6   [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.00     True   \n",
       "7   [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.03     True   \n",
       "8   [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.01     True   \n",
       "9   [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]       0.00     True   \n",
       "10  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      48.24    False   \n",
       "11  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      43.67    False   \n",
       "12  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      68.04    False   \n",
       "13  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      68.04    False   \n",
       "14  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      55.35    False   \n",
       "15  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      23.36    False   \n",
       "16  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      48.24    False   \n",
       "17  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      48.24    False   \n",
       "18  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      38.08    False   \n",
       "19  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]      38.08    False   \n",
       "20  [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]      31.48    False   \n",
       "21  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]      47.22    False   \n",
       "22  [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      49.76    False   \n",
       "23  [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      48.24    False   \n",
       "24  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]      31.99    False   \n",
       "25  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]       0.02     True   \n",
       "26  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]       0.00     True   \n",
       "27  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]       0.01     True   \n",
       "28  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]       0.01     True   \n",
       "29  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]       0.00     True   \n",
       "30  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]       0.00     True   \n",
       "31  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]       0.01     True   \n",
       "32  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]       0.00     True   \n",
       "33  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]       0.01     True   \n",
       "34  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]       0.01     True   \n",
       "35  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]      12.06    False   \n",
       "36  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]      10.92    False   \n",
       "37  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]      17.01    False   \n",
       "38  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]      17.01    False   \n",
       "39  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]      13.84    False   \n",
       "40  [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]       5.84    False   \n",
       "41  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]      12.06    False   \n",
       "42  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]      12.06    False   \n",
       "43  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]       9.52    False   \n",
       "44  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]       9.52    False   \n",
       "45  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]       7.87    False   \n",
       "46  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]      11.81    False   \n",
       "47  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]      12.44    False   \n",
       "48  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]      12.06    False   \n",
       "49  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]       8.00    False   \n",
       "\n",
       "    used_reconstruct analyst   isNa  \n",
       "0              False   Alice  False  \n",
       "1              False   Alice  False  \n",
       "2              False   Alice  False  \n",
       "3              False   Alice  False  \n",
       "4              False   Alice  False  \n",
       "5              False   Alice  False  \n",
       "6              False   Alice  False  \n",
       "7              False   Alice  False  \n",
       "8              False   Alice  False  \n",
       "9              False   Alice  False  \n",
       "10              True   Alice  False  \n",
       "11              True   Alice  False  \n",
       "12              True   Alice  False  \n",
       "13              True   Alice  False  \n",
       "14              True   Alice  False  \n",
       "15              True   Alice  False  \n",
       "16              True   Alice  False  \n",
       "17              True   Alice  False  \n",
       "18              True   Alice  False  \n",
       "19              True   Alice  False  \n",
       "20              True   Alice  False  \n",
       "21              True   Alice  False  \n",
       "22              True   Alice  False  \n",
       "23              True   Alice  False  \n",
       "24              True   Alice  False  \n",
       "25             False     Bob  False  \n",
       "26             False     Bob  False  \n",
       "27             False     Bob  False  \n",
       "28             False     Bob  False  \n",
       "29             False     Bob  False  \n",
       "30             False     Bob  False  \n",
       "31             False     Bob  False  \n",
       "32             False     Bob  False  \n",
       "33             False     Bob  False  \n",
       "34             False     Bob  False  \n",
       "35              True     Bob  False  \n",
       "36              True     Bob  False  \n",
       "37              True     Bob  False  \n",
       "38              True     Bob  False  \n",
       "39              True     Bob  False  \n",
       "40              True     Bob  False  \n",
       "41              True     Bob  False  \n",
       "42              True     Bob  False  \n",
       "43              True     Bob  False  \n",
       "44              True     Bob  False  \n",
       "45              True     Bob  False  \n",
       "46              True     Bob  False  \n",
       "47              True     Bob  False  \n",
       "48              True     Bob  False  \n",
       "49              True     Bob  False  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1alice_q = np.hstack((s1random_array, s1zero_array))\n",
    "s1bob_q = np.hstack((s1zero_array, s1random_array))\n",
    "\n",
    "cache_and_reconstruct(np.vstack((s1alice_q, s1bob_q)), x_small, eps=2, k=10, \n",
    "                      analyst_labels=['Alice'] * 25 + ['Bob'] * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd2b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e2f1c6",
   "metadata": {},
   "source": [
    "# Long-term To-do's (11/9):\n",
    "Results: \n",
    "- Look at Yikai’s papers to see how to structure the results of your experiments for the papers.\n",
    "- Toy results (shown in the definition), larger evaluations (testing efficacy on larger experiments on the cluster. Datasets like this don’t work. Make a stochastic process for generating these sets) \n",
    "- Try to get these done in Janurary. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b520d0",
   "metadata": {},
   "source": [
    "# 11/12 To-do's: \n",
    "- Fix cache and reconstruct cache epsilon step\n",
    "- Run cache and reconstruct on all settings\n",
    "- [done] New implementation of PMW with splitting budget "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
