{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a3957c7",
   "metadata": {},
   "source": [
    "# To Do list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f52b58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "77bd3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmw2(workload, x, T, eps=0.01, k=0, show_messages=True, to_return='pd', analyst_labels = [],\n",
    "       show_plot=False, show_failure_step=True):\n",
    "    \"\"\"\n",
    "    Implement Private Multiplicative Weights Mechanism (PMW) on a workload of\n",
    "    linear queries. New arguments to allow for optimizing the amount of\n",
    "    privacy budget used in each step.\n",
    "    \n",
    "    to_return argument determines what the function will return. \n",
    "        - if 'pd', pmw() returns pandas df with test data for each \n",
    "        query (query, d_t_hat, updated, algo_ans, real_ans, abs_error, \n",
    "        rel_error). \n",
    "        - if 'update_count', pmw() returns the update count for the total\n",
    "        amount of queries\n",
    "\n",
    "    - W = workload of queries (M x k numpy array)\n",
    "    - x = true database (M x 1 numpy array)\n",
    "    - eps = privacy budget\n",
    "    - k = number of update steps\n",
    "    - T  = update threshold\n",
    "    \"\"\" \n",
    "    \n",
    "    # initialize constants\n",
    "    m = x.size  # database len\n",
    "    n = x.sum()\n",
    "    eta = (math.log(m, np.e) ** (1 / 4)) / (math.sqrt(n))\n",
    "    # Set k to be the desired number of update rounds\n",
    "    if k==0: # essentially, if k hasn't been changed from its default value, use the length of the workload\n",
    "        k = len(workload)  # num of queries\n",
    "    delta = 1 / (n * math.log(n, np.e))\n",
    "    x_norm = x / np.sum(x)\n",
    "    # synthetic databases at time 0 (prior to any queries)\n",
    "    y_t = np.ones(m) / m\n",
    "    x_t = np.ones(m) / m\n",
    "\n",
    "    # append to list of databases y_t and x_t\n",
    "    x_list = [x_t]\n",
    "    \n",
    "    update_list = []\n",
    "    update_count = 0\n",
    "    pmw_answers = []\n",
    "    update_times = []\n",
    "    d_t_hat_list = []\n",
    "    \n",
    "    failure_mode = False # if reaches failure, failure mode because true and only runs lazy rounds\n",
    "    \n",
    "    def lazy_round():\n",
    "        update_list.append('no')\n",
    "        pmw_answers.append(np.dot(query, x_list[time]))\n",
    "        x_list.append(x_list[time].round(3))\n",
    "    \n",
    "    #inititate first instance of SVT with half the budget and k updates\n",
    "    #will be reset in the main loop\n",
    "    SVTtrigger = False \n",
    "    SVTepsilon1 =((eps/2)/2)\n",
    "    SVTepsilon2 = ((eps/2)/2)\n",
    "    rho = np.random.laplace(loc=0, scale=(1/SVTepsilon1), size=1)[0]\n",
    "    # iterate through time \n",
    "    for time, query in enumerate(workload):\n",
    "        # Do one round of sparce vector technique \n",
    "        \n",
    "        # compute noisy answer by adding Laplacian noise\n",
    "        a_t = np.random.laplace(loc=0, scale=(2*k/SVTepsilon2), size=1)[0]\n",
    "        a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "\n",
    "        # difference between noisy and maintained histogram answer\n",
    "        d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "        \n",
    "        # lazy round: use maintained histogram to answer the query\n",
    "        if (abs(d_t_hat) <= T + rho) or failure_mode:\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            lazy_round()\n",
    "            continue\n",
    "\n",
    "        # update round: update histogram and return noisy answer\n",
    "        else:\n",
    "            update_times.append(time)\n",
    "            #make a new noisy query answer using some of the leftover budget\n",
    "            a_t = np.random.laplace(loc=0, scale=(2*k/eps), size=1)[0]\n",
    "            a_t_hat = (np.dot(query, x_norm)*n ) + a_t\n",
    "            d_t_hat = a_t_hat - (n*np.dot(query, x_list[time]))\n",
    "            d_t_hat_list.append(d_t_hat)\n",
    "            \n",
    "            # step a\n",
    "            if d_t_hat < 0:\n",
    "                r_t = query\n",
    "            else:\n",
    "                r_t = np.ones(m) - query\n",
    "            for i, v in enumerate(y_t):\n",
    "                #y_t[i] = x_list[time][i] * math.exp(-eta * r_t[i])\n",
    "                y_t[i] = x_list[time][i] * math.exp((d_t_hat/(2*n)) * query[i])\n",
    "            \n",
    "            #print(d_t_hat)\n",
    "            #print(query)\n",
    "            #print(x_list[time])\n",
    "            # step b\n",
    "            x_t = y_t / np.sum(y_t)\n",
    "            update_count = update_list.count('yes')\n",
    "            \n",
    "            if update_count >= k: # threshold for num updates is reached, enter failure_mode\n",
    "                failure_mode = True\n",
    "                if show_failure_step:\n",
    "                    print(f'Failure mode reached at query number {time}: {query}')\n",
    "                lazy_round()\n",
    "            else: # threshold for num updates is not reached yet\n",
    "                x_list.append(x_t.round(3))\n",
    "                update_list.append('yes') # increment number of updates counter\n",
    "                pmw_answers.append(a_t_hat / np.sum(x))\n",
    "                \n",
    "    update_count = update_list.count('yes')      \n",
    "\n",
    "    # calculate error\n",
    "    real_ans = np.matmul(workload, x_norm)\n",
    "    abs_error = np.abs(pmw_answers - real_ans)\n",
    "    rel_error = np.abs(abs_error / np.where(real_ans == 0, 0.000001,\n",
    "                                                real_ans))\n",
    "    \n",
    "    def print_outputs():\n",
    "        np.set_printoptions(suppress=True)\n",
    "        \"\"\"Print inputes/outputs to analyze each query\"\"\"\n",
    "        print(f'Original database: {x}\\n')\n",
    "        print(f'Normalized database: {x_norm}\\n')\n",
    "        print(f'Updated Database = {x_t}\\n')\n",
    "        print(f'Update Count = {update_count}\\n')\n",
    "        print(f'{T=}\\n')\n",
    "        print(f'Error Scale Query Answer= {2*((2*k/eps)**2)}\\n')\n",
    "        print(f'Error Scale SVT= {2*((2*k/SVTepsilon2)**2)}\\n')\n",
    "        print(f'Update Parameter Scale = {eta}\\n')\n",
    "        print(f'{delta=}\\n')\n",
    "    \n",
    "    if show_messages:\n",
    "        print_outputs()\n",
    "        \n",
    "    if show_plot: \n",
    "        plt.xticks(range(0, len(workload), 5))\n",
    "        plt.title('Error across queries:')\n",
    "        #rel_line, = plt.plot(rel_error, label='Relative Error')\n",
    "        abs_line, = plt.plot(abs_error, label='Absolute Error')\n",
    "        for xc in update_times:\n",
    "            plt.axvline(x=xc, color='red', label='Update Times', linestyle='dashed')\n",
    "        plt.legend(handles=[abs_line]) #,rel_line])\n",
    "        \n",
    "    if to_return == \"pd\":\n",
    "        x_list.pop(0).tolist() # remove the first synthetic database to keep length of lists consistent-x_list[t] represents the synthetic database at the end of time t\n",
    "        \n",
    "        \n",
    "        d = {\n",
    "            'algo_ans': pmw_answers,\n",
    "            'real_ans': real_ans.tolist(),\n",
    "            'queries': workload.tolist(), \n",
    "            'updated': update_list,\n",
    "            'abs_error': abs_error,               \n",
    "#            'rel_error': rel_error,\n",
    "            'synthetic database': x_list,\n",
    "            'analyst': analyst_labels,\n",
    "            'd_t_hat': d_t_hat_list, \n",
    "\n",
    "             }\n",
    "        test_data = pd.DataFrame(data=d)\n",
    "        test_data = test_data.round(3)\n",
    "        return test_data\n",
    "    \n",
    "    if to_return == \"error\":\n",
    "        #unique_analysts = list(OrderedDict.fromkeys(analyst_labels))\n",
    "        \n",
    "        d = {'analyst': analyst_labels,\n",
    "             'abs_error': abs_error,               \n",
    "             'rel_error': rel_error,}\n",
    "        data = pd.DataFrame(data=d)\n",
    "        data = data.round(3)\n",
    "        \n",
    "        analyst_error = {}\n",
    "        for analyst in list(set(analyst_labels)):\n",
    "            analyst_error[analyst] = data[data.analyst==analyst]['abs_error'].sum()\n",
    "        return analyst_error\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17ca88",
   "metadata": {},
   "source": [
    "### Initializing workloads and databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a073ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_small = np.array([20, 160, 20, 20, 20, 180, 20, 20])\n",
    "normalized = x_small / x_small.sum()\n",
    "m = x_small.size  # database len\n",
    "n = x_small.sum()\n",
    "#print(f'the threshold for failure is {n * math.log(m, np.e) ** (1 / 2)}')\n",
    "\n",
    "random_array = np.random.randint(2, size=(500,4))\n",
    "zero_array = np.zeros((500,4))\n",
    "alice = np.hstack((random_array, zero_array))\n",
    "bob = np.hstack((zero_array, random_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ca2fd",
   "metadata": {},
   "source": [
    "We've shown that Alice can use up all the privacy budget. \n",
    "\n",
    "Next, let's take some of the basic adaptations of pmw and see if we can get the same effects to happen or a similar effect were people get similar results indpenedently\n",
    "\n",
    "### To Dos: \n",
    "\n",
    "Instead of having a communal pool of update steps we can do, split the amount of update steps evenly across all analysts. If your update steps are not a multiple of the analysts, you can change the number of update steps.  \n",
    "\n",
    "Look for the same kind of violation where either Bob or Alice will have more overall error in the joint case as opposed to the independent case.\n",
    "\n",
    "In the independent state, you can use the existing pmw algorihtm.\n",
    "\n",
    "Suggestion: When you split it to their individual settings, give them the same amount of update steps that they would've gotten in the group. \n",
    "\n",
    "Individually - 1 ep, 5 k. together - 2 ep, 10k. \n",
    "\n",
    "### Experiments: \n",
    "Try original pmw, adapted w equal update steps pmw, individual: \n",
    "1. [done] A and B query disjoint sections\n",
    "2. A queries the entire dataset except for last index. B queries entire dataset, last index inclusive. \n",
    "3. A asks singleton, B asks all range queries\n",
    "4. [if time] Is total error the right metric? Context: You might run into a case where you get flat error across all of your queries. You may get a lot worse error on one specific query, but the overall error is better. Now Alice and Bob care about the same data. Alice eats all the budget (entire database except for last). Bob cares about entire database, but his queries about the last index has higher error. \n",
    "    \n",
    "    \n",
    "Scenarios to look for: \n",
    "1. Regular pmw performs poorly, but adapted pmw works well. (probably in disjoint setting)\n",
    "2. Scenarios where regular AND adapted pmw perform poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36962c66",
   "metadata": {},
   "source": [
    "## Scenario 1: Disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ced25535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined</th>\n",
       "      <th>individual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.27986</td>\n",
       "      <td>1.89754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>3.14006</td>\n",
       "      <td>2.12520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       combined  individual\n",
       "Alice   1.27986     1.89754\n",
       "Bob     3.14006     2.12520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize\n",
    "s1random_array = np.random.randint(2, size=(25,4))\n",
    "s1zero_array = np.zeros((25,4))\n",
    "s1alice = np.hstack((s1random_array, s1zero_array))\n",
    "s1bob = np.hstack((s1zero_array, s1random_array))\n",
    "\n",
    "s1combined_list = []\n",
    "s1individual_list = []\n",
    "\n",
    "for i in range(100):\n",
    "    # combined\n",
    "    s1combined = pmw2(workload=np.vstack((s1alice, s1bob)), x=x_small, eps=2, T=40, k=10,  \n",
    "                                 analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                                 to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1combined_list.append(s1combined)\n",
    "    \n",
    "    # individual\n",
    "    s1a = pmw2(workload=s1alice, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Alice'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1b = pmw2(workload=s1bob, x=x_small, eps=1, T=40, k=5,\n",
    "               analyst_labels=['Bob'] * 25, \n",
    "               to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "    s1individual = {**s1a, **s1b}\n",
    "    s1individual_list.append(s1individual)\n",
    "    \n",
    "# find mean over multiple trials\n",
    "s1combined_average = dict(pd.DataFrame(s1combined_list).mean())\n",
    "s1individual_average = dict(pd.DataFrame(s1individual_list).mean())\n",
    "\n",
    "\n",
    "d = {'combined': s1combined_average, 'individual': s1individual_average}\n",
    "df = pd.DataFrame(data=d).sort_index()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfebd710",
   "metadata": {},
   "source": [
    "Bob always receives more error in the combined setting than in the individual setting.\n",
    "\n",
    "Questions: \n",
    "\n",
    "1. Why does Bob always receives more error than Alice in the individual setting if their queries are not related? I would expect instead that their individual error would be very similar.\n",
    "2. Alice receives substantially more error in the individual setting than the combined setting. Is this supposed to happen? Although she receives less update steps in the individual setting, shouldn't the smaller epsilon value in the inidivual case counteract this effect?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1895189",
   "metadata": {},
   "source": [
    "# Scenario 2: Last Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "4345e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bob': 3.166, 'Alice': 2.65}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined\n",
    "s2alice = np.hstack((np.random.randint(2, size=(25,7)), np.zeros((25,1))))\n",
    "s2bob = np.random.randint(2, size=(25,8))\n",
    "\n",
    "s2combined = pmw2(workload=np.vstack((s2alice, s2bob)), x=x_small, eps=1, T=40, k=10,  \n",
    "                             analyst_labels=['Alice'] * 25 + ['Bob'] * 25, \n",
    "                             to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "s2combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0cfabf25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alice': 2.3080000000000003, 'Bob': 2.47}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individual\n",
    "s1a = pmw2(workload=s2alice, x=x_small, eps=1, T=40, k=10,\n",
    "           analyst_labels=['Alice'] * 25, \n",
    "           to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "s1b = pmw2(workload=s2bob, x=x_small, eps=1, T=40, k=10,\n",
    "           analyst_labels=['Bob'] * 25, \n",
    "           to_return='error', show_plot=False, show_messages=False, show_failure_step=False)\n",
    "s1individual = {**s1a, **s1b}\n",
    "s1individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97213e",
   "metadata": {},
   "source": [
    "Bob always receives more error in the combined setting than in the individual setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef73772",
   "metadata": {},
   "source": [
    "# Scenario 3: Incompatible Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3alice = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b6bffa",
   "metadata": {},
   "source": [
    "# Results:\n",
    "- Alice's total error individually:\n",
    "- Bob's total error individually: \n",
    "- Alice's total error in collective: \n",
    "- Bob's total error in collective: \n",
    "\n",
    "# Conclusion: \n",
    "\n",
    "# Follow-ups:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0718e77e574b71e9f7991c7da6831896cfd7281e366db0dbf84de44e8d5f66e5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
